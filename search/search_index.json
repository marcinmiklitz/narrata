{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"<p><code>narrata</code> turns price series into short text that an LLM can reason about quickly.</p> <p>It is designed for situations where a chart is easy for a human to read, but you need an agent to consume the same information as text.</p>"},{"location":"#installation","title":"Installation","text":"<p>From PyPI:</p> <pre><code>pip install narrata\n</code></pre> <p>With optional extras for enhanced backends:</p> <pre><code>pip install \"narrata[all]\"\n</code></pre>"},{"location":"#quickstart","title":"Quickstart","text":"<p><code>narrate(...)</code> takes a pandas OHLCV DataFrame with a datetime index.</p> <pre><code>import yfinance as yf\nfrom narrata import narrate\n\ndf = yf.download(\"AAPL\", period=\"1y\", multi_level_index=False)\nprint(narrate(df, ticker=\"AAPL\"))\n</code></pre> <p>Any data source works \u2014 yfinance, OpenBB, CSV, database \u2014 as long as you have a DataFrame with <code>Open</code>, <code>High</code>, <code>Low</code>, <code>Close</code>, <code>Volume</code> columns and a <code>DatetimeIndex</code>.</p> <p>Example output:</p> <pre><code>AAPL (251 pts, daily): \u2585\u2584\u2583\u2581\u2582\u2581\u2581\u2582\u2582\u2582\u2584\u2584\u2586\u2587\u2587\u2588\u2588\u2586\u2586\u2586\nDate range: 2025-02-14 to 2026-02-13\nRange: [$171.67, $285.92]  Mean: $235.06  Std: $28.36\nStart: $243.54  End: $255.78  Change: +5.03%\nRegime: Uptrend since 2025-05-07 (low volatility)\nRSI(14): 39.6 (neutral-bearish)  MACD: bearish crossover 0 days ago\nBB: lower half\nSMA 50/200: golden cross\nVolume: 0.94x 20-day avg (average)\nVolatility: 84th percentile (high)\nSAX(16): ecabbabbdegghhhg\nPatterns: none detected\nCandlestick: Inside Bar on 2026-02-10\nSupport: $201.77 (26 touches), $208.38 (23 touches)  Resistance: $270.88 (24 touches), $257.57 (22 touches)\n</code></pre>"},{"location":"#token-compression","title":"Token compression","text":"<p>The whole point of narrata is fitting price context into an LLM prompt without wasting tokens. On a 251-day AAPL OHLCV DataFrame:</p> Representation Tokens (gpt-4o) <code>df.to_string()</code> ~9,000 <code>df.to_csv()</code> ~10,700 <code>narrate(df)</code> ~260 <p>That's ~35\u201341x compression while preserving regime, indicators, patterns, and support/resistance.</p> <p>Reproduce this comparison:</p> <pre><code>import tiktoken\nimport pandas as pd\nfrom narrata import narrate\n\nenc = tiktoken.encoding_for_model(\"gpt-4o\")\n# df = your OHLCV DataFrame\nprint(f\"Raw:     {len(enc.encode(df.to_string())):,} tokens\")\nprint(f\"CSV:     {len(enc.encode(df.to_csv())):,} tokens\")\nprint(f\"narrate: {len(enc.encode(narrate(df))):,} tokens\")\n</code></pre>"},{"location":"#fallback-vs-extras-same-input","title":"Fallback vs extras (same input)","text":"<p>Using the same static real-market MSFT dataset (251 daily points, yfinance fixture):</p> <p>Use separate clean virtual environments when comparing fallback vs extras.</p> <p>Fallback-only (<code>pip install narrata</code>):</p> <pre><code>MSFT (251 pts, daily): \u2582\u2581\u2581\u2581\u2583\u2584\u2585\u2587\u2587\u2588\u2587\u2588\u2588\u2588\u2587\u2586\u2585\u2586\u2586\u2582\nDate range: 2025-02-14 to 2026-02-13\nRange: [$354.56, $542.07]  Mean: $466.98  Std: $49.62\nStart: $408.43  End: $401.32  Change: -1.74%\nRegime: Downtrend since 2026-01-29 (high volatility)\nRSI(14): 32.4 (neutral-bearish)  MACD: bearish crossover 11 days ago\nBB: lower half\nSMA 50/200: death cross 17 days ago\nVolume: 0.74x 20-day avg (below average)\nVolatility: 94th percentile (extremely high)\nSAX(16): aaabdfggggggffdb\nPatterns: none detected\nCandlestick: Inside Bar on 2026-02-13\nSupport: $393.67 (15 touches), $378.77 (8 touches)  Resistance: $510.83 (34 touches), $481.63 (21 touches)\n</code></pre> <p>With extras (<code>pip install \"narrata[all]\"</code>):</p> <pre><code>MSFT (251 pts, daily): \u2582\u2581\u2581\u2581\u2583\u2584\u2585\u2587\u2587\u2588\u2587\u2588\u2588\u2588\u2587\u2586\u2585\u2586\u2586\u2582\nDate range: 2025-02-14 to 2026-02-13\nRange: [$354.56, $542.07]  Mean: $466.98  Std: $49.62\nStart: $408.43  End: $401.32  Change: -1.74%\nRegime: Ranging since 2025-02-18 (low volatility)\nRSI(14): 32.4 (neutral-bearish)  MACD: bearish crossover 11 days ago\nBB: lower half\nSMA 50/200: death cross 17 days ago\nVolume: 0.74x 20-day avg (below average)\nVolatility: 94th percentile (extremely high)\nSAX(16): aaabdefggggggfed\nPatterns: none detected\nCandlestick: Inside Bar on 2026-02-13\nSupport: $393.67 (15 touches), $378.77 (8 touches)  Resistance: $510.83 (34 touches), $481.63 (21 touches)\n</code></pre> <p>Main differences in this run: - <code>Regime</code> changed: <code>Regime: Downtrend since 2026-01-29 (high volatility)</code> -&gt; <code>Regime: Ranging since 2025-02-18 (low volatility)</code> - <code>SAX(16)</code> changed: <code>SAX(16): aaabdfggggggffdb</code> -&gt; <code>SAX(16): aaabdefggggggfed</code></p>"},{"location":"#compose-your-own-output","title":"Compose your own output","text":"<p>Use lower-level functions when you want full control:</p> <pre><code>from narrata import analyze_summary, describe_summary, make_sparkline\n\nsummary = analyze_summary(df)\ntext_block = describe_summary(summary)\nspark = make_sparkline(df[\"Close\"].tolist(), width=12)\n\nprint(text_block)\nprint(f\"Close sparkline: {spark}\")\n</code></pre>"},{"location":"#output-formats","title":"Output formats","text":"<p>You can keep the output plain, render as Markdown key-value, or serialize to TOON.</p> <pre><code>from narrata import narrate\n\nmarkdown_text = narrate(df, output_format=\"markdown_kv\")\nplain_text = narrate(df, output_format=\"plain\")\n</code></pre>"},{"location":"#digit-splitting-for-llm-robustness","title":"Digit Splitting for LLM Robustness","text":"<p><code>digit_tokenize(...)</code> is useful when your downstream model struggles with long or dense numeric strings.</p> <p>Why this can help:</p> <ul> <li>Some tokenizers split long numbers in inconsistent chunks.</li> <li>Smaller models can be less stable when many decimals/signs appear close together.</li> <li>Splitting digits can reduce numeric parsing ambiguity in prompts and tool outputs.</li> </ul> <p>When to use it:</p> <ul> <li>Use it for numeric-heavy prompts (prices, percentages, IDs, many decimals).</li> <li>Keep it off when human readability matters more than model robustness.</li> </ul> <p>Example:</p> <pre><code>from narrata import digit_tokenize\n\nprint(digit_tokenize(\"Price 171.24, move +3.2%\"))\n# &lt;digits-split&gt;\n# Price 1 7 1 . 2 4 , move + 3 . 2 %\n</code></pre>"},{"location":"#dependencies","title":"Dependencies","text":"<p>Optional extras:</p> <ul> <li><code>indicators</code>: <code>pandas-ta-openbb</code> (import path remains <code>pandas_ta</code>)</li> <li><code>patterns</code>: <code>pandas-ta-openbb</code> (candlestick pattern backend)</li> <li><code>regimes</code>: <code>ruptures</code> (for change-point regime detection)</li> <li><code>symbolic</code>: <code>tslearn</code>, <code>ruptures</code> (<code>ruptures</code> currently supports Python &lt; 3.14)</li> <li><code>all</code>: install all compatible extras for your interpreter</li> </ul>"},{"location":"#agent-integrations","title":"Agent Integrations","text":""},{"location":"#narrata-skill","title":"narrata Skill","text":"<p>A reusable skill is included at <code>skills/narrata/SKILL.md</code>.</p> <p>Depending on your CLI:</p> <ul> <li>Anthropic-style skills dir: copy to <code>~/.agents/skills/narrata/</code></li> <li>Codex-style skills dir: copy to <code>~/.codex/skills/narrata/</code></li> </ul> <pre><code>mkdir -p ~/.agents/skills/narrata\ncp skills/narrata/SKILL.md ~/.agents/skills/narrata/SKILL.md\n</code></pre>"},{"location":"#fastmcp-server","title":"FastMCP Server","text":"<p>A dedicated MCP package is available on PyPI. Full docs: <code>src/narrata-mcp/README.md</code>.</p> <pre><code>pip install narrata-mcp\nnarrata-mcp\n</code></pre> Claude Desktop configuration  Add to your `claude_desktop_config.json`:  <pre><code>{\n  \"mcpServers\": {\n    \"narrata\": {\n      \"command\": \"uvx\",\n      \"args\": [\"narrata-mcp\"]\n    }\n  }\n}\n</code></pre>"},{"location":"#features","title":"Features","text":"<ul> <li>Input validation for OHLCV DataFrames</li> <li>Summary analysis with date range context</li> <li>Regime classification (<code>Uptrend</code> / <code>Downtrend</code> / <code>Ranging</code>)</li> <li>RSI and MACD interpretation (uses <code>pandas_ta</code> indicator lines when available)</li> <li>Volume analysis (ratio to moving average)</li> <li>Bollinger Band position and squeeze detection</li> <li>Moving average crossover detection (golden/death cross)</li> <li>Volatility percentile ranking</li> <li>SAX symbolic encoding</li> <li>ASTRIDE adaptive symbolic encoding (requires <code>ruptures</code>)</li> <li>Pattern detection plus candlestick detection (<code>pandas_ta</code> first, in-house fallback)</li> <li>Support/resistance extraction</li> <li>Compact Unicode sparklines</li> <li>Output formatting helpers (<code>plain</code>, <code>markdown_kv</code>, <code>toon</code>)</li> <li>High-level <code>narrate(...)</code> composition</li> </ul>"},{"location":"#faq","title":"FAQ","text":""},{"location":"#is-narrata-redundant-if-i-already-use-openbb-yfinance-or-another-data-sdk","title":"Is narrata redundant if I already use OpenBB, yfinance, or another data SDK?","text":"<p>No. <code>narrata</code> is complementary.</p> <p>It sits on top of your existing data layer and turns OHLCV data into compact, LLM-ready narrative text.</p> <p>Typical flow:</p> <pre><code>Data source (OpenBB / yfinance / CSV / DB)\n        -&gt; pandas DataFrame (OHLCV)\n        -&gt; narrata\n        -&gt; concise narrative context for an LLM\n</code></pre> <p><code>narrata</code> is data-source-agnostic: if you can produce a standard OHLCV DataFrame, you can use it.</p>"},{"location":"#does-narrata-call-an-llm-or-provide-llm-endpoints","title":"Does narrata call an LLM or provide LLM endpoints?","text":"<p>No. This is intentional.</p> <p><code>narrata</code> is a pure Python library with deterministic, programmatic analysis and narration. It does not make LLM API calls and does not ship model endpoints.</p> <p>Use it as a pipeline component:</p> <pre><code>your data -&gt; narrata text output -&gt; your chosen LLM/runtime\n</code></pre> <p>This keeps the library lightweight, testable, and provider-agnostic.</p>"},{"location":"#citation","title":"Citation","text":"<p>If you use <code>narrata</code> in research, publications, or public projects:</p> <pre><code>@software{miklitz_narrata,\n  author  = {Miklitz, Marcin},\n  title   = {narrata},\n  url     = {https://github.com/marcinmiklitz/narrata},\n  license = {MIT}\n}\n</code></pre> <p>You can also use the GitHub \"Cite this repository\" button or the metadata in <code>CITATION.cff</code>.</p>"},{"location":"mcp/","title":"MCP Server","text":"<p><code>narrata-mcp</code> is a FastMCP server that exposes narrata's analysis as MCP tools. Available on PyPI.</p>"},{"location":"mcp/#install","title":"Install","text":"<pre><code>pip install narrata-mcp\n</code></pre> <p><code>narrata</code> is installed automatically as a dependency.</p>"},{"location":"mcp/#run","title":"Run","text":"<pre><code>narrata-mcp\n</code></pre> <p>Or without installing globally:</p> <pre><code>uvx narrata-mcp\n</code></pre>"},{"location":"mcp/#claude-desktop-configuration","title":"Claude Desktop configuration","text":"<p>Add to your <code>claude_desktop_config.json</code>:</p> <pre><code>{\n  \"mcpServers\": {\n    \"narrata\": {\n      \"command\": \"uvx\",\n      \"args\": [\"narrata-mcp\"]\n    }\n  }\n}\n</code></pre>"},{"location":"mcp/#exposed-tools","title":"Exposed tools","text":"Tool Description <code>narrata_narrate_ohlcv</code> Full narration text (default entry point) <code>narrata_summary_ohlcv</code> Summary stats and text <code>narrata_regime_ohlcv</code> Regime classification (trend + volatility) <code>narrata_indicators_ohlcv</code> RSI, MACD, Bollinger, volume, volatility <code>narrata_symbolic_sax_ohlcv</code> SAX symbolic encoding <code>narrata_symbolic_astride_ohlcv</code> ASTRIDE adaptive symbolic encoding <code>narrata_patterns_ohlcv</code> Chart and candlestick patterns <code>narrata_levels_ohlcv</code> Support and resistance levels"},{"location":"mcp/#input-format","title":"Input format","text":"<p>All tools accept OHLCV data as a list of points:</p> <pre><code>{\n  \"points\": [\n    {\"timestamp\": \"2025-01-02\", \"Open\": 140.0, \"High\": 142.0, \"Low\": 139.5, \"Close\": 141.5, \"Volume\": 1000000},\n    {\"timestamp\": \"2025-01-03\", \"Open\": 141.5, \"High\": 143.0, \"Low\": 140.0, \"Close\": 142.8, \"Volume\": 1100000}\n  ],\n  \"ticker\": \"AAPL\"\n}\n</code></pre> <p>Common optional fields:</p> <ul> <li><code>ticker</code> \u2014 symbol for headers (default: column name)</li> <li><code>column</code> \u2014 price column to analyze (default: <code>\"Close\"</code>)</li> <li><code>sort_index</code> \u2014 sort points by timestamp (default: <code>true</code>)</li> <li><code>deduplicate_timestamps</code> \u2014 keep latest row for duplicates (default: <code>true</code>)</li> </ul> <p>See the API Reference for the full <code>narrata.mcp_api</code> interface.</p>"},{"location":"pipeline/","title":"Pipeline","text":"<p><code>narrata</code> can be used in two ways:</p> <ol> <li>Call one high-level function (<code>narrate</code>) and get the full text block.</li> <li>Compose only the parts you need for your token budget.</li> </ol> <p>For a full end-to-end walkthrough, see the Tutorial.</p>"},{"location":"pipeline/#fast-path-one-call","title":"Fast path: one call","text":"<pre><code>import yfinance as yf\nfrom narrata import narrate\n\ndf = yf.download(\"AAPL\", period=\"1y\", multi_level_index=False)\ntext = narrate(df, ticker=\"AAPL\")\nprint(text)\n</code></pre> <p>This returns a compact multi-line summary (sparkline, date range, regime, indicators, symbolic encoding, patterns, and levels).</p>"},{"location":"pipeline/#composed-path-pick-only-what-matters","title":"Composed path: pick only what matters","text":"<p>If you want tighter control over prompt size, call the public analysis/rendering helpers directly:</p> <pre><code>import yfinance as yf\nfrom narrata import (\n    analyze_indicators,\n    analyze_regime,\n    analyze_summary,\n    describe_indicators,\n    describe_regime,\n    describe_summary,\n    describe_support_resistance,\n    find_support_resistance,\n    format_sections,\n    make_sparkline,\n)\n\ndf = yf.download(\"MSFT\", period=\"1y\", multi_level_index=False)\n\nsummary = analyze_summary(df, ticker=\"MSFT\")\nregime = analyze_regime(df)\nindicators = analyze_indicators(df)\nlevels = find_support_resistance(df)\n\nsections = {\n    \"overview\": f\"{summary.ticker} ({summary.points} pts, {summary.frequency}): \"\n    f\"{make_sparkline(df['Close'].tolist(), width=16)}\",\n    \"range\": describe_summary(summary, include_header=False).splitlines()[0],\n    \"change\": describe_summary(summary, include_header=False).splitlines()[1],\n    \"regime\": describe_regime(regime),\n    \"indicators\": describe_indicators(indicators),\n    \"levels\": describe_support_resistance(levels),\n}\n\nprint(format_sections(sections, output_format=\"plain\"))\n</code></pre> <p>Representative output shape:</p> <pre><code>MSFT (251 pts, daily): \u2582\u2581\u2581\u2581\u2583\u2584\u2585\u2587\u2587\u2588\u2587\u2588\u2588\u2588\u2587\u2586\u2585\u2586\nRange: [$354.56, $542.07]  Mean: $466.98  Std: $49.62\nStart: $408.43  End: $401.32  Change: -1.74%\nRegime: Ranging since 2025-02-18 (low volatility)\nRSI(14): 32.4 (neutral-bearish)  MACD: bearish crossover 11 days ago\nSupport: $393.67 (15 touches), $378.77 (8 touches)  Resistance: $510.83 (34 touches), $481.63 (21 touches)\n</code></pre>"},{"location":"pipeline/#practical-guidance","title":"Practical guidance","text":"<ul> <li>Use <code>narrate(...)</code> for default usage in agents and apps.</li> <li>Use composed sections when you need strict token control.</li> <li>Keep summary + regime + indicators as a strong minimal subset for most prompts.</li> </ul>"},{"location":"tutorial/","title":"Tutorial: From OHLCV to LLM Prompt","text":"<p>This tutorial shows a complete flow you can copy-paste.</p>"},{"location":"tutorial/#1-prepare-data","title":"1. Prepare data","text":"<pre><code>import yfinance as yf\n\ndf = yf.download(\"AAPL\", period=\"1y\", multi_level_index=False)\n</code></pre>"},{"location":"tutorial/#2-generate-narration","title":"2. Generate narration","text":"<pre><code>from narrata import narrate\n\ntext = narrate(df, ticker=\"AAPL\")\nprint(text)\n</code></pre> <p>Representative output:</p> <pre><code>AAPL (251 pts, daily): \u2585\u2584\u2583\u2581\u2582\u2581\u2581\u2582\u2582\u2582\u2584\u2584\u2586\u2587\u2587\u2588\u2588\u2586\u2586\u2586\nDate range: 2025-02-14 to 2026-02-13\nRange: [$171.67, $285.92]  Mean: $235.06  Std: $28.36\nStart: $243.54  End: $255.78  Change: +5.03%\nRegime: Uptrend since 2025-05-07 (low volatility)\nRSI(14): 39.6 (neutral-bearish)  MACD: bearish crossover 0 days ago\nBB: lower half\nSMA 50/200: golden cross\nVolume: 0.94x 20-day avg (average)\nVolatility: 84th percentile (high)\nSAX(16): ecabbabbdegghhhg\nPatterns: none detected\nCandlestick: Inside Bar on 2026-02-10\nSupport: $201.77 (26 touches), $208.38 (23 touches)  Resistance: $270.88 (24 touches), $257.57 (22 touches)\n</code></pre>"},{"location":"tutorial/#3-use-in-a-prompt","title":"3. Use in a prompt","text":"<pre><code>prompt = f\"\"\"\nYou are a market analysis assistant.\nGiven this time-series context:\n\n{text}\n\nProvide a concise trend interpretation and key risk caveats.\n\"\"\"\n</code></pre>"},{"location":"tutorial/#4-optional-markdown-key-value-output","title":"4. Optional: markdown key-value output","text":"<pre><code>markdown_text = narrate(df, output_format=\"markdown_kv\")\nprint(markdown_text)\n</code></pre>"},{"location":"tutorial/#5-public-imports","title":"5. Public imports","text":"<p>All public methods are available from top-level <code>narrata</code> imports.</p> <pre><code>from narrata import (\n    narrate,\n    analyze_summary,\n    analyze_regime,\n    analyze_indicators,\n    sax_encode,\n    astride_encode,\n    detect_patterns,\n    find_support_resistance,\n    make_sparkline,\n    digit_tokenize,\n    to_plain,\n    to_markdown_kv,\n    to_toon,\n)\n</code></pre> <p>If you prefer module-scoped imports, use <code>narrata.analysis.*</code>, <code>narrata.rendering.*</code>, and <code>narrata.formatting.*</code>.</p> <p>For the full public export list at your installed version:</p> <pre><code>import narrata\nprint(narrata.__all__)\n</code></pre>"},{"location":"tutorial/#6-compare-fallback-only-vs-extras-enabled-output","title":"6. Compare fallback-only vs extras-enabled output","text":"<p>This comparison uses the same static real-market MSFT fixture (251 daily points from yfinance).</p> <p>Use separate clean virtual environments when comparing fallback vs extras.</p>"},{"location":"tutorial/#fallback-only-environment","title":"Fallback-only environment","text":"<p>Install only the core package:</p> <pre><code>pip install narrata\n</code></pre> <p>Detected optional backends:</p> <ul> <li><code>{'pandas_ta': False, 'ruptures': False, 'tslearn': False}</code></li> </ul> <p>Representative output:</p> <pre><code>MSFT (251 pts, daily): \u2582\u2581\u2581\u2581\u2583\u2584\u2585\u2587\u2587\u2588\u2587\u2588\u2588\u2588\u2587\u2586\u2585\u2586\u2586\u2582\nDate range: 2025-02-14 to 2026-02-13\nRange: [$354.56, $542.07]  Mean: $466.98  Std: $49.62\nStart: $408.43  End: $401.32  Change: -1.74%\nRegime: Downtrend since 2026-01-29 (high volatility)\nRSI(14): 32.4 (neutral-bearish)  MACD: bearish crossover 11 days ago\nBB: lower half\nSMA 50/200: death cross 17 days ago\nVolume: 0.74x 20-day avg (below average)\nVolatility: 94th percentile (extremely high)\nSAX(16): aaabdfggggggffdb\nPatterns: none detected\nCandlestick: Inside Bar on 2026-02-13\nSupport: $393.67 (15 touches), $378.77 (8 touches)  Resistance: $510.83 (34 touches), $481.63 (21 touches)\n</code></pre>"},{"location":"tutorial/#extras-enabled-environment","title":"Extras-enabled environment","text":"<p>Install optional backends:</p> <pre><code>pip install \"narrata[all]\"\n</code></pre> <p>Detected optional backends:</p> <ul> <li><code>{'pandas_ta': True, 'ruptures': True, 'tslearn': True}</code></li> </ul> <p>Representative output:</p> <pre><code>MSFT (251 pts, daily): \u2582\u2581\u2581\u2581\u2583\u2584\u2585\u2587\u2587\u2588\u2587\u2588\u2588\u2588\u2587\u2586\u2585\u2586\u2586\u2582\nDate range: 2025-02-14 to 2026-02-13\nRange: [$354.56, $542.07]  Mean: $466.98  Std: $49.62\nStart: $408.43  End: $401.32  Change: -1.74%\nRegime: Ranging since 2025-02-18 (low volatility)\nRSI(14): 32.4 (neutral-bearish)  MACD: bearish crossover 11 days ago\nBB: lower half\nSMA 50/200: death cross 17 days ago\nVolume: 0.74x 20-day avg (below average)\nVolatility: 94th percentile (extremely high)\nSAX(16): aaabdefggggggfed\nPatterns: none detected\nCandlestick: Inside Bar on 2026-02-13\nSupport: $393.67 (15 touches), $378.77 (8 touches)  Resistance: $510.83 (34 touches), $481.63 (21 touches)\n</code></pre>"},{"location":"tutorial/#why-the-outputs-differ","title":"Why the outputs differ","text":"<ul> <li><code>Regime</code> line changed   fallback: <code>Regime: Downtrend since 2026-01-29 (high volatility)</code>   extras: <code>Regime: Ranging since 2025-02-18 (low volatility)</code></li> <li><code>SAX(16)</code> line changed   fallback: <code>SAX(16): aaabdfggggggffdb</code>   extras: <code>SAX(16): aaabdefggggggfed</code></li> </ul>"},{"location":"tutorial/#why-some-lines-stay-the-same","title":"Why some lines stay the same","text":"<ul> <li>Sparkline, summary statistics, support/resistance, and many pattern labels come from deterministic in-house logic.</li> <li>RSI/MACD values are often numerically close between in-house and <code>pandas_ta</code> for the same input series.</li> </ul>"},{"location":"tutorial/#7-practical-notes","title":"7. Practical notes","text":""},{"location":"tutorial/#choosing-output-format","title":"Choosing output format","text":"<ul> <li>Use <code>plain</code> when the text goes directly into a prompt.</li> <li>Use <code>markdown_kv</code> when you want highly scannable sections.</li> <li>Use <code>toon</code> when you optimize for compact structured serialization.</li> </ul>"},{"location":"tutorial/#choosing-sparkline-width","title":"Choosing sparkline width","text":"<ul> <li><code>8-12</code> chars for very tight token budgets</li> <li><code>16-24</code> chars for better visual shape</li> </ul>"},{"location":"tutorial/#when-to-enable-digit-level-tokenization","title":"When to enable digit-level tokenization","text":"<p>Use <code>digit_level=True</code> only when you are explicitly optimizing number tokenization behavior in your LLM pipeline. For general usage, leave it off for readability.</p>"},{"location":"reference/narrata/","title":"narrata","text":""},{"location":"reference/narrata/#narrata","title":"<code>narrata</code>","text":"<p>Public API for narrata.</p>"},{"location":"reference/narrata/#narrata.NarrataError","title":"<code>NarrataError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for narrata.</p>"},{"location":"reference/narrata/#narrata.UnsupportedFormatError","title":"<code>UnsupportedFormatError</code>","text":"<p>               Bases: <code>NarrataError</code></p> <p>Raised when a requested output format is unsupported.</p>"},{"location":"reference/narrata/#narrata.ValidationError","title":"<code>ValidationError</code>","text":"<p>               Bases: <code>NarrataError</code></p> <p>Raised when input data does not meet narrata contracts.</p>"},{"location":"reference/narrata/#narrata.IndicatorStats","title":"<code>IndicatorStats(rsi_period, rsi_value, rsi_state, macd_value, macd_signal, macd_histogram, macd_state, crossover_days_ago, bb_position=None, bb_squeeze=None, ma_cross=None, ma_cross_days_ago=None, volume_ratio=None, volume_state=None, volatility_percentile=None, volatility_state=None)</code>  <code>dataclass</code>","text":"<p>Structured output for key technical indicators.</p>"},{"location":"reference/narrata/#narrata.LevelStats","title":"<code>LevelStats(supports, resistances)</code>  <code>dataclass</code>","text":"<p>Structured support and resistance output.</p>"},{"location":"reference/narrata/#narrata.PatternStats","title":"<code>PatternStats(chart_pattern, chart_pattern_since, candlestick_pattern, candlestick_date)</code>  <code>dataclass</code>","text":"<p>Structured output for detected chart and candlestick patterns.</p>"},{"location":"reference/narrata/#narrata.PriceLevel","title":"<code>PriceLevel(price, touches)</code>  <code>dataclass</code>","text":"<p>Single support or resistance level.</p>"},{"location":"reference/narrata/#narrata.RegimeStats","title":"<code>RegimeStats(trend_label, volatility_label, start_date)</code>  <code>dataclass</code>","text":"<p>Structured output for current market regime.</p>"},{"location":"reference/narrata/#narrata.SummaryStats","title":"<code>SummaryStats(ticker, column, points, frequency, start_date, end_date, start, end, minimum, maximum, mean, std, change_pct)</code>  <code>dataclass</code>","text":"<p>Structured output of summary analysis for one series.</p>"},{"location":"reference/narrata/#narrata.SymbolicStats","title":"<code>SymbolicStats(method, word_size, alphabet_size, symbols)</code>  <code>dataclass</code>","text":"<p>Structured output for symbolic time-series encoding.</p>"},{"location":"reference/narrata/#narrata.analyze_indicators","title":"<code>analyze_indicators(df, column='Close', rsi_period=14)</code>","text":"<p>Analyze RSI, MACD, Bollinger Bands, MA crossovers, volume, and volatility.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>column</code> <code>str</code> <p>Price column to analyze.</p> <code>'Close'</code> <code>rsi_period</code> <code>int</code> <p>RSI period.</p> <code>14</code> <p>Returns:</p> Type Description <code>IndicatorStats</code> <p>Structured indicator statistics.</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def analyze_indicators(df: pd.DataFrame, column: str = \"Close\", rsi_period: int = 14) -&gt; IndicatorStats:\n    \"\"\"Analyze RSI, MACD, Bollinger Bands, MA crossovers, volume, and volatility.\n\n    :param df: OHLCV DataFrame.\n    :param column: Price column to analyze.\n    :param rsi_period: RSI period.\n    :return: Structured indicator statistics.\n    \"\"\"\n    validate_ohlcv_frame(df)\n    if column not in df.columns:\n        raise ValidationError(f\"Column '{column}' does not exist in DataFrame.\")\n\n    values = pd.to_numeric(df[column], errors=\"coerce\").dropna()\n    if ta is None:\n        rsi_value = compute_rsi(values, period=rsi_period)\n        macd_value, signal_value, histogram = compute_macd(values)\n        macd_state, crossover_days = _classify_macd(values)\n    else:\n        rsi_value = _compute_rsi_with_pandas_ta(values, period=rsi_period)\n        macd_value, signal_value, histogram, macd_state, crossover_days = _compute_macd_with_pandas_ta(values)\n\n    rsi_state = _classify_rsi(values, rsi_value)\n\n    bb_position: str | None = None\n    bb_squeeze: bool | None = None\n    try:\n        bb_position, bb_squeeze = compute_bollinger(values)\n    except ValidationError:\n        pass\n\n    ma_cross: str | None = None\n    ma_cross_days: int | None = None\n    try:\n        ma_cross, ma_cross_days = compute_ma_crossover(values)\n    except ValidationError:\n        pass\n\n    volume_ratio: float | None = None\n    volume_state: str | None = None\n    try:\n        volume_ratio, volume_state = compute_volume_state(df)\n    except ValidationError:\n        pass\n\n    vol_pct: float | None = None\n    vol_state: str | None = None\n    try:\n        vol_pct, vol_state = compute_volatility_percentile(values)\n    except ValidationError:\n        pass\n\n    return IndicatorStats(\n        rsi_period=rsi_period,\n        rsi_value=rsi_value,\n        rsi_state=rsi_state,\n        macd_value=macd_value,\n        macd_signal=signal_value,\n        macd_histogram=histogram,\n        macd_state=macd_state,\n        crossover_days_ago=crossover_days,\n        bb_position=bb_position,\n        bb_squeeze=bb_squeeze,\n        ma_cross=ma_cross,\n        ma_cross_days_ago=ma_cross_days,\n        volume_ratio=volume_ratio,\n        volume_state=volume_state,\n        volatility_percentile=vol_pct,\n        volatility_state=vol_state,\n    )\n</code></pre>"},{"location":"reference/narrata/#narrata.compute_bollinger","title":"<code>compute_bollinger(series, period=20, num_std=2.0)</code>","text":"<p>Compute Bollinger Band position and squeeze state.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>Price series.</p> required <code>period</code> <code>int</code> <p>Bollinger Band period.</p> <code>20</code> <code>num_std</code> <code>float</code> <p>Number of standard deviations for band width.</p> <code>2.0</code> <p>Returns:</p> Type Description <code>tuple[str, bool]</code> <p>Tuple of (position label, squeeze detected).</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def compute_bollinger(series: pd.Series, period: int = 20, num_std: float = 2.0) -&gt; tuple[str, bool]:\n    \"\"\"Compute Bollinger Band position and squeeze state.\n\n    :param series: Price series.\n    :param period: Bollinger Band period.\n    :param num_std: Number of standard deviations for band width.\n    :return: Tuple of (position label, squeeze detected).\n    \"\"\"\n    values = pd.to_numeric(series, errors=\"coerce\").dropna()\n    if values.size &lt; period:\n        raise ValidationError(\"Not enough data to compute Bollinger Bands.\")\n\n    sma = values.rolling(window=period).mean()\n    std = values.rolling(window=period).std(ddof=0)\n    upper = sma + num_std * std\n    lower = sma - num_std * std\n    bandwidth = ((upper - lower) / sma).dropna()\n\n    latest_price = float(values.iloc[-1])\n    latest_upper = float(upper.iloc[-1])\n    latest_lower = float(lower.iloc[-1])\n    latest_sma = float(sma.iloc[-1])\n\n    if latest_upper == latest_lower:\n        position = \"at midline\"\n    else:\n        pct = (latest_price - latest_lower) / (latest_upper - latest_lower)\n        if pct &gt;= 0.95:\n            position = \"above upper band\"\n        elif pct &gt;= 0.80:\n            position = \"near upper band\"\n        elif pct &lt;= 0.05:\n            position = \"below lower band\"\n        elif pct &lt;= 0.20:\n            position = \"near lower band\"\n        elif latest_price &gt; latest_sma:\n            position = \"upper half\"\n        else:\n            position = \"lower half\"\n\n    squeeze = False\n    if bandwidth.size &gt;= period:\n        recent_bw = float(bandwidth.iloc[-1])\n        lookback_bw = float(bandwidth.iloc[-period:].quantile(0.20))\n        squeeze = recent_bw &lt;= lookback_bw\n\n    return position, squeeze\n</code></pre>"},{"location":"reference/narrata/#narrata.compute_ma_crossover","title":"<code>compute_ma_crossover(series, fast_period=50, slow_period=200)</code>","text":"<p>Detect moving average crossover (golden/death cross).</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>Price series.</p> required <code>fast_period</code> <code>int</code> <p>Fast SMA period.</p> <code>50</code> <code>slow_period</code> <code>int</code> <p>Slow SMA period.</p> <code>200</code> <p>Returns:</p> Type Description <code>tuple[str | None, int | None]</code> <p>Tuple of (cross type or None, days since cross or None).</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def compute_ma_crossover(\n    series: pd.Series, fast_period: int = 50, slow_period: int = 200\n) -&gt; tuple[str | None, int | None]:\n    \"\"\"Detect moving average crossover (golden/death cross).\n\n    :param series: Price series.\n    :param fast_period: Fast SMA period.\n    :param slow_period: Slow SMA period.\n    :return: Tuple of (cross type or None, days since cross or None).\n    \"\"\"\n    values = pd.to_numeric(series, errors=\"coerce\").dropna()\n    if values.size &lt; slow_period + 1:\n        return None, None\n\n    fast_sma = values.rolling(window=fast_period).mean()\n    slow_sma = values.rolling(window=slow_period).mean()\n    diff = (fast_sma - slow_sma).dropna()\n    if diff.size &lt; 2:\n        return None, None\n\n    signs = np.sign(diff.to_numpy())\n    current = \"golden cross\" if signs[-1] &gt;= 0.0 else \"death cross\"\n\n    for idx in range(signs.size - 1, 0, -1):\n        if signs[idx] != signs[idx - 1] and signs[idx] != 0.0 and signs[idx - 1] != 0.0:\n            days_ago = signs.size - 1 - idx\n            return current, days_ago\n\n    return current, None\n</code></pre>"},{"location":"reference/narrata/#narrata.compute_macd","title":"<code>compute_macd(series, fast_period=12, slow_period=26, signal_period=9)</code>","text":"<p>Compute MACD values for the latest sample.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>Price series.</p> required <code>fast_period</code> <code>int</code> <p>Fast EMA period.</p> <code>12</code> <code>slow_period</code> <code>int</code> <p>Slow EMA period.</p> <code>26</code> <code>signal_period</code> <code>int</code> <p>Signal EMA period.</p> <code>9</code> <p>Returns:</p> Type Description <code>tuple[float, float, float]</code> <p>Tuple of (macd_line, signal_line, histogram).</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def compute_macd(\n    series: pd.Series, fast_period: int = 12, slow_period: int = 26, signal_period: int = 9\n) -&gt; tuple[float, float, float]:\n    \"\"\"Compute MACD values for the latest sample.\n\n    :param series: Price series.\n    :param fast_period: Fast EMA period.\n    :param slow_period: Slow EMA period.\n    :param signal_period: Signal EMA period.\n    :return: Tuple of (macd_line, signal_line, histogram).\n    \"\"\"\n    if fast_period &gt;= slow_period:\n        raise ValidationError(\"fast_period must be smaller than slow_period.\")\n\n    values = pd.to_numeric(series, errors=\"coerce\").dropna()\n    if values.size &lt; slow_period + signal_period:\n        raise ValidationError(\"Not enough data to compute MACD.\")\n\n    fast_ema = values.ewm(span=fast_period, adjust=False).mean()\n    slow_ema = values.ewm(span=slow_period, adjust=False).mean()\n    macd_line = fast_ema - slow_ema\n    signal_line = macd_line.ewm(span=signal_period, adjust=False).mean()\n    histogram = macd_line - signal_line\n\n    return float(macd_line.iloc[-1]), float(signal_line.iloc[-1]), float(histogram.iloc[-1])\n</code></pre>"},{"location":"reference/narrata/#narrata.compute_rsi","title":"<code>compute_rsi(series, period=14)</code>","text":"<p>Compute RSI using Wilder-style exponential smoothing.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>Price series.</p> required <code>period</code> <code>int</code> <p>RSI period length.</p> <code>14</code> <p>Returns:</p> Type Description <code>float</code> <p>Latest RSI value.</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def compute_rsi(series: pd.Series, period: int = 14) -&gt; float:\n    \"\"\"Compute RSI using Wilder-style exponential smoothing.\n\n    :param series: Price series.\n    :param period: RSI period length.\n    :return: Latest RSI value.\n    \"\"\"\n    if period &lt; 2:\n        raise ValidationError(\"RSI period must be &gt;= 2.\")\n\n    values = pd.to_numeric(series, errors=\"coerce\").dropna()\n    if values.size &lt; period + 1:\n        raise ValidationError(\"Not enough data to compute RSI.\")\n\n    delta = values.diff()\n    gains = delta.clip(lower=0.0)\n    losses = -delta.clip(upper=0.0)\n    avg_gain = gains.ewm(alpha=1.0 / period, adjust=False).mean()\n    avg_loss = losses.ewm(alpha=1.0 / period, adjust=False).mean()\n    rs = avg_gain / avg_loss.replace(0.0, np.nan)\n    rsi = 100.0 - (100.0 / (1.0 + rs))\n\n    latest = float(rsi.iloc[-1]) if not np.isnan(rsi.iloc[-1]) else 100.0\n    return max(0.0, min(100.0, latest))\n</code></pre>"},{"location":"reference/narrata/#narrata.compute_volatility_percentile","title":"<code>compute_volatility_percentile(series, window=20, lookback=252)</code>","text":"<p>Compute historical volatility percentile rank.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>Price series.</p> required <code>window</code> <code>int</code> <p>Rolling window for volatility calculation.</p> <code>20</code> <code>lookback</code> <code>int</code> <p>Lookback period for percentile ranking.</p> <code>252</code> <p>Returns:</p> Type Description <code>tuple[float, str]</code> <p>Tuple of (percentile 0-100, state label).</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def compute_volatility_percentile(series: pd.Series, window: int = 20, lookback: int = 252) -&gt; tuple[float, str]:\n    \"\"\"Compute historical volatility percentile rank.\n\n    :param series: Price series.\n    :param window: Rolling window for volatility calculation.\n    :param lookback: Lookback period for percentile ranking.\n    :return: Tuple of (percentile 0-100, state label).\n    \"\"\"\n    values = pd.to_numeric(series, errors=\"coerce\").dropna()\n    if values.size &lt; window + 2:\n        raise ValidationError(\"Not enough data to compute volatility percentile.\")\n\n    returns = values.pct_change().dropna()\n    rolling_vol = returns.rolling(window=window).std(ddof=0).dropna()\n    if rolling_vol.empty:\n        raise ValidationError(\"Not enough data to compute volatility percentile.\")\n\n    current_vol = float(rolling_vol.iloc[-1])\n    rank_window = rolling_vol.tail(min(lookback, rolling_vol.size))\n    percentile = float((rank_window &lt;= current_vol).sum() / rank_window.size * 100.0)\n    percentile = round(percentile, 0)\n\n    if percentile &lt;= 10:\n        state = \"extremely low\"\n    elif percentile &lt;= 25:\n        state = \"low\"\n    elif percentile &gt;= 90:\n        state = \"extremely high\"\n    elif percentile &gt;= 75:\n        state = \"high\"\n    else:\n        state = \"moderate\"\n\n    return percentile, state\n</code></pre>"},{"location":"reference/narrata/#narrata.compute_volume_state","title":"<code>compute_volume_state(df, lookback=20)</code>","text":"<p>Compute volume ratio to N-day moving average and classify.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame with Volume column.</p> required <code>lookback</code> <code>int</code> <p>Moving average lookback period.</p> <code>20</code> <p>Returns:</p> Type Description <code>tuple[float, str]</code> <p>Tuple of (ratio to average, state label).</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def compute_volume_state(df: pd.DataFrame, lookback: int = 20) -&gt; tuple[float, str]:\n    \"\"\"Compute volume ratio to N-day moving average and classify.\n\n    :param df: OHLCV DataFrame with Volume column.\n    :param lookback: Moving average lookback period.\n    :return: Tuple of (ratio to average, state label).\n    \"\"\"\n    if \"Volume\" not in df.columns:\n        raise ValidationError(\"DataFrame must contain Volume column.\")\n\n    volume = pd.to_numeric(df[\"Volume\"], errors=\"coerce\").dropna()\n    if volume.size &lt; lookback + 1:\n        raise ValidationError(\"Not enough data to compute volume state.\")\n\n    avg = float(volume.rolling(window=lookback).mean().iloc[-1])\n    if avg &lt;= 0.0:\n        return 1.0, \"average\"\n\n    latest = float(volume.iloc[-1])\n    ratio = latest / avg\n\n    if ratio &gt;= 2.0:\n        state = \"unusually high\"\n    elif ratio &gt;= 1.5:\n        state = \"above average\"\n    elif ratio &lt;= 0.5:\n        state = \"unusually low\"\n    elif ratio &lt;= 0.75:\n        state = \"below average\"\n    else:\n        state = \"average\"\n\n    return round(ratio, 2), state\n</code></pre>"},{"location":"reference/narrata/#narrata.describe_indicators","title":"<code>describe_indicators(stats)</code>","text":"<p>Render indicator statistics as concise narration lines.</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>IndicatorStats</code> <p>Indicator statistics.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Human-readable indicator narration.</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def describe_indicators(stats: IndicatorStats) -&gt; str:\n    \"\"\"Render indicator statistics as concise narration lines.\n\n    :param stats: Indicator statistics.\n    :return: Human-readable indicator narration.\n    \"\"\"\n    rsi_part = f\"RSI({stats.rsi_period}): {stats.rsi_value:.1f} ({stats.rsi_state})\"\n\n    if stats.crossover_days_ago is None:\n        macd_part = f\"MACD: {stats.macd_state}\"\n    else:\n        unit = \"day\" if stats.crossover_days_ago == 1 else \"days\"\n        macd_part = f\"MACD: {stats.macd_state} crossover {stats.crossover_days_ago} {unit} ago\"\n\n    parts = [f\"{rsi_part}  {macd_part}\"]\n\n    if stats.bb_position is not None:\n        bb_text = f\"BB: {stats.bb_position}\"\n        if stats.bb_squeeze:\n            bb_text += \" (squeeze)\"\n        parts.append(bb_text)\n\n    if stats.ma_cross is not None:\n        if stats.ma_cross_days_ago is not None:\n            unit = \"day\" if stats.ma_cross_days_ago == 1 else \"days\"\n            parts.append(f\"SMA 50/200: {stats.ma_cross} {stats.ma_cross_days_ago} {unit} ago\")\n        else:\n            parts.append(f\"SMA 50/200: {stats.ma_cross}\")\n\n    if stats.volume_ratio is not None and stats.volume_state is not None:\n        parts.append(f\"Volume: {stats.volume_ratio}x 20-day avg ({stats.volume_state})\")\n\n    if stats.volatility_percentile is not None and stats.volatility_state is not None:\n        percentile = _format_ordinal(stats.volatility_percentile)\n        parts.append(f\"Volatility: {percentile} percentile ({stats.volatility_state})\")\n\n    return \"\\n\".join(parts)\n</code></pre>"},{"location":"reference/narrata/#narrata.describe_candlestick","title":"<code>describe_candlestick(stats)</code>","text":"<p>Render candlestick line.</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>PatternStats</code> <p>Pattern detection results.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Human-readable candlestick narration.</p> Source code in <code>src/narrata/narrata/analysis/patterns.py</code> <pre><code>def describe_candlestick(stats: PatternStats) -&gt; str:\n    \"\"\"Render candlestick line.\n\n    :param stats: Pattern detection results.\n    :return: Human-readable candlestick narration.\n    \"\"\"\n    if stats.candlestick_pattern is None or stats.candlestick_date is None:\n        return \"Candlestick: none detected\"\n    return f\"Candlestick: {stats.candlestick_pattern} on {stats.candlestick_date.isoformat()}\"\n</code></pre>"},{"location":"reference/narrata/#narrata.describe_patterns","title":"<code>describe_patterns(stats)</code>","text":"<p>Render chart pattern line.</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>PatternStats</code> <p>Pattern detection results.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Human-readable chart pattern narration.</p> Source code in <code>src/narrata/narrata/analysis/patterns.py</code> <pre><code>def describe_patterns(stats: PatternStats) -&gt; str:\n    \"\"\"Render chart pattern line.\n\n    :param stats: Pattern detection results.\n    :return: Human-readable chart pattern narration.\n    \"\"\"\n    if stats.chart_pattern is None or stats.chart_pattern_since is None:\n        return \"Patterns: none detected\"\n    return f\"Patterns: {stats.chart_pattern} forming since {stats.chart_pattern_since.isoformat()}\"\n</code></pre>"},{"location":"reference/narrata/#narrata.detect_candlestick_pattern","title":"<code>detect_candlestick_pattern(df)</code>","text":"<p>Detect candlestick patterns using optional backend and in-house fallback.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <p>Returns:</p> Type Description <code>tuple[str | None, date | None]</code> <p>Candlestick pattern name and timestamp if detected.</p> Source code in <code>src/narrata/narrata/analysis/patterns.py</code> <pre><code>def detect_candlestick_pattern(df: pd.DataFrame) -&gt; tuple[str | None, date | None]:\n    \"\"\"Detect candlestick patterns using optional backend and in-house fallback.\n\n    :param df: OHLCV DataFrame.\n    :return: Candlestick pattern name and timestamp if detected.\n    \"\"\"\n    for column in (\"Open\", \"Close\"):\n        if column not in df.columns:\n            raise ValidationError(\"DataFrame must contain Open and Close columns.\")\n    if df.shape[0] &lt; 2:\n        return None, None\n\n    if ta is not None and \"High\" in df.columns and \"Low\" in df.columns:\n        detected = _detect_candlestick_with_pandas_ta(df)\n        if detected[0] is not None:\n            return detected\n\n    return _detect_candlestick_inhouse(df)\n</code></pre>"},{"location":"reference/narrata/#narrata.detect_chart_pattern","title":"<code>detect_chart_pattern(df, lookback=60)</code>","text":"<p>Detect simple chart patterns from highs and lows.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>lookback</code> <code>int</code> <p>Number of recent rows to inspect.</p> <code>60</code> <p>Returns:</p> Type Description <code>tuple[str | None, date | None]</code> <p>Pattern name and starting timestamp if detected.</p> Source code in <code>src/narrata/narrata/analysis/patterns.py</code> <pre><code>def detect_chart_pattern(df: pd.DataFrame, lookback: int = 60) -&gt; tuple[str | None, date | None]:\n    \"\"\"Detect simple chart patterns from highs and lows.\n\n    :param df: OHLCV DataFrame.\n    :param lookback: Number of recent rows to inspect.\n    :return: Pattern name and starting timestamp if detected.\n    \"\"\"\n    if \"High\" not in df.columns or \"Low\" not in df.columns or \"Close\" not in df.columns:\n        raise ValidationError(\"DataFrame must contain High, Low and Close columns.\")\n\n    window = df.tail(lookback).copy()\n    highs = pd.to_numeric(window[\"High\"], errors=\"coerce\").dropna()\n    lows = pd.to_numeric(window[\"Low\"], errors=\"coerce\").dropna()\n    if highs.size &lt; 5 or lows.size &lt; 5:\n        return None, None\n\n    resistance = highs.quantile(0.85)\n    high_band = highs[(highs &gt;= resistance * 0.99) &amp; (highs &lt;= resistance * 1.01)]\n    if high_band.size &lt; 2:\n        return None, None\n\n    low_x = np.arange(lows.size, dtype=float)\n    slope, _ = np.polyfit(low_x, lows.to_numpy(dtype=float), 1)\n    if slope &lt;= 0:\n        return None, None\n\n    start_idx = min(high_band.index.min(), lows.index.min())\n    return \"Ascending triangle\", pd.Timestamp(start_idx).date()\n</code></pre>"},{"location":"reference/narrata/#narrata.detect_patterns","title":"<code>detect_patterns(df, lookback=60)</code>","text":"<p>Detect chart and candlestick patterns.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>lookback</code> <code>int</code> <p>Number of recent rows to inspect for chart patterns.</p> <code>60</code> <p>Returns:</p> Type Description <code>PatternStats</code> <p>Pattern detection result.</p> Source code in <code>src/narrata/narrata/analysis/patterns.py</code> <pre><code>def detect_patterns(df: pd.DataFrame, lookback: int = 60) -&gt; PatternStats:\n    \"\"\"Detect chart and candlestick patterns.\n\n    :param df: OHLCV DataFrame.\n    :param lookback: Number of recent rows to inspect for chart patterns.\n    :return: Pattern detection result.\n    \"\"\"\n    validate_ohlcv_frame(df)\n    if lookback &lt; 10:\n        raise ValidationError(\"lookback must be &gt;= 10.\")\n\n    chart_pattern, chart_since = detect_chart_pattern(df, lookback=lookback)\n    candle_pattern, candle_date = detect_candlestick_pattern(df)\n    return PatternStats(\n        chart_pattern=chart_pattern,\n        chart_pattern_since=chart_since,\n        candlestick_pattern=candle_pattern,\n        candlestick_date=candle_date,\n    )\n</code></pre>"},{"location":"reference/narrata/#narrata.analyze_regime","title":"<code>analyze_regime(df, column='Close', window=20, penalty=3.0, trend_threshold=0.0005)</code>","text":"<p>Classify current trend and volatility regime.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>column</code> <code>str</code> <p>Price column to analyze.</p> <code>'Close'</code> <code>window</code> <code>int</code> <p>Rolling window for fallback regime metrics.</p> <code>20</code> <code>penalty</code> <code>float</code> <p>Ruptures PELT penalty parameter.</p> <code>3.0</code> <code>trend_threshold</code> <code>float</code> <p>Mean-return threshold for trend labels.</p> <code>0.0005</code> <p>Returns:</p> Type Description <code>RegimeStats</code> <p>Regime classification with inferred start date.</p> Source code in <code>src/narrata/narrata/analysis/regimes.py</code> <pre><code>def analyze_regime(\n    df: pd.DataFrame,\n    column: str = \"Close\",\n    window: int = 20,\n    penalty: float = 3.0,\n    trend_threshold: float = 0.0005,\n) -&gt; RegimeStats:\n    \"\"\"Classify current trend and volatility regime.\n\n    :param df: OHLCV DataFrame.\n    :param column: Price column to analyze.\n    :param window: Rolling window for fallback regime metrics.\n    :param penalty: Ruptures PELT penalty parameter.\n    :param trend_threshold: Mean-return threshold for trend labels.\n    :return: Regime classification with inferred start date.\n    \"\"\"\n    validate_ohlcv_frame(df)\n    if column not in df.columns:\n        raise ValidationError(f\"Column '{column}' does not exist in DataFrame.\")\n    if window &lt; 5:\n        raise ValidationError(\"window must be &gt;= 5.\")\n\n    prices = pd.to_numeric(df[column], errors=\"coerce\").dropna()\n    returns = prices.pct_change().dropna()\n    if returns.size &lt; window:\n        raise ValidationError(\"Not enough data to infer regime.\")\n\n    if rpt is not None and returns.size &gt;= max(window, 40):\n        trend_label, volatility_label, start_date = _analyze_with_ruptures(\n            returns=returns,\n            penalty=penalty,\n            trend_threshold=trend_threshold,\n            min_size=window,\n            rpt_module=rpt,\n        )\n    else:\n        trend_label, volatility_label, start_date = _analyze_with_rolling(\n            returns=returns,\n            window=window,\n            trend_threshold=trend_threshold,\n        )\n\n    return RegimeStats(\n        trend_label=trend_label,\n        volatility_label=volatility_label,\n        start_date=start_date,\n    )\n</code></pre>"},{"location":"reference/narrata/#narrata.describe_regime","title":"<code>describe_regime(stats)</code>","text":"<p>Render regime classification as one line.</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>RegimeStats</code> <p>Regime classification.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Human-readable regime text.</p> Source code in <code>src/narrata/narrata/analysis/regimes.py</code> <pre><code>def describe_regime(stats: RegimeStats) -&gt; str:\n    \"\"\"Render regime classification as one line.\n\n    :param stats: Regime classification.\n    :return: Human-readable regime text.\n    \"\"\"\n    return f\"Regime: {stats.trend_label} since {stats.start_date.isoformat()} ({stats.volatility_label} volatility)\"\n</code></pre>"},{"location":"reference/narrata/#narrata.analyze_summary","title":"<code>analyze_summary(df, column='Close', ticker=None)</code>","text":"<p>Compute summary statistics for a selected numeric column.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>column</code> <code>str</code> <p>Numeric column to summarize.</p> <code>'Close'</code> <code>ticker</code> <code>str | None</code> <p>Optional ticker override.</p> <code>None</code> <p>Returns:</p> Type Description <code>SummaryStats</code> <p>Structured summary statistics.</p> Source code in <code>src/narrata/narrata/analysis/summary.py</code> <pre><code>def analyze_summary(df: pd.DataFrame, column: str = \"Close\", ticker: str | None = None) -&gt; SummaryStats:\n    \"\"\"Compute summary statistics for a selected numeric column.\n\n    :param df: OHLCV DataFrame.\n    :param column: Numeric column to summarize.\n    :param ticker: Optional ticker override.\n    :return: Structured summary statistics.\n    \"\"\"\n    validate_ohlcv_frame(df)\n\n    if column not in df.columns:\n        raise ValidationError(f\"Column '{column}' does not exist in DataFrame.\")\n\n    series = pd.to_numeric(df[column], errors=\"coerce\").dropna()\n    if series.empty:\n        raise ValidationError(f\"Column '{column}' contains no numeric values.\")\n\n    start = float(series.iloc[0])\n    end = float(series.iloc[-1])\n\n    if start == 0.0:\n        change_pct = math.nan\n    else:\n        change_pct = ((end - start) / abs(start)) * 100.0\n\n    return SummaryStats(\n        ticker=_resolve_ticker(df, ticker),\n        column=column,\n        points=int(series.size),\n        frequency=infer_frequency_label(df.index),\n        start_date=df.index[0].date(),\n        end_date=df.index[-1].date(),\n        start=start,\n        end=end,\n        minimum=float(series.min()),\n        maximum=float(series.max()),\n        mean=float(series.mean()),\n        std=float(series.std(ddof=0)),\n        change_pct=change_pct,\n    )\n</code></pre>"},{"location":"reference/narrata/#narrata.describe_summary","title":"<code>describe_summary(summary, currency_symbol='$', precision=2, include_header=True)</code>","text":"<p>Render summary statistics as text.</p> <p>Parameters:</p> Name Type Description Default <code>summary</code> <code>SummaryStats</code> <p>Summary statistics.</p> required <code>currency_symbol</code> <code>str</code> <p>Symbol for currency formatting.</p> <code>'$'</code> <code>precision</code> <code>int</code> <p>Decimal precision for numeric values.</p> <code>2</code> <code>include_header</code> <code>bool</code> <p>Include ticker/points/frequency prefix.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>Summary narration.</p> Source code in <code>src/narrata/narrata/analysis/summary.py</code> <pre><code>def describe_summary(\n    summary: SummaryStats, currency_symbol: str = \"$\", precision: int = 2, include_header: bool = True\n) -&gt; str:\n    \"\"\"Render summary statistics as text.\n\n    :param summary: Summary statistics.\n    :param currency_symbol: Symbol for currency formatting.\n    :param precision: Decimal precision for numeric values.\n    :param include_header: Include ticker/points/frequency prefix.\n    :return: Summary narration.\n    \"\"\"\n    entity_name = summary.ticker or summary.column\n    prefix = f\"{entity_name} ({summary.points} pts, {summary.frequency}): \" if include_header else \"\"\n\n    line_1 = (\n        f\"{prefix}Range: [{_format_currency(summary.minimum, currency_symbol, precision)}, \"\n        f\"{_format_currency(summary.maximum, currency_symbol, precision)}]  \"\n        f\"Mean: {_format_currency(summary.mean, currency_symbol, precision)}  \"\n        f\"Std: {_format_currency(summary.std, currency_symbol, precision)}\"\n    )\n    line_2 = (\n        f\"Start: {_format_currency(summary.start, currency_symbol, precision)}  \"\n        f\"End: {_format_currency(summary.end, currency_symbol, precision)}  \"\n        f\"Change: {_format_change(summary.change_pct, precision)}\"\n    )\n\n    return f\"{line_1}\\n{line_2}\"\n</code></pre>"},{"location":"reference/narrata/#narrata.describe_support_resistance","title":"<code>describe_support_resistance(stats, currency_symbol='$', precision=2)</code>","text":"<p>Render support and resistance levels as one line.</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>LevelStats</code> <p>Support and resistance stats.</p> required <code>currency_symbol</code> <code>str</code> <p>Currency symbol for formatting.</p> <code>'$'</code> <code>precision</code> <code>int</code> <p>Decimal precision.</p> <code>2</code> <p>Returns:</p> Type Description <code>str</code> <p>Human-readable support/resistance narration.</p> Source code in <code>src/narrata/narrata/analysis/support_resistance.py</code> <pre><code>def describe_support_resistance(stats: LevelStats, currency_symbol: str = \"$\", precision: int = 2) -&gt; str:\n    \"\"\"Render support and resistance levels as one line.\n\n    :param stats: Support and resistance stats.\n    :param currency_symbol: Currency symbol for formatting.\n    :param precision: Decimal precision.\n    :return: Human-readable support/resistance narration.\n    \"\"\"\n    support_text = _format_levels(stats.supports, currency_symbol, precision)\n    resistance_text = _format_levels(stats.resistances, currency_symbol, precision)\n    return f\"Support: {support_text}  Resistance: {resistance_text}\"\n</code></pre>"},{"location":"reference/narrata/#narrata.find_support_resistance","title":"<code>find_support_resistance(df, column='Close', tolerance_ratio=0.01, max_levels=2, extrema_order=5)</code>","text":"<p>Detect support and resistance levels from local extrema and touch counts.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>column</code> <code>str</code> <p>Price column used for level detection.</p> <code>'Close'</code> <code>tolerance_ratio</code> <code>float</code> <p>Clustering tolerance as a price ratio.</p> <code>0.01</code> <code>max_levels</code> <code>int</code> <p>Max number of support and resistance levels to return.</p> <code>2</code> <code>extrema_order</code> <code>int</code> <p>Neighborhood size used by <code>argrelextrema</code>.</p> <code>5</code> <p>Returns:</p> Type Description <code>LevelStats</code> <p>Structured support and resistance levels.</p> Source code in <code>src/narrata/narrata/analysis/support_resistance.py</code> <pre><code>def find_support_resistance(\n    df: pd.DataFrame,\n    column: str = \"Close\",\n    tolerance_ratio: float = 0.01,\n    max_levels: int = 2,\n    extrema_order: int = 5,\n) -&gt; LevelStats:\n    \"\"\"Detect support and resistance levels from local extrema and touch counts.\n\n    :param df: OHLCV DataFrame.\n    :param column: Price column used for level detection.\n    :param tolerance_ratio: Clustering tolerance as a price ratio.\n    :param max_levels: Max number of support and resistance levels to return.\n    :param extrema_order: Neighborhood size used by ``argrelextrema``.\n    :return: Structured support and resistance levels.\n    \"\"\"\n    validate_ohlcv_frame(df)\n    if column not in df.columns:\n        raise ValidationError(f\"Column '{column}' does not exist in DataFrame.\")\n    if tolerance_ratio &lt;= 0.0:\n        raise ValidationError(\"tolerance_ratio must be &gt; 0.\")\n    if max_levels &lt; 1:\n        raise ValidationError(\"max_levels must be &gt;= 1.\")\n    if extrema_order &lt; 1:\n        raise ValidationError(\"extrema_order must be &gt;= 1.\")\n\n    prices = pd.to_numeric(df[column], errors=\"coerce\").dropna().to_numpy(dtype=float)\n    if prices.size &lt; extrema_order * 2 + 3:\n        raise ValidationError(\"Not enough data to find support/resistance.\")\n\n    minima_indices = argrelextrema(prices, np.less_equal, order=extrema_order)[0]\n    maxima_indices = argrelextrema(prices, np.greater_equal, order=extrema_order)[0]\n    current_price = float(prices[-1])\n    tolerance = max(current_price * tolerance_ratio, 1e-9)\n\n    support_values = [float(prices[idx]) for idx in minima_indices if prices[idx] &lt;= current_price]\n    resistance_values = [float(prices[idx]) for idx in maxima_indices if prices[idx] &gt;= current_price]\n\n    supports = _build_levels(\n        candidate_values=support_values,\n        extrema_values=np.asarray([prices[idx] for idx in minima_indices], dtype=float),\n        all_prices=prices,\n        tolerance=tolerance,\n        max_levels=max_levels,\n        reverse=True,\n    )\n    resistances = _build_levels(\n        candidate_values=resistance_values,\n        extrema_values=np.asarray([prices[idx] for idx in maxima_indices], dtype=float),\n        all_prices=prices,\n        tolerance=tolerance,\n        max_levels=max_levels,\n        reverse=False,\n    )\n\n    return LevelStats(supports=supports, resistances=resistances)\n</code></pre>"},{"location":"reference/narrata/#narrata.astride_encode","title":"<code>astride_encode(df, column='Close', n_segments=16, alphabet_size=8, penalty=3.0)</code>","text":"<p>Encode a series with ASTRIDE-style adaptive symbolization.</p> <p>Uses change-point detection (ruptures) to find segment boundaries that align with regime changes, then quantizes segment means into symbols. Unlike SAX, segments have variable length.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>column</code> <code>str</code> <p>Price column to encode.</p> <code>'Close'</code> <code>n_segments</code> <code>int</code> <p>Approximate number of segments.</p> <code>16</code> <code>alphabet_size</code> <code>int</code> <p>Number of symbols in alphabet.</p> <code>8</code> <code>penalty</code> <code>float</code> <p>Ruptures PELT penalty parameter.</p> <code>3.0</code> <p>Returns:</p> Type Description <code>SymbolicStats</code> <p>Structured symbolic encoding result.</p> Source code in <code>src/narrata/narrata/analysis/symbolic.py</code> <pre><code>def astride_encode(\n    df: pd.DataFrame,\n    column: str = \"Close\",\n    n_segments: int = 16,\n    alphabet_size: int = 8,\n    penalty: float = 3.0,\n) -&gt; SymbolicStats:\n    \"\"\"Encode a series with ASTRIDE-style adaptive symbolization.\n\n    Uses change-point detection (ruptures) to find segment boundaries that\n    align with regime changes, then quantizes segment means into symbols.\n    Unlike SAX, segments have variable length.\n\n    :param df: OHLCV DataFrame.\n    :param column: Price column to encode.\n    :param n_segments: Approximate number of segments.\n    :param alphabet_size: Number of symbols in alphabet.\n    :param penalty: Ruptures PELT penalty parameter.\n    :return: Structured symbolic encoding result.\n    \"\"\"\n    validate_ohlcv_frame(df)\n    if column not in df.columns:\n        raise ValidationError(f\"Column '{column}' does not exist in DataFrame.\")\n    if n_segments &lt; 2:\n        raise ValidationError(\"n_segments must be &gt;= 2.\")\n    if alphabet_size &lt; 2 or alphabet_size &gt; 26:\n        raise ValidationError(\"alphabet_size must be between 2 and 26.\")\n    if rpt is None:\n        raise ValidationError(\n            \"ASTRIDE encoding requires the 'ruptures' package. Install with: pip install narrata[symbolic]\"\n        )\n\n    values = pd.to_numeric(df[column], errors=\"coerce\").dropna().to_numpy(dtype=float)\n    if values.size &lt; n_segments:\n        raise ValidationError(\"Not enough data points for requested n_segments.\")\n\n    normalized = _z_normalize(values)\n    symbols = _astride_encode_core(normalized, n_segments=n_segments, alphabet_size=alphabet_size, penalty=penalty)\n\n    return SymbolicStats(\n        method=\"ASTRIDE\",\n        word_size=len(symbols),\n        alphabet_size=alphabet_size,\n        symbols=symbols,\n    )\n</code></pre>"},{"location":"reference/narrata/#narrata.describe_astride","title":"<code>describe_astride(stats)</code>","text":"<p>Render ASTRIDE symbolic encoding as one line.</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>SymbolicStats</code> <p>Symbolic encoding result.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Human-readable symbolic description.</p> Source code in <code>src/narrata/narrata/analysis/symbolic.py</code> <pre><code>def describe_astride(stats: SymbolicStats) -&gt; str:\n    \"\"\"Render ASTRIDE symbolic encoding as one line.\n\n    :param stats: Symbolic encoding result.\n    :return: Human-readable symbolic description.\n    \"\"\"\n    return f\"ASTRIDE({stats.word_size}): {stats.symbols}\"\n</code></pre>"},{"location":"reference/narrata/#narrata.describe_sax","title":"<code>describe_sax(stats)</code>","text":"<p>Render symbolic encoding as one line.</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>SymbolicStats</code> <p>Symbolic encoding result.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Human-readable symbolic description.</p> Source code in <code>src/narrata/narrata/analysis/symbolic.py</code> <pre><code>def describe_sax(stats: SymbolicStats) -&gt; str:\n    \"\"\"Render symbolic encoding as one line.\n\n    :param stats: Symbolic encoding result.\n    :return: Human-readable symbolic description.\n    \"\"\"\n    return f\"SAX({stats.word_size}): {stats.symbols}\"\n</code></pre>"},{"location":"reference/narrata/#narrata.sax_encode","title":"<code>sax_encode(df, column='Close', word_size=16, alphabet_size=8)</code>","text":"<p>Encode a series with SAX-style symbolization.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>column</code> <code>str</code> <p>Price column to encode.</p> <code>'Close'</code> <code>word_size</code> <code>int</code> <p>Number of PAA segments.</p> <code>16</code> <code>alphabet_size</code> <code>int</code> <p>Number of symbols in alphabet.</p> <code>8</code> <p>Returns:</p> Type Description <code>SymbolicStats</code> <p>Structured symbolic encoding result.</p> Source code in <code>src/narrata/narrata/analysis/symbolic.py</code> <pre><code>def sax_encode(df: pd.DataFrame, column: str = \"Close\", word_size: int = 16, alphabet_size: int = 8) -&gt; SymbolicStats:\n    \"\"\"Encode a series with SAX-style symbolization.\n\n    :param df: OHLCV DataFrame.\n    :param column: Price column to encode.\n    :param word_size: Number of PAA segments.\n    :param alphabet_size: Number of symbols in alphabet.\n    :return: Structured symbolic encoding result.\n    \"\"\"\n    validate_ohlcv_frame(df)\n    if column not in df.columns:\n        raise ValidationError(f\"Column '{column}' does not exist in DataFrame.\")\n    if word_size &lt; 2:\n        raise ValidationError(\"word_size must be &gt;= 2.\")\n    if alphabet_size &lt; 2 or alphabet_size &gt; 26:\n        raise ValidationError(\"alphabet_size must be between 2 and 26.\")\n\n    values = pd.to_numeric(df[column], errors=\"coerce\").dropna().to_numpy(dtype=float)\n    if values.size &lt; word_size:\n        raise ValidationError(\"Not enough data points for requested word_size.\")\n\n    if SymbolicAggregateApproximation is not None:\n        symbols = _sax_encode_with_tslearn(\n            values=values,\n            word_size=word_size,\n            alphabet_size=alphabet_size,\n            sax_cls=SymbolicAggregateApproximation,\n        )\n    else:\n        symbols = _sax_encode_inhouse(values=values, word_size=word_size, alphabet_size=alphabet_size)\n\n    return SymbolicStats(\n        method=\"SAX\",\n        word_size=word_size,\n        alphabet_size=alphabet_size,\n        symbols=symbols,\n    )\n</code></pre>"},{"location":"reference/narrata/#narrata.narrate","title":"<code>narrate(df, *, column='Close', ticker=None, include_summary=True, include_sparkline=True, include_regime=True, include_indicators=True, include_symbolic=True, include_patterns=True, include_support_resistance=True, sparkline_width=20, symbolic_word_size=16, symbolic_alphabet_size=8, digit_level=False, output_format='plain')</code>","text":"<p>Compose selected narration components into one final text output.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>column</code> <code>str</code> <p>Price column used across modules.</p> <code>'Close'</code> <code>ticker</code> <code>str | None</code> <p>Optional ticker override.</p> <code>None</code> <code>include_summary</code> <code>bool</code> <p>Include summary lines.</p> <code>True</code> <code>include_sparkline</code> <code>bool</code> <p>Include sparkline in overview line.</p> <code>True</code> <code>include_regime</code> <code>bool</code> <p>Include regime classification line.</p> <code>True</code> <code>include_indicators</code> <code>bool</code> <p>Include indicators line.</p> <code>True</code> <code>include_symbolic</code> <code>bool</code> <p>Include SAX line.</p> <code>True</code> <code>include_patterns</code> <code>bool</code> <p>Include chart and candlestick pattern lines.</p> <code>True</code> <code>include_support_resistance</code> <code>bool</code> <p>Include support/resistance line.</p> <code>True</code> <code>sparkline_width</code> <code>int</code> <p>Sparkline width.</p> <code>20</code> <code>symbolic_word_size</code> <code>int</code> <p>SAX word size.</p> <code>16</code> <code>symbolic_alphabet_size</code> <code>int</code> <p>SAX alphabet size.</p> <code>8</code> <code>digit_level</code> <code>bool</code> <p>Apply digit-level tokenization to final text.</p> <code>False</code> <code>output_format</code> <code>OutputFormat</code> <p>Output format.</p> <code>'plain'</code> <p>Returns:</p> Type Description <code>str</code> <p>Composed narration text.</p> Source code in <code>src/narrata/narrata/composition/narrate.py</code> <pre><code>def narrate(\n    df: pd.DataFrame,\n    *,\n    column: str = \"Close\",\n    ticker: str | None = None,\n    include_summary: bool = True,\n    include_sparkline: bool = True,\n    include_regime: bool = True,\n    include_indicators: bool = True,\n    include_symbolic: bool = True,\n    include_patterns: bool = True,\n    include_support_resistance: bool = True,\n    sparkline_width: int = 20,\n    symbolic_word_size: int = 16,\n    symbolic_alphabet_size: int = 8,\n    digit_level: bool = False,\n    output_format: OutputFormat = \"plain\",\n) -&gt; str:\n    \"\"\"Compose selected narration components into one final text output.\n\n    :param df: OHLCV DataFrame.\n    :param column: Price column used across modules.\n    :param ticker: Optional ticker override.\n    :param include_summary: Include summary lines.\n    :param include_sparkline: Include sparkline in overview line.\n    :param include_regime: Include regime classification line.\n    :param include_indicators: Include indicators line.\n    :param include_symbolic: Include SAX line.\n    :param include_patterns: Include chart and candlestick pattern lines.\n    :param include_support_resistance: Include support/resistance line.\n    :param sparkline_width: Sparkline width.\n    :param symbolic_word_size: SAX word size.\n    :param symbolic_alphabet_size: SAX alphabet size.\n    :param digit_level: Apply digit-level tokenization to final text.\n    :param output_format: Output format.\n    :return: Composed narration text.\n    \"\"\"\n    validate_ohlcv_frame(df)\n\n    if column not in df.columns:\n        raise ValidationError(f\"Column '{column}' does not exist in DataFrame.\")\n\n    if not any(\n        [\n            include_summary,\n            include_sparkline,\n            include_regime,\n            include_indicators,\n            include_symbolic,\n            include_patterns,\n            include_support_resistance,\n        ]\n    ):\n        raise ValidationError(\"At least one narration component must be enabled.\")\n\n    sections: dict[str, str] = {}\n    summary = analyze_summary(df, column=column, ticker=ticker)\n\n    if include_summary or include_sparkline:\n        entity_name = summary.ticker or summary.column\n        if include_sparkline:\n            values = pd.to_numeric(df[column], errors=\"coerce\").dropna().tolist()\n            if not values:\n                raise ValidationError(f\"Column '{column}' contains no numeric values for sparkline rendering.\")\n            sparkline = make_sparkline(values, width=sparkline_width)\n            sections[\"overview\"] = f\"{entity_name} ({summary.points} pts, {summary.frequency}): {sparkline}\"\n        else:\n            sections[\"overview\"] = f\"{entity_name} ({summary.points} pts, {summary.frequency})\"\n\n    if include_summary:\n        sections[\"date_range\"] = f\"Date range: {summary.start_date.isoformat()} to {summary.end_date.isoformat()}\"\n        summary_lines = describe_summary(summary, include_header=False).splitlines()\n        sections[\"range\"] = summary_lines[0]\n        sections[\"change\"] = summary_lines[1]\n\n    if include_regime:\n        sections[\"regime\"] = describe_regime(analyze_regime(df, column=column))\n\n    if include_indicators:\n        sections[\"indicators\"] = describe_indicators(analyze_indicators(df, column=column))\n\n    if include_symbolic:\n        symbolic = sax_encode(df, column=column, word_size=symbolic_word_size, alphabet_size=symbolic_alphabet_size)\n        sections[\"symbolic\"] = describe_sax(symbolic)\n\n    if include_patterns:\n        pattern_stats = detect_patterns(df)\n        sections[\"patterns\"] = describe_patterns(pattern_stats)\n        sections[\"candlestick\"] = describe_candlestick(pattern_stats)\n\n    if include_support_resistance:\n        levels = find_support_resistance(df, column=column)\n        sections[\"levels\"] = describe_support_resistance(levels)\n\n    rendered = format_sections(sections, output_format=output_format)\n    if digit_level:\n        return digit_tokenize(rendered)\n\n    return rendered\n</code></pre>"},{"location":"reference/narrata/#narrata.digit_tokenize","title":"<code>digit_tokenize(text, add_note=True)</code>","text":"<p>Split every digit into standalone tokens separated by spaces.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Input text.</p> required <code>add_note</code> <code>bool</code> <p>Prefix output with a short marker when digit splitting is applied.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>Digit-tokenized text.</p> Source code in <code>src/narrata/narrata/compression/digits.py</code> <pre><code>def digit_tokenize(text: str, add_note: bool = True) -&gt; str:\n    \"\"\"Split every digit into standalone tokens separated by spaces.\n\n    :param text: Input text.\n    :param add_note: Prefix output with a short marker when digit splitting is applied.\n    :return: Digit-tokenized text.\n    \"\"\"\n    spaced = _DIGIT_PATTERN.sub(r\" \\1 \", text)\n    tokenized = \" \".join(spaced.split())\n    if add_note:\n        return f\"&lt;digits-split&gt;\\n{tokenized}\"\n    return tokenized\n</code></pre>"},{"location":"reference/narrata/#narrata.format_sections","title":"<code>format_sections(sections, output_format='plain')</code>","text":"<p>Format narration sections for the selected output format.</p> <p>Parameters:</p> Name Type Description Default <code>sections</code> <code>Mapping[str, str]</code> <p>Ordered mapping of section keys to rendered text.</p> required <code>output_format</code> <code>OutputFormat</code> <p>Output format selector.</p> <code>'plain'</code> <p>Returns:</p> Type Description <code>str</code> <p>Serialized text output.</p> Source code in <code>src/narrata/narrata/formatting/serializers.py</code> <pre><code>def format_sections(sections: Mapping[str, str], output_format: OutputFormat = \"plain\") -&gt; str:\n    \"\"\"Format narration sections for the selected output format.\n\n    :param sections: Ordered mapping of section keys to rendered text.\n    :param output_format: Output format selector.\n    :return: Serialized text output.\n    \"\"\"\n    if output_format == \"plain\":\n        return to_plain(list(sections.values()))\n    if output_format == \"markdown_kv\":\n        return to_markdown_kv(sections)\n    if output_format == \"toon\":\n        return to_toon(sections)\n    raise UnsupportedFormatError(f\"Unsupported output format: {output_format}\")\n</code></pre>"},{"location":"reference/narrata/#narrata.to_markdown_kv","title":"<code>to_markdown_kv(data)</code>","text":"<p>Serialize key-value pairs as Markdown.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Mapping[str, object]</code> <p>Mapping of section names to values.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Markdown key-value representation.</p> Source code in <code>src/narrata/narrata/formatting/serializers.py</code> <pre><code>def to_markdown_kv(data: Mapping[str, object]) -&gt; str:\n    \"\"\"Serialize key-value pairs as Markdown.\n\n    :param data: Mapping of section names to values.\n    :return: Markdown key-value representation.\n    \"\"\"\n    return \"\\n\".join(f\"**{key}**: {value}\" for key, value in data.items())\n</code></pre>"},{"location":"reference/narrata/#narrata.to_plain","title":"<code>to_plain(lines)</code>","text":"<p>Join non-empty lines into plain-text output.</p> <p>Parameters:</p> Name Type Description Default <code>lines</code> <code>Sequence[str]</code> <p>Ordered lines to join.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Plain-text representation.</p> Source code in <code>src/narrata/narrata/formatting/serializers.py</code> <pre><code>def to_plain(lines: Sequence[str]) -&gt; str:\n    \"\"\"Join non-empty lines into plain-text output.\n\n    :param lines: Ordered lines to join.\n    :return: Plain-text representation.\n    \"\"\"\n    return \"\\n\".join(line for line in lines if line)\n</code></pre>"},{"location":"reference/narrata/#narrata.to_toon","title":"<code>to_toon(data)</code>","text":"<p>Serialize mappings to TOON.</p> <p>Requires the <code>toons</code> package.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Mapping[str, object]</code> <p>Mapping of section names to values.</p> required <p>Returns:</p> Type Description <code>str</code> <p>TOON string representation.</p> Source code in <code>src/narrata/narrata/formatting/serializers.py</code> <pre><code>def to_toon(data: Mapping[str, object]) -&gt; str:\n    \"\"\"Serialize mappings to TOON.\n\n    Requires the ``toons`` package.\n\n    :param data: Mapping of section names to values.\n    :return: TOON string representation.\n    \"\"\"\n    return str(dumps(dict(data)))\n</code></pre>"},{"location":"reference/narrata/#narrata.make_sparkline","title":"<code>make_sparkline(values, width=20, bars=BARS)</code>","text":"<p>Create a single-line Unicode sparkline.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Sequence[float]</code> <p>Input numeric sequence.</p> required <code>width</code> <code>int</code> <p>Max number of output glyphs.</p> <code>20</code> <code>bars</code> <code>str</code> <p>Glyph palette from low to high.</p> <code>BARS</code> <p>Returns:</p> Type Description <code>str</code> <p>Sparkline string.</p> Source code in <code>src/narrata/narrata/rendering/sparkline.py</code> <pre><code>def make_sparkline(values: Sequence[float], width: int = 20, bars: str = BARS) -&gt; str:\n    \"\"\"Create a single-line Unicode sparkline.\n\n    :param values: Input numeric sequence.\n    :param width: Max number of output glyphs.\n    :param bars: Glyph palette from low to high.\n    :return: Sparkline string.\n    \"\"\"\n    if len(bars) &lt; 2:\n        raise ValueError(\"bars must have at least two characters\")\n\n    sampled = downsample_evenly(values, width=width)\n    if not sampled:\n        return \"\"\n\n    bins = normalize_to_bins(sampled, bins=len(bars))\n    return \"\".join(bars[index] for index in bins)\n</code></pre>"},{"location":"reference/narrata/#narrata.infer_frequency_label","title":"<code>infer_frequency_label(index)</code>","text":"<p>Infer a user-facing frequency label from a DatetimeIndex.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>DatetimeIndex</code> <p>Datetime index.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Inferred frequency label.</p> Source code in <code>src/narrata/narrata/validation/ohlcv.py</code> <pre><code>def infer_frequency_label(index: pd.DatetimeIndex) -&gt; str:\n    \"\"\"Infer a user-facing frequency label from a DatetimeIndex.\n\n    :param index: Datetime index.\n    :return: Inferred frequency label.\n    \"\"\"\n    if len(index) &lt; 2:\n        return \"irregular\"\n\n    inferred = pd.infer_freq(index)\n    if inferred:\n        key = str(inferred).split(\"-\")[0]\n        return _FREQUENCY_LABELS.get(key, key.lower())\n\n    deltas = index.to_series().diff().dropna()\n    if deltas.empty:\n        return \"irregular\"\n\n    median_seconds = float(deltas.dt.total_seconds().median())\n\n    if median_seconds &lt;= 3600:\n        return \"hourly\"\n    if median_seconds &lt;= 86_400:\n        return \"daily\"\n    if median_seconds &lt;= 86_400 * 7:\n        return \"weekly\"\n    if median_seconds &lt;= 86_400 * 31:\n        return \"monthly\"\n    return \"irregular\"\n</code></pre>"},{"location":"reference/narrata/#narrata.validate_ohlcv_frame","title":"<code>validate_ohlcv_frame(df, required_columns=REQUIRED_OHLCV_COLUMNS)</code>","text":"<p>Validate basic OHLCV and index contracts expected by narrata.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame to validate.</p> required <code>required_columns</code> <code>Sequence[str]</code> <p>Required OHLCV columns.</p> <code>REQUIRED_OHLCV_COLUMNS</code> <p>Returns:</p> Type Description <code>None</code> <p><code>None</code> if validation passes.</p> Source code in <code>src/narrata/narrata/validation/ohlcv.py</code> <pre><code>def validate_ohlcv_frame(df: pd.DataFrame, required_columns: Sequence[str] = REQUIRED_OHLCV_COLUMNS) -&gt; None:\n    \"\"\"Validate basic OHLCV and index contracts expected by narrata.\n\n    :param df: Input DataFrame to validate.\n    :param required_columns: Required OHLCV columns.\n    :return: ``None`` if validation passes.\n    \"\"\"\n    if isinstance(df, pd.DataFrame) and df.attrs.get(_VALIDATED_ATTR):\n        return\n\n    if not isinstance(df, pd.DataFrame):\n        raise ValidationError(\"Input must be a pandas DataFrame.\")\n\n    if df.empty:\n        raise ValidationError(\"Input DataFrame must not be empty.\")\n\n    if isinstance(df.index, pd.MultiIndex):\n        raise ValidationError(\n            \"MultiIndex input is not supported. For stacked multi-ticker data, \"\n            \"split by ticker and call narrate per symbol.\"\n        )\n\n    if not isinstance(df.index, pd.DatetimeIndex):\n        raise ValidationError(\"DataFrame index must be a pandas DatetimeIndex.\")\n\n    if df.index.has_duplicates:\n        raise ValidationError(\"DataFrame index must not contain duplicate timestamps.\")\n\n    if not df.index.is_monotonic_increasing:\n        raise ValidationError(\"DataFrame index must be sorted in ascending order.\")\n\n    missing_columns = [name for name in required_columns if name not in df.columns]\n    if missing_columns:\n        joined = \", \".join(missing_columns)\n        raise ValidationError(f\"DataFrame is missing required columns: {joined}.\")\n\n    df.attrs[_VALIDATED_ATTR] = True\n</code></pre>"},{"location":"reference/narrata/analysis/","title":"analysis","text":""},{"location":"reference/narrata/analysis/#narrata.analysis","title":"<code>narrata.analysis</code>","text":"<p>Numerical analysis primitives for narrata.</p>"},{"location":"reference/narrata/analysis/#narrata.analysis.analyze_indicators","title":"<code>analyze_indicators(df, column='Close', rsi_period=14)</code>","text":"<p>Analyze RSI, MACD, Bollinger Bands, MA crossovers, volume, and volatility.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>column</code> <code>str</code> <p>Price column to analyze.</p> <code>'Close'</code> <code>rsi_period</code> <code>int</code> <p>RSI period.</p> <code>14</code> <p>Returns:</p> Type Description <code>IndicatorStats</code> <p>Structured indicator statistics.</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def analyze_indicators(df: pd.DataFrame, column: str = \"Close\", rsi_period: int = 14) -&gt; IndicatorStats:\n    \"\"\"Analyze RSI, MACD, Bollinger Bands, MA crossovers, volume, and volatility.\n\n    :param df: OHLCV DataFrame.\n    :param column: Price column to analyze.\n    :param rsi_period: RSI period.\n    :return: Structured indicator statistics.\n    \"\"\"\n    validate_ohlcv_frame(df)\n    if column not in df.columns:\n        raise ValidationError(f\"Column '{column}' does not exist in DataFrame.\")\n\n    values = pd.to_numeric(df[column], errors=\"coerce\").dropna()\n    if ta is None:\n        rsi_value = compute_rsi(values, period=rsi_period)\n        macd_value, signal_value, histogram = compute_macd(values)\n        macd_state, crossover_days = _classify_macd(values)\n    else:\n        rsi_value = _compute_rsi_with_pandas_ta(values, period=rsi_period)\n        macd_value, signal_value, histogram, macd_state, crossover_days = _compute_macd_with_pandas_ta(values)\n\n    rsi_state = _classify_rsi(values, rsi_value)\n\n    bb_position: str | None = None\n    bb_squeeze: bool | None = None\n    try:\n        bb_position, bb_squeeze = compute_bollinger(values)\n    except ValidationError:\n        pass\n\n    ma_cross: str | None = None\n    ma_cross_days: int | None = None\n    try:\n        ma_cross, ma_cross_days = compute_ma_crossover(values)\n    except ValidationError:\n        pass\n\n    volume_ratio: float | None = None\n    volume_state: str | None = None\n    try:\n        volume_ratio, volume_state = compute_volume_state(df)\n    except ValidationError:\n        pass\n\n    vol_pct: float | None = None\n    vol_state: str | None = None\n    try:\n        vol_pct, vol_state = compute_volatility_percentile(values)\n    except ValidationError:\n        pass\n\n    return IndicatorStats(\n        rsi_period=rsi_period,\n        rsi_value=rsi_value,\n        rsi_state=rsi_state,\n        macd_value=macd_value,\n        macd_signal=signal_value,\n        macd_histogram=histogram,\n        macd_state=macd_state,\n        crossover_days_ago=crossover_days,\n        bb_position=bb_position,\n        bb_squeeze=bb_squeeze,\n        ma_cross=ma_cross,\n        ma_cross_days_ago=ma_cross_days,\n        volume_ratio=volume_ratio,\n        volume_state=volume_state,\n        volatility_percentile=vol_pct,\n        volatility_state=vol_state,\n    )\n</code></pre>"},{"location":"reference/narrata/analysis/#narrata.analysis.compute_bollinger","title":"<code>compute_bollinger(series, period=20, num_std=2.0)</code>","text":"<p>Compute Bollinger Band position and squeeze state.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>Price series.</p> required <code>period</code> <code>int</code> <p>Bollinger Band period.</p> <code>20</code> <code>num_std</code> <code>float</code> <p>Number of standard deviations for band width.</p> <code>2.0</code> <p>Returns:</p> Type Description <code>tuple[str, bool]</code> <p>Tuple of (position label, squeeze detected).</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def compute_bollinger(series: pd.Series, period: int = 20, num_std: float = 2.0) -&gt; tuple[str, bool]:\n    \"\"\"Compute Bollinger Band position and squeeze state.\n\n    :param series: Price series.\n    :param period: Bollinger Band period.\n    :param num_std: Number of standard deviations for band width.\n    :return: Tuple of (position label, squeeze detected).\n    \"\"\"\n    values = pd.to_numeric(series, errors=\"coerce\").dropna()\n    if values.size &lt; period:\n        raise ValidationError(\"Not enough data to compute Bollinger Bands.\")\n\n    sma = values.rolling(window=period).mean()\n    std = values.rolling(window=period).std(ddof=0)\n    upper = sma + num_std * std\n    lower = sma - num_std * std\n    bandwidth = ((upper - lower) / sma).dropna()\n\n    latest_price = float(values.iloc[-1])\n    latest_upper = float(upper.iloc[-1])\n    latest_lower = float(lower.iloc[-1])\n    latest_sma = float(sma.iloc[-1])\n\n    if latest_upper == latest_lower:\n        position = \"at midline\"\n    else:\n        pct = (latest_price - latest_lower) / (latest_upper - latest_lower)\n        if pct &gt;= 0.95:\n            position = \"above upper band\"\n        elif pct &gt;= 0.80:\n            position = \"near upper band\"\n        elif pct &lt;= 0.05:\n            position = \"below lower band\"\n        elif pct &lt;= 0.20:\n            position = \"near lower band\"\n        elif latest_price &gt; latest_sma:\n            position = \"upper half\"\n        else:\n            position = \"lower half\"\n\n    squeeze = False\n    if bandwidth.size &gt;= period:\n        recent_bw = float(bandwidth.iloc[-1])\n        lookback_bw = float(bandwidth.iloc[-period:].quantile(0.20))\n        squeeze = recent_bw &lt;= lookback_bw\n\n    return position, squeeze\n</code></pre>"},{"location":"reference/narrata/analysis/#narrata.analysis.compute_ma_crossover","title":"<code>compute_ma_crossover(series, fast_period=50, slow_period=200)</code>","text":"<p>Detect moving average crossover (golden/death cross).</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>Price series.</p> required <code>fast_period</code> <code>int</code> <p>Fast SMA period.</p> <code>50</code> <code>slow_period</code> <code>int</code> <p>Slow SMA period.</p> <code>200</code> <p>Returns:</p> Type Description <code>tuple[str | None, int | None]</code> <p>Tuple of (cross type or None, days since cross or None).</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def compute_ma_crossover(\n    series: pd.Series, fast_period: int = 50, slow_period: int = 200\n) -&gt; tuple[str | None, int | None]:\n    \"\"\"Detect moving average crossover (golden/death cross).\n\n    :param series: Price series.\n    :param fast_period: Fast SMA period.\n    :param slow_period: Slow SMA period.\n    :return: Tuple of (cross type or None, days since cross or None).\n    \"\"\"\n    values = pd.to_numeric(series, errors=\"coerce\").dropna()\n    if values.size &lt; slow_period + 1:\n        return None, None\n\n    fast_sma = values.rolling(window=fast_period).mean()\n    slow_sma = values.rolling(window=slow_period).mean()\n    diff = (fast_sma - slow_sma).dropna()\n    if diff.size &lt; 2:\n        return None, None\n\n    signs = np.sign(diff.to_numpy())\n    current = \"golden cross\" if signs[-1] &gt;= 0.0 else \"death cross\"\n\n    for idx in range(signs.size - 1, 0, -1):\n        if signs[idx] != signs[idx - 1] and signs[idx] != 0.0 and signs[idx - 1] != 0.0:\n            days_ago = signs.size - 1 - idx\n            return current, days_ago\n\n    return current, None\n</code></pre>"},{"location":"reference/narrata/analysis/#narrata.analysis.compute_macd","title":"<code>compute_macd(series, fast_period=12, slow_period=26, signal_period=9)</code>","text":"<p>Compute MACD values for the latest sample.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>Price series.</p> required <code>fast_period</code> <code>int</code> <p>Fast EMA period.</p> <code>12</code> <code>slow_period</code> <code>int</code> <p>Slow EMA period.</p> <code>26</code> <code>signal_period</code> <code>int</code> <p>Signal EMA period.</p> <code>9</code> <p>Returns:</p> Type Description <code>tuple[float, float, float]</code> <p>Tuple of (macd_line, signal_line, histogram).</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def compute_macd(\n    series: pd.Series, fast_period: int = 12, slow_period: int = 26, signal_period: int = 9\n) -&gt; tuple[float, float, float]:\n    \"\"\"Compute MACD values for the latest sample.\n\n    :param series: Price series.\n    :param fast_period: Fast EMA period.\n    :param slow_period: Slow EMA period.\n    :param signal_period: Signal EMA period.\n    :return: Tuple of (macd_line, signal_line, histogram).\n    \"\"\"\n    if fast_period &gt;= slow_period:\n        raise ValidationError(\"fast_period must be smaller than slow_period.\")\n\n    values = pd.to_numeric(series, errors=\"coerce\").dropna()\n    if values.size &lt; slow_period + signal_period:\n        raise ValidationError(\"Not enough data to compute MACD.\")\n\n    fast_ema = values.ewm(span=fast_period, adjust=False).mean()\n    slow_ema = values.ewm(span=slow_period, adjust=False).mean()\n    macd_line = fast_ema - slow_ema\n    signal_line = macd_line.ewm(span=signal_period, adjust=False).mean()\n    histogram = macd_line - signal_line\n\n    return float(macd_line.iloc[-1]), float(signal_line.iloc[-1]), float(histogram.iloc[-1])\n</code></pre>"},{"location":"reference/narrata/analysis/#narrata.analysis.compute_rsi","title":"<code>compute_rsi(series, period=14)</code>","text":"<p>Compute RSI using Wilder-style exponential smoothing.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>Price series.</p> required <code>period</code> <code>int</code> <p>RSI period length.</p> <code>14</code> <p>Returns:</p> Type Description <code>float</code> <p>Latest RSI value.</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def compute_rsi(series: pd.Series, period: int = 14) -&gt; float:\n    \"\"\"Compute RSI using Wilder-style exponential smoothing.\n\n    :param series: Price series.\n    :param period: RSI period length.\n    :return: Latest RSI value.\n    \"\"\"\n    if period &lt; 2:\n        raise ValidationError(\"RSI period must be &gt;= 2.\")\n\n    values = pd.to_numeric(series, errors=\"coerce\").dropna()\n    if values.size &lt; period + 1:\n        raise ValidationError(\"Not enough data to compute RSI.\")\n\n    delta = values.diff()\n    gains = delta.clip(lower=0.0)\n    losses = -delta.clip(upper=0.0)\n    avg_gain = gains.ewm(alpha=1.0 / period, adjust=False).mean()\n    avg_loss = losses.ewm(alpha=1.0 / period, adjust=False).mean()\n    rs = avg_gain / avg_loss.replace(0.0, np.nan)\n    rsi = 100.0 - (100.0 / (1.0 + rs))\n\n    latest = float(rsi.iloc[-1]) if not np.isnan(rsi.iloc[-1]) else 100.0\n    return max(0.0, min(100.0, latest))\n</code></pre>"},{"location":"reference/narrata/analysis/#narrata.analysis.compute_volatility_percentile","title":"<code>compute_volatility_percentile(series, window=20, lookback=252)</code>","text":"<p>Compute historical volatility percentile rank.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>Price series.</p> required <code>window</code> <code>int</code> <p>Rolling window for volatility calculation.</p> <code>20</code> <code>lookback</code> <code>int</code> <p>Lookback period for percentile ranking.</p> <code>252</code> <p>Returns:</p> Type Description <code>tuple[float, str]</code> <p>Tuple of (percentile 0-100, state label).</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def compute_volatility_percentile(series: pd.Series, window: int = 20, lookback: int = 252) -&gt; tuple[float, str]:\n    \"\"\"Compute historical volatility percentile rank.\n\n    :param series: Price series.\n    :param window: Rolling window for volatility calculation.\n    :param lookback: Lookback period for percentile ranking.\n    :return: Tuple of (percentile 0-100, state label).\n    \"\"\"\n    values = pd.to_numeric(series, errors=\"coerce\").dropna()\n    if values.size &lt; window + 2:\n        raise ValidationError(\"Not enough data to compute volatility percentile.\")\n\n    returns = values.pct_change().dropna()\n    rolling_vol = returns.rolling(window=window).std(ddof=0).dropna()\n    if rolling_vol.empty:\n        raise ValidationError(\"Not enough data to compute volatility percentile.\")\n\n    current_vol = float(rolling_vol.iloc[-1])\n    rank_window = rolling_vol.tail(min(lookback, rolling_vol.size))\n    percentile = float((rank_window &lt;= current_vol).sum() / rank_window.size * 100.0)\n    percentile = round(percentile, 0)\n\n    if percentile &lt;= 10:\n        state = \"extremely low\"\n    elif percentile &lt;= 25:\n        state = \"low\"\n    elif percentile &gt;= 90:\n        state = \"extremely high\"\n    elif percentile &gt;= 75:\n        state = \"high\"\n    else:\n        state = \"moderate\"\n\n    return percentile, state\n</code></pre>"},{"location":"reference/narrata/analysis/#narrata.analysis.compute_volume_state","title":"<code>compute_volume_state(df, lookback=20)</code>","text":"<p>Compute volume ratio to N-day moving average and classify.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame with Volume column.</p> required <code>lookback</code> <code>int</code> <p>Moving average lookback period.</p> <code>20</code> <p>Returns:</p> Type Description <code>tuple[float, str]</code> <p>Tuple of (ratio to average, state label).</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def compute_volume_state(df: pd.DataFrame, lookback: int = 20) -&gt; tuple[float, str]:\n    \"\"\"Compute volume ratio to N-day moving average and classify.\n\n    :param df: OHLCV DataFrame with Volume column.\n    :param lookback: Moving average lookback period.\n    :return: Tuple of (ratio to average, state label).\n    \"\"\"\n    if \"Volume\" not in df.columns:\n        raise ValidationError(\"DataFrame must contain Volume column.\")\n\n    volume = pd.to_numeric(df[\"Volume\"], errors=\"coerce\").dropna()\n    if volume.size &lt; lookback + 1:\n        raise ValidationError(\"Not enough data to compute volume state.\")\n\n    avg = float(volume.rolling(window=lookback).mean().iloc[-1])\n    if avg &lt;= 0.0:\n        return 1.0, \"average\"\n\n    latest = float(volume.iloc[-1])\n    ratio = latest / avg\n\n    if ratio &gt;= 2.0:\n        state = \"unusually high\"\n    elif ratio &gt;= 1.5:\n        state = \"above average\"\n    elif ratio &lt;= 0.5:\n        state = \"unusually low\"\n    elif ratio &lt;= 0.75:\n        state = \"below average\"\n    else:\n        state = \"average\"\n\n    return round(ratio, 2), state\n</code></pre>"},{"location":"reference/narrata/analysis/#narrata.analysis.describe_indicators","title":"<code>describe_indicators(stats)</code>","text":"<p>Render indicator statistics as concise narration lines.</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>IndicatorStats</code> <p>Indicator statistics.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Human-readable indicator narration.</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def describe_indicators(stats: IndicatorStats) -&gt; str:\n    \"\"\"Render indicator statistics as concise narration lines.\n\n    :param stats: Indicator statistics.\n    :return: Human-readable indicator narration.\n    \"\"\"\n    rsi_part = f\"RSI({stats.rsi_period}): {stats.rsi_value:.1f} ({stats.rsi_state})\"\n\n    if stats.crossover_days_ago is None:\n        macd_part = f\"MACD: {stats.macd_state}\"\n    else:\n        unit = \"day\" if stats.crossover_days_ago == 1 else \"days\"\n        macd_part = f\"MACD: {stats.macd_state} crossover {stats.crossover_days_ago} {unit} ago\"\n\n    parts = [f\"{rsi_part}  {macd_part}\"]\n\n    if stats.bb_position is not None:\n        bb_text = f\"BB: {stats.bb_position}\"\n        if stats.bb_squeeze:\n            bb_text += \" (squeeze)\"\n        parts.append(bb_text)\n\n    if stats.ma_cross is not None:\n        if stats.ma_cross_days_ago is not None:\n            unit = \"day\" if stats.ma_cross_days_ago == 1 else \"days\"\n            parts.append(f\"SMA 50/200: {stats.ma_cross} {stats.ma_cross_days_ago} {unit} ago\")\n        else:\n            parts.append(f\"SMA 50/200: {stats.ma_cross}\")\n\n    if stats.volume_ratio is not None and stats.volume_state is not None:\n        parts.append(f\"Volume: {stats.volume_ratio}x 20-day avg ({stats.volume_state})\")\n\n    if stats.volatility_percentile is not None and stats.volatility_state is not None:\n        percentile = _format_ordinal(stats.volatility_percentile)\n        parts.append(f\"Volatility: {percentile} percentile ({stats.volatility_state})\")\n\n    return \"\\n\".join(parts)\n</code></pre>"},{"location":"reference/narrata/analysis/#narrata.analysis.describe_candlestick","title":"<code>describe_candlestick(stats)</code>","text":"<p>Render candlestick line.</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>PatternStats</code> <p>Pattern detection results.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Human-readable candlestick narration.</p> Source code in <code>src/narrata/narrata/analysis/patterns.py</code> <pre><code>def describe_candlestick(stats: PatternStats) -&gt; str:\n    \"\"\"Render candlestick line.\n\n    :param stats: Pattern detection results.\n    :return: Human-readable candlestick narration.\n    \"\"\"\n    if stats.candlestick_pattern is None or stats.candlestick_date is None:\n        return \"Candlestick: none detected\"\n    return f\"Candlestick: {stats.candlestick_pattern} on {stats.candlestick_date.isoformat()}\"\n</code></pre>"},{"location":"reference/narrata/analysis/#narrata.analysis.describe_patterns","title":"<code>describe_patterns(stats)</code>","text":"<p>Render chart pattern line.</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>PatternStats</code> <p>Pattern detection results.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Human-readable chart pattern narration.</p> Source code in <code>src/narrata/narrata/analysis/patterns.py</code> <pre><code>def describe_patterns(stats: PatternStats) -&gt; str:\n    \"\"\"Render chart pattern line.\n\n    :param stats: Pattern detection results.\n    :return: Human-readable chart pattern narration.\n    \"\"\"\n    if stats.chart_pattern is None or stats.chart_pattern_since is None:\n        return \"Patterns: none detected\"\n    return f\"Patterns: {stats.chart_pattern} forming since {stats.chart_pattern_since.isoformat()}\"\n</code></pre>"},{"location":"reference/narrata/analysis/#narrata.analysis.detect_candlestick_pattern","title":"<code>detect_candlestick_pattern(df)</code>","text":"<p>Detect candlestick patterns using optional backend and in-house fallback.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <p>Returns:</p> Type Description <code>tuple[str | None, date | None]</code> <p>Candlestick pattern name and timestamp if detected.</p> Source code in <code>src/narrata/narrata/analysis/patterns.py</code> <pre><code>def detect_candlestick_pattern(df: pd.DataFrame) -&gt; tuple[str | None, date | None]:\n    \"\"\"Detect candlestick patterns using optional backend and in-house fallback.\n\n    :param df: OHLCV DataFrame.\n    :return: Candlestick pattern name and timestamp if detected.\n    \"\"\"\n    for column in (\"Open\", \"Close\"):\n        if column not in df.columns:\n            raise ValidationError(\"DataFrame must contain Open and Close columns.\")\n    if df.shape[0] &lt; 2:\n        return None, None\n\n    if ta is not None and \"High\" in df.columns and \"Low\" in df.columns:\n        detected = _detect_candlestick_with_pandas_ta(df)\n        if detected[0] is not None:\n            return detected\n\n    return _detect_candlestick_inhouse(df)\n</code></pre>"},{"location":"reference/narrata/analysis/#narrata.analysis.detect_chart_pattern","title":"<code>detect_chart_pattern(df, lookback=60)</code>","text":"<p>Detect simple chart patterns from highs and lows.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>lookback</code> <code>int</code> <p>Number of recent rows to inspect.</p> <code>60</code> <p>Returns:</p> Type Description <code>tuple[str | None, date | None]</code> <p>Pattern name and starting timestamp if detected.</p> Source code in <code>src/narrata/narrata/analysis/patterns.py</code> <pre><code>def detect_chart_pattern(df: pd.DataFrame, lookback: int = 60) -&gt; tuple[str | None, date | None]:\n    \"\"\"Detect simple chart patterns from highs and lows.\n\n    :param df: OHLCV DataFrame.\n    :param lookback: Number of recent rows to inspect.\n    :return: Pattern name and starting timestamp if detected.\n    \"\"\"\n    if \"High\" not in df.columns or \"Low\" not in df.columns or \"Close\" not in df.columns:\n        raise ValidationError(\"DataFrame must contain High, Low and Close columns.\")\n\n    window = df.tail(lookback).copy()\n    highs = pd.to_numeric(window[\"High\"], errors=\"coerce\").dropna()\n    lows = pd.to_numeric(window[\"Low\"], errors=\"coerce\").dropna()\n    if highs.size &lt; 5 or lows.size &lt; 5:\n        return None, None\n\n    resistance = highs.quantile(0.85)\n    high_band = highs[(highs &gt;= resistance * 0.99) &amp; (highs &lt;= resistance * 1.01)]\n    if high_band.size &lt; 2:\n        return None, None\n\n    low_x = np.arange(lows.size, dtype=float)\n    slope, _ = np.polyfit(low_x, lows.to_numpy(dtype=float), 1)\n    if slope &lt;= 0:\n        return None, None\n\n    start_idx = min(high_band.index.min(), lows.index.min())\n    return \"Ascending triangle\", pd.Timestamp(start_idx).date()\n</code></pre>"},{"location":"reference/narrata/analysis/#narrata.analysis.detect_patterns","title":"<code>detect_patterns(df, lookback=60)</code>","text":"<p>Detect chart and candlestick patterns.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>lookback</code> <code>int</code> <p>Number of recent rows to inspect for chart patterns.</p> <code>60</code> <p>Returns:</p> Type Description <code>PatternStats</code> <p>Pattern detection result.</p> Source code in <code>src/narrata/narrata/analysis/patterns.py</code> <pre><code>def detect_patterns(df: pd.DataFrame, lookback: int = 60) -&gt; PatternStats:\n    \"\"\"Detect chart and candlestick patterns.\n\n    :param df: OHLCV DataFrame.\n    :param lookback: Number of recent rows to inspect for chart patterns.\n    :return: Pattern detection result.\n    \"\"\"\n    validate_ohlcv_frame(df)\n    if lookback &lt; 10:\n        raise ValidationError(\"lookback must be &gt;= 10.\")\n\n    chart_pattern, chart_since = detect_chart_pattern(df, lookback=lookback)\n    candle_pattern, candle_date = detect_candlestick_pattern(df)\n    return PatternStats(\n        chart_pattern=chart_pattern,\n        chart_pattern_since=chart_since,\n        candlestick_pattern=candle_pattern,\n        candlestick_date=candle_date,\n    )\n</code></pre>"},{"location":"reference/narrata/analysis/#narrata.analysis.analyze_regime","title":"<code>analyze_regime(df, column='Close', window=20, penalty=3.0, trend_threshold=0.0005)</code>","text":"<p>Classify current trend and volatility regime.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>column</code> <code>str</code> <p>Price column to analyze.</p> <code>'Close'</code> <code>window</code> <code>int</code> <p>Rolling window for fallback regime metrics.</p> <code>20</code> <code>penalty</code> <code>float</code> <p>Ruptures PELT penalty parameter.</p> <code>3.0</code> <code>trend_threshold</code> <code>float</code> <p>Mean-return threshold for trend labels.</p> <code>0.0005</code> <p>Returns:</p> Type Description <code>RegimeStats</code> <p>Regime classification with inferred start date.</p> Source code in <code>src/narrata/narrata/analysis/regimes.py</code> <pre><code>def analyze_regime(\n    df: pd.DataFrame,\n    column: str = \"Close\",\n    window: int = 20,\n    penalty: float = 3.0,\n    trend_threshold: float = 0.0005,\n) -&gt; RegimeStats:\n    \"\"\"Classify current trend and volatility regime.\n\n    :param df: OHLCV DataFrame.\n    :param column: Price column to analyze.\n    :param window: Rolling window for fallback regime metrics.\n    :param penalty: Ruptures PELT penalty parameter.\n    :param trend_threshold: Mean-return threshold for trend labels.\n    :return: Regime classification with inferred start date.\n    \"\"\"\n    validate_ohlcv_frame(df)\n    if column not in df.columns:\n        raise ValidationError(f\"Column '{column}' does not exist in DataFrame.\")\n    if window &lt; 5:\n        raise ValidationError(\"window must be &gt;= 5.\")\n\n    prices = pd.to_numeric(df[column], errors=\"coerce\").dropna()\n    returns = prices.pct_change().dropna()\n    if returns.size &lt; window:\n        raise ValidationError(\"Not enough data to infer regime.\")\n\n    if rpt is not None and returns.size &gt;= max(window, 40):\n        trend_label, volatility_label, start_date = _analyze_with_ruptures(\n            returns=returns,\n            penalty=penalty,\n            trend_threshold=trend_threshold,\n            min_size=window,\n            rpt_module=rpt,\n        )\n    else:\n        trend_label, volatility_label, start_date = _analyze_with_rolling(\n            returns=returns,\n            window=window,\n            trend_threshold=trend_threshold,\n        )\n\n    return RegimeStats(\n        trend_label=trend_label,\n        volatility_label=volatility_label,\n        start_date=start_date,\n    )\n</code></pre>"},{"location":"reference/narrata/analysis/#narrata.analysis.describe_regime","title":"<code>describe_regime(stats)</code>","text":"<p>Render regime classification as one line.</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>RegimeStats</code> <p>Regime classification.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Human-readable regime text.</p> Source code in <code>src/narrata/narrata/analysis/regimes.py</code> <pre><code>def describe_regime(stats: RegimeStats) -&gt; str:\n    \"\"\"Render regime classification as one line.\n\n    :param stats: Regime classification.\n    :return: Human-readable regime text.\n    \"\"\"\n    return f\"Regime: {stats.trend_label} since {stats.start_date.isoformat()} ({stats.volatility_label} volatility)\"\n</code></pre>"},{"location":"reference/narrata/analysis/#narrata.analysis.analyze_summary","title":"<code>analyze_summary(df, column='Close', ticker=None)</code>","text":"<p>Compute summary statistics for a selected numeric column.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>column</code> <code>str</code> <p>Numeric column to summarize.</p> <code>'Close'</code> <code>ticker</code> <code>str | None</code> <p>Optional ticker override.</p> <code>None</code> <p>Returns:</p> Type Description <code>SummaryStats</code> <p>Structured summary statistics.</p> Source code in <code>src/narrata/narrata/analysis/summary.py</code> <pre><code>def analyze_summary(df: pd.DataFrame, column: str = \"Close\", ticker: str | None = None) -&gt; SummaryStats:\n    \"\"\"Compute summary statistics for a selected numeric column.\n\n    :param df: OHLCV DataFrame.\n    :param column: Numeric column to summarize.\n    :param ticker: Optional ticker override.\n    :return: Structured summary statistics.\n    \"\"\"\n    validate_ohlcv_frame(df)\n\n    if column not in df.columns:\n        raise ValidationError(f\"Column '{column}' does not exist in DataFrame.\")\n\n    series = pd.to_numeric(df[column], errors=\"coerce\").dropna()\n    if series.empty:\n        raise ValidationError(f\"Column '{column}' contains no numeric values.\")\n\n    start = float(series.iloc[0])\n    end = float(series.iloc[-1])\n\n    if start == 0.0:\n        change_pct = math.nan\n    else:\n        change_pct = ((end - start) / abs(start)) * 100.0\n\n    return SummaryStats(\n        ticker=_resolve_ticker(df, ticker),\n        column=column,\n        points=int(series.size),\n        frequency=infer_frequency_label(df.index),\n        start_date=df.index[0].date(),\n        end_date=df.index[-1].date(),\n        start=start,\n        end=end,\n        minimum=float(series.min()),\n        maximum=float(series.max()),\n        mean=float(series.mean()),\n        std=float(series.std(ddof=0)),\n        change_pct=change_pct,\n    )\n</code></pre>"},{"location":"reference/narrata/analysis/#narrata.analysis.describe_summary","title":"<code>describe_summary(summary, currency_symbol='$', precision=2, include_header=True)</code>","text":"<p>Render summary statistics as text.</p> <p>Parameters:</p> Name Type Description Default <code>summary</code> <code>SummaryStats</code> <p>Summary statistics.</p> required <code>currency_symbol</code> <code>str</code> <p>Symbol for currency formatting.</p> <code>'$'</code> <code>precision</code> <code>int</code> <p>Decimal precision for numeric values.</p> <code>2</code> <code>include_header</code> <code>bool</code> <p>Include ticker/points/frequency prefix.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>Summary narration.</p> Source code in <code>src/narrata/narrata/analysis/summary.py</code> <pre><code>def describe_summary(\n    summary: SummaryStats, currency_symbol: str = \"$\", precision: int = 2, include_header: bool = True\n) -&gt; str:\n    \"\"\"Render summary statistics as text.\n\n    :param summary: Summary statistics.\n    :param currency_symbol: Symbol for currency formatting.\n    :param precision: Decimal precision for numeric values.\n    :param include_header: Include ticker/points/frequency prefix.\n    :return: Summary narration.\n    \"\"\"\n    entity_name = summary.ticker or summary.column\n    prefix = f\"{entity_name} ({summary.points} pts, {summary.frequency}): \" if include_header else \"\"\n\n    line_1 = (\n        f\"{prefix}Range: [{_format_currency(summary.minimum, currency_symbol, precision)}, \"\n        f\"{_format_currency(summary.maximum, currency_symbol, precision)}]  \"\n        f\"Mean: {_format_currency(summary.mean, currency_symbol, precision)}  \"\n        f\"Std: {_format_currency(summary.std, currency_symbol, precision)}\"\n    )\n    line_2 = (\n        f\"Start: {_format_currency(summary.start, currency_symbol, precision)}  \"\n        f\"End: {_format_currency(summary.end, currency_symbol, precision)}  \"\n        f\"Change: {_format_change(summary.change_pct, precision)}\"\n    )\n\n    return f\"{line_1}\\n{line_2}\"\n</code></pre>"},{"location":"reference/narrata/analysis/#narrata.analysis.describe_support_resistance","title":"<code>describe_support_resistance(stats, currency_symbol='$', precision=2)</code>","text":"<p>Render support and resistance levels as one line.</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>LevelStats</code> <p>Support and resistance stats.</p> required <code>currency_symbol</code> <code>str</code> <p>Currency symbol for formatting.</p> <code>'$'</code> <code>precision</code> <code>int</code> <p>Decimal precision.</p> <code>2</code> <p>Returns:</p> Type Description <code>str</code> <p>Human-readable support/resistance narration.</p> Source code in <code>src/narrata/narrata/analysis/support_resistance.py</code> <pre><code>def describe_support_resistance(stats: LevelStats, currency_symbol: str = \"$\", precision: int = 2) -&gt; str:\n    \"\"\"Render support and resistance levels as one line.\n\n    :param stats: Support and resistance stats.\n    :param currency_symbol: Currency symbol for formatting.\n    :param precision: Decimal precision.\n    :return: Human-readable support/resistance narration.\n    \"\"\"\n    support_text = _format_levels(stats.supports, currency_symbol, precision)\n    resistance_text = _format_levels(stats.resistances, currency_symbol, precision)\n    return f\"Support: {support_text}  Resistance: {resistance_text}\"\n</code></pre>"},{"location":"reference/narrata/analysis/#narrata.analysis.find_support_resistance","title":"<code>find_support_resistance(df, column='Close', tolerance_ratio=0.01, max_levels=2, extrema_order=5)</code>","text":"<p>Detect support and resistance levels from local extrema and touch counts.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>column</code> <code>str</code> <p>Price column used for level detection.</p> <code>'Close'</code> <code>tolerance_ratio</code> <code>float</code> <p>Clustering tolerance as a price ratio.</p> <code>0.01</code> <code>max_levels</code> <code>int</code> <p>Max number of support and resistance levels to return.</p> <code>2</code> <code>extrema_order</code> <code>int</code> <p>Neighborhood size used by <code>argrelextrema</code>.</p> <code>5</code> <p>Returns:</p> Type Description <code>LevelStats</code> <p>Structured support and resistance levels.</p> Source code in <code>src/narrata/narrata/analysis/support_resistance.py</code> <pre><code>def find_support_resistance(\n    df: pd.DataFrame,\n    column: str = \"Close\",\n    tolerance_ratio: float = 0.01,\n    max_levels: int = 2,\n    extrema_order: int = 5,\n) -&gt; LevelStats:\n    \"\"\"Detect support and resistance levels from local extrema and touch counts.\n\n    :param df: OHLCV DataFrame.\n    :param column: Price column used for level detection.\n    :param tolerance_ratio: Clustering tolerance as a price ratio.\n    :param max_levels: Max number of support and resistance levels to return.\n    :param extrema_order: Neighborhood size used by ``argrelextrema``.\n    :return: Structured support and resistance levels.\n    \"\"\"\n    validate_ohlcv_frame(df)\n    if column not in df.columns:\n        raise ValidationError(f\"Column '{column}' does not exist in DataFrame.\")\n    if tolerance_ratio &lt;= 0.0:\n        raise ValidationError(\"tolerance_ratio must be &gt; 0.\")\n    if max_levels &lt; 1:\n        raise ValidationError(\"max_levels must be &gt;= 1.\")\n    if extrema_order &lt; 1:\n        raise ValidationError(\"extrema_order must be &gt;= 1.\")\n\n    prices = pd.to_numeric(df[column], errors=\"coerce\").dropna().to_numpy(dtype=float)\n    if prices.size &lt; extrema_order * 2 + 3:\n        raise ValidationError(\"Not enough data to find support/resistance.\")\n\n    minima_indices = argrelextrema(prices, np.less_equal, order=extrema_order)[0]\n    maxima_indices = argrelextrema(prices, np.greater_equal, order=extrema_order)[0]\n    current_price = float(prices[-1])\n    tolerance = max(current_price * tolerance_ratio, 1e-9)\n\n    support_values = [float(prices[idx]) for idx in minima_indices if prices[idx] &lt;= current_price]\n    resistance_values = [float(prices[idx]) for idx in maxima_indices if prices[idx] &gt;= current_price]\n\n    supports = _build_levels(\n        candidate_values=support_values,\n        extrema_values=np.asarray([prices[idx] for idx in minima_indices], dtype=float),\n        all_prices=prices,\n        tolerance=tolerance,\n        max_levels=max_levels,\n        reverse=True,\n    )\n    resistances = _build_levels(\n        candidate_values=resistance_values,\n        extrema_values=np.asarray([prices[idx] for idx in maxima_indices], dtype=float),\n        all_prices=prices,\n        tolerance=tolerance,\n        max_levels=max_levels,\n        reverse=False,\n    )\n\n    return LevelStats(supports=supports, resistances=resistances)\n</code></pre>"},{"location":"reference/narrata/analysis/#narrata.analysis.astride_encode","title":"<code>astride_encode(df, column='Close', n_segments=16, alphabet_size=8, penalty=3.0)</code>","text":"<p>Encode a series with ASTRIDE-style adaptive symbolization.</p> <p>Uses change-point detection (ruptures) to find segment boundaries that align with regime changes, then quantizes segment means into symbols. Unlike SAX, segments have variable length.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>column</code> <code>str</code> <p>Price column to encode.</p> <code>'Close'</code> <code>n_segments</code> <code>int</code> <p>Approximate number of segments.</p> <code>16</code> <code>alphabet_size</code> <code>int</code> <p>Number of symbols in alphabet.</p> <code>8</code> <code>penalty</code> <code>float</code> <p>Ruptures PELT penalty parameter.</p> <code>3.0</code> <p>Returns:</p> Type Description <code>SymbolicStats</code> <p>Structured symbolic encoding result.</p> Source code in <code>src/narrata/narrata/analysis/symbolic.py</code> <pre><code>def astride_encode(\n    df: pd.DataFrame,\n    column: str = \"Close\",\n    n_segments: int = 16,\n    alphabet_size: int = 8,\n    penalty: float = 3.0,\n) -&gt; SymbolicStats:\n    \"\"\"Encode a series with ASTRIDE-style adaptive symbolization.\n\n    Uses change-point detection (ruptures) to find segment boundaries that\n    align with regime changes, then quantizes segment means into symbols.\n    Unlike SAX, segments have variable length.\n\n    :param df: OHLCV DataFrame.\n    :param column: Price column to encode.\n    :param n_segments: Approximate number of segments.\n    :param alphabet_size: Number of symbols in alphabet.\n    :param penalty: Ruptures PELT penalty parameter.\n    :return: Structured symbolic encoding result.\n    \"\"\"\n    validate_ohlcv_frame(df)\n    if column not in df.columns:\n        raise ValidationError(f\"Column '{column}' does not exist in DataFrame.\")\n    if n_segments &lt; 2:\n        raise ValidationError(\"n_segments must be &gt;= 2.\")\n    if alphabet_size &lt; 2 or alphabet_size &gt; 26:\n        raise ValidationError(\"alphabet_size must be between 2 and 26.\")\n    if rpt is None:\n        raise ValidationError(\n            \"ASTRIDE encoding requires the 'ruptures' package. Install with: pip install narrata[symbolic]\"\n        )\n\n    values = pd.to_numeric(df[column], errors=\"coerce\").dropna().to_numpy(dtype=float)\n    if values.size &lt; n_segments:\n        raise ValidationError(\"Not enough data points for requested n_segments.\")\n\n    normalized = _z_normalize(values)\n    symbols = _astride_encode_core(normalized, n_segments=n_segments, alphabet_size=alphabet_size, penalty=penalty)\n\n    return SymbolicStats(\n        method=\"ASTRIDE\",\n        word_size=len(symbols),\n        alphabet_size=alphabet_size,\n        symbols=symbols,\n    )\n</code></pre>"},{"location":"reference/narrata/analysis/#narrata.analysis.describe_astride","title":"<code>describe_astride(stats)</code>","text":"<p>Render ASTRIDE symbolic encoding as one line.</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>SymbolicStats</code> <p>Symbolic encoding result.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Human-readable symbolic description.</p> Source code in <code>src/narrata/narrata/analysis/symbolic.py</code> <pre><code>def describe_astride(stats: SymbolicStats) -&gt; str:\n    \"\"\"Render ASTRIDE symbolic encoding as one line.\n\n    :param stats: Symbolic encoding result.\n    :return: Human-readable symbolic description.\n    \"\"\"\n    return f\"ASTRIDE({stats.word_size}): {stats.symbols}\"\n</code></pre>"},{"location":"reference/narrata/analysis/#narrata.analysis.describe_sax","title":"<code>describe_sax(stats)</code>","text":"<p>Render symbolic encoding as one line.</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>SymbolicStats</code> <p>Symbolic encoding result.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Human-readable symbolic description.</p> Source code in <code>src/narrata/narrata/analysis/symbolic.py</code> <pre><code>def describe_sax(stats: SymbolicStats) -&gt; str:\n    \"\"\"Render symbolic encoding as one line.\n\n    :param stats: Symbolic encoding result.\n    :return: Human-readable symbolic description.\n    \"\"\"\n    return f\"SAX({stats.word_size}): {stats.symbols}\"\n</code></pre>"},{"location":"reference/narrata/analysis/#narrata.analysis.sax_encode","title":"<code>sax_encode(df, column='Close', word_size=16, alphabet_size=8)</code>","text":"<p>Encode a series with SAX-style symbolization.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>column</code> <code>str</code> <p>Price column to encode.</p> <code>'Close'</code> <code>word_size</code> <code>int</code> <p>Number of PAA segments.</p> <code>16</code> <code>alphabet_size</code> <code>int</code> <p>Number of symbols in alphabet.</p> <code>8</code> <p>Returns:</p> Type Description <code>SymbolicStats</code> <p>Structured symbolic encoding result.</p> Source code in <code>src/narrata/narrata/analysis/symbolic.py</code> <pre><code>def sax_encode(df: pd.DataFrame, column: str = \"Close\", word_size: int = 16, alphabet_size: int = 8) -&gt; SymbolicStats:\n    \"\"\"Encode a series with SAX-style symbolization.\n\n    :param df: OHLCV DataFrame.\n    :param column: Price column to encode.\n    :param word_size: Number of PAA segments.\n    :param alphabet_size: Number of symbols in alphabet.\n    :return: Structured symbolic encoding result.\n    \"\"\"\n    validate_ohlcv_frame(df)\n    if column not in df.columns:\n        raise ValidationError(f\"Column '{column}' does not exist in DataFrame.\")\n    if word_size &lt; 2:\n        raise ValidationError(\"word_size must be &gt;= 2.\")\n    if alphabet_size &lt; 2 or alphabet_size &gt; 26:\n        raise ValidationError(\"alphabet_size must be between 2 and 26.\")\n\n    values = pd.to_numeric(df[column], errors=\"coerce\").dropna().to_numpy(dtype=float)\n    if values.size &lt; word_size:\n        raise ValidationError(\"Not enough data points for requested word_size.\")\n\n    if SymbolicAggregateApproximation is not None:\n        symbols = _sax_encode_with_tslearn(\n            values=values,\n            word_size=word_size,\n            alphabet_size=alphabet_size,\n            sax_cls=SymbolicAggregateApproximation,\n        )\n    else:\n        symbols = _sax_encode_inhouse(values=values, word_size=word_size, alphabet_size=alphabet_size)\n\n    return SymbolicStats(\n        method=\"SAX\",\n        word_size=word_size,\n        alphabet_size=alphabet_size,\n        symbols=symbols,\n    )\n</code></pre>"},{"location":"reference/narrata/analysis/indicators/","title":"indicators","text":""},{"location":"reference/narrata/analysis/indicators/#narrata.analysis.indicators","title":"<code>narrata.analysis.indicators</code>","text":"<p>Technical indicator analysis and narration.</p>"},{"location":"reference/narrata/analysis/indicators/#narrata.analysis.indicators.compute_rsi","title":"<code>compute_rsi(series, period=14)</code>","text":"<p>Compute RSI using Wilder-style exponential smoothing.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>Price series.</p> required <code>period</code> <code>int</code> <p>RSI period length.</p> <code>14</code> <p>Returns:</p> Type Description <code>float</code> <p>Latest RSI value.</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def compute_rsi(series: pd.Series, period: int = 14) -&gt; float:\n    \"\"\"Compute RSI using Wilder-style exponential smoothing.\n\n    :param series: Price series.\n    :param period: RSI period length.\n    :return: Latest RSI value.\n    \"\"\"\n    if period &lt; 2:\n        raise ValidationError(\"RSI period must be &gt;= 2.\")\n\n    values = pd.to_numeric(series, errors=\"coerce\").dropna()\n    if values.size &lt; period + 1:\n        raise ValidationError(\"Not enough data to compute RSI.\")\n\n    delta = values.diff()\n    gains = delta.clip(lower=0.0)\n    losses = -delta.clip(upper=0.0)\n    avg_gain = gains.ewm(alpha=1.0 / period, adjust=False).mean()\n    avg_loss = losses.ewm(alpha=1.0 / period, adjust=False).mean()\n    rs = avg_gain / avg_loss.replace(0.0, np.nan)\n    rsi = 100.0 - (100.0 / (1.0 + rs))\n\n    latest = float(rsi.iloc[-1]) if not np.isnan(rsi.iloc[-1]) else 100.0\n    return max(0.0, min(100.0, latest))\n</code></pre>"},{"location":"reference/narrata/analysis/indicators/#narrata.analysis.indicators.compute_macd","title":"<code>compute_macd(series, fast_period=12, slow_period=26, signal_period=9)</code>","text":"<p>Compute MACD values for the latest sample.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>Price series.</p> required <code>fast_period</code> <code>int</code> <p>Fast EMA period.</p> <code>12</code> <code>slow_period</code> <code>int</code> <p>Slow EMA period.</p> <code>26</code> <code>signal_period</code> <code>int</code> <p>Signal EMA period.</p> <code>9</code> <p>Returns:</p> Type Description <code>tuple[float, float, float]</code> <p>Tuple of (macd_line, signal_line, histogram).</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def compute_macd(\n    series: pd.Series, fast_period: int = 12, slow_period: int = 26, signal_period: int = 9\n) -&gt; tuple[float, float, float]:\n    \"\"\"Compute MACD values for the latest sample.\n\n    :param series: Price series.\n    :param fast_period: Fast EMA period.\n    :param slow_period: Slow EMA period.\n    :param signal_period: Signal EMA period.\n    :return: Tuple of (macd_line, signal_line, histogram).\n    \"\"\"\n    if fast_period &gt;= slow_period:\n        raise ValidationError(\"fast_period must be smaller than slow_period.\")\n\n    values = pd.to_numeric(series, errors=\"coerce\").dropna()\n    if values.size &lt; slow_period + signal_period:\n        raise ValidationError(\"Not enough data to compute MACD.\")\n\n    fast_ema = values.ewm(span=fast_period, adjust=False).mean()\n    slow_ema = values.ewm(span=slow_period, adjust=False).mean()\n    macd_line = fast_ema - slow_ema\n    signal_line = macd_line.ewm(span=signal_period, adjust=False).mean()\n    histogram = macd_line - signal_line\n\n    return float(macd_line.iloc[-1]), float(signal_line.iloc[-1]), float(histogram.iloc[-1])\n</code></pre>"},{"location":"reference/narrata/analysis/indicators/#narrata.analysis.indicators.compute_bollinger","title":"<code>compute_bollinger(series, period=20, num_std=2.0)</code>","text":"<p>Compute Bollinger Band position and squeeze state.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>Price series.</p> required <code>period</code> <code>int</code> <p>Bollinger Band period.</p> <code>20</code> <code>num_std</code> <code>float</code> <p>Number of standard deviations for band width.</p> <code>2.0</code> <p>Returns:</p> Type Description <code>tuple[str, bool]</code> <p>Tuple of (position label, squeeze detected).</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def compute_bollinger(series: pd.Series, period: int = 20, num_std: float = 2.0) -&gt; tuple[str, bool]:\n    \"\"\"Compute Bollinger Band position and squeeze state.\n\n    :param series: Price series.\n    :param period: Bollinger Band period.\n    :param num_std: Number of standard deviations for band width.\n    :return: Tuple of (position label, squeeze detected).\n    \"\"\"\n    values = pd.to_numeric(series, errors=\"coerce\").dropna()\n    if values.size &lt; period:\n        raise ValidationError(\"Not enough data to compute Bollinger Bands.\")\n\n    sma = values.rolling(window=period).mean()\n    std = values.rolling(window=period).std(ddof=0)\n    upper = sma + num_std * std\n    lower = sma - num_std * std\n    bandwidth = ((upper - lower) / sma).dropna()\n\n    latest_price = float(values.iloc[-1])\n    latest_upper = float(upper.iloc[-1])\n    latest_lower = float(lower.iloc[-1])\n    latest_sma = float(sma.iloc[-1])\n\n    if latest_upper == latest_lower:\n        position = \"at midline\"\n    else:\n        pct = (latest_price - latest_lower) / (latest_upper - latest_lower)\n        if pct &gt;= 0.95:\n            position = \"above upper band\"\n        elif pct &gt;= 0.80:\n            position = \"near upper band\"\n        elif pct &lt;= 0.05:\n            position = \"below lower band\"\n        elif pct &lt;= 0.20:\n            position = \"near lower band\"\n        elif latest_price &gt; latest_sma:\n            position = \"upper half\"\n        else:\n            position = \"lower half\"\n\n    squeeze = False\n    if bandwidth.size &gt;= period:\n        recent_bw = float(bandwidth.iloc[-1])\n        lookback_bw = float(bandwidth.iloc[-period:].quantile(0.20))\n        squeeze = recent_bw &lt;= lookback_bw\n\n    return position, squeeze\n</code></pre>"},{"location":"reference/narrata/analysis/indicators/#narrata.analysis.indicators.compute_ma_crossover","title":"<code>compute_ma_crossover(series, fast_period=50, slow_period=200)</code>","text":"<p>Detect moving average crossover (golden/death cross).</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>Price series.</p> required <code>fast_period</code> <code>int</code> <p>Fast SMA period.</p> <code>50</code> <code>slow_period</code> <code>int</code> <p>Slow SMA period.</p> <code>200</code> <p>Returns:</p> Type Description <code>tuple[str | None, int | None]</code> <p>Tuple of (cross type or None, days since cross or None).</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def compute_ma_crossover(\n    series: pd.Series, fast_period: int = 50, slow_period: int = 200\n) -&gt; tuple[str | None, int | None]:\n    \"\"\"Detect moving average crossover (golden/death cross).\n\n    :param series: Price series.\n    :param fast_period: Fast SMA period.\n    :param slow_period: Slow SMA period.\n    :return: Tuple of (cross type or None, days since cross or None).\n    \"\"\"\n    values = pd.to_numeric(series, errors=\"coerce\").dropna()\n    if values.size &lt; slow_period + 1:\n        return None, None\n\n    fast_sma = values.rolling(window=fast_period).mean()\n    slow_sma = values.rolling(window=slow_period).mean()\n    diff = (fast_sma - slow_sma).dropna()\n    if diff.size &lt; 2:\n        return None, None\n\n    signs = np.sign(diff.to_numpy())\n    current = \"golden cross\" if signs[-1] &gt;= 0.0 else \"death cross\"\n\n    for idx in range(signs.size - 1, 0, -1):\n        if signs[idx] != signs[idx - 1] and signs[idx] != 0.0 and signs[idx - 1] != 0.0:\n            days_ago = signs.size - 1 - idx\n            return current, days_ago\n\n    return current, None\n</code></pre>"},{"location":"reference/narrata/analysis/indicators/#narrata.analysis.indicators.compute_volume_state","title":"<code>compute_volume_state(df, lookback=20)</code>","text":"<p>Compute volume ratio to N-day moving average and classify.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame with Volume column.</p> required <code>lookback</code> <code>int</code> <p>Moving average lookback period.</p> <code>20</code> <p>Returns:</p> Type Description <code>tuple[float, str]</code> <p>Tuple of (ratio to average, state label).</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def compute_volume_state(df: pd.DataFrame, lookback: int = 20) -&gt; tuple[float, str]:\n    \"\"\"Compute volume ratio to N-day moving average and classify.\n\n    :param df: OHLCV DataFrame with Volume column.\n    :param lookback: Moving average lookback period.\n    :return: Tuple of (ratio to average, state label).\n    \"\"\"\n    if \"Volume\" not in df.columns:\n        raise ValidationError(\"DataFrame must contain Volume column.\")\n\n    volume = pd.to_numeric(df[\"Volume\"], errors=\"coerce\").dropna()\n    if volume.size &lt; lookback + 1:\n        raise ValidationError(\"Not enough data to compute volume state.\")\n\n    avg = float(volume.rolling(window=lookback).mean().iloc[-1])\n    if avg &lt;= 0.0:\n        return 1.0, \"average\"\n\n    latest = float(volume.iloc[-1])\n    ratio = latest / avg\n\n    if ratio &gt;= 2.0:\n        state = \"unusually high\"\n    elif ratio &gt;= 1.5:\n        state = \"above average\"\n    elif ratio &lt;= 0.5:\n        state = \"unusually low\"\n    elif ratio &lt;= 0.75:\n        state = \"below average\"\n    else:\n        state = \"average\"\n\n    return round(ratio, 2), state\n</code></pre>"},{"location":"reference/narrata/analysis/indicators/#narrata.analysis.indicators.compute_volatility_percentile","title":"<code>compute_volatility_percentile(series, window=20, lookback=252)</code>","text":"<p>Compute historical volatility percentile rank.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>Price series.</p> required <code>window</code> <code>int</code> <p>Rolling window for volatility calculation.</p> <code>20</code> <code>lookback</code> <code>int</code> <p>Lookback period for percentile ranking.</p> <code>252</code> <p>Returns:</p> Type Description <code>tuple[float, str]</code> <p>Tuple of (percentile 0-100, state label).</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def compute_volatility_percentile(series: pd.Series, window: int = 20, lookback: int = 252) -&gt; tuple[float, str]:\n    \"\"\"Compute historical volatility percentile rank.\n\n    :param series: Price series.\n    :param window: Rolling window for volatility calculation.\n    :param lookback: Lookback period for percentile ranking.\n    :return: Tuple of (percentile 0-100, state label).\n    \"\"\"\n    values = pd.to_numeric(series, errors=\"coerce\").dropna()\n    if values.size &lt; window + 2:\n        raise ValidationError(\"Not enough data to compute volatility percentile.\")\n\n    returns = values.pct_change().dropna()\n    rolling_vol = returns.rolling(window=window).std(ddof=0).dropna()\n    if rolling_vol.empty:\n        raise ValidationError(\"Not enough data to compute volatility percentile.\")\n\n    current_vol = float(rolling_vol.iloc[-1])\n    rank_window = rolling_vol.tail(min(lookback, rolling_vol.size))\n    percentile = float((rank_window &lt;= current_vol).sum() / rank_window.size * 100.0)\n    percentile = round(percentile, 0)\n\n    if percentile &lt;= 10:\n        state = \"extremely low\"\n    elif percentile &lt;= 25:\n        state = \"low\"\n    elif percentile &gt;= 90:\n        state = \"extremely high\"\n    elif percentile &gt;= 75:\n        state = \"high\"\n    else:\n        state = \"moderate\"\n\n    return percentile, state\n</code></pre>"},{"location":"reference/narrata/analysis/indicators/#narrata.analysis.indicators.analyze_indicators","title":"<code>analyze_indicators(df, column='Close', rsi_period=14)</code>","text":"<p>Analyze RSI, MACD, Bollinger Bands, MA crossovers, volume, and volatility.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>column</code> <code>str</code> <p>Price column to analyze.</p> <code>'Close'</code> <code>rsi_period</code> <code>int</code> <p>RSI period.</p> <code>14</code> <p>Returns:</p> Type Description <code>IndicatorStats</code> <p>Structured indicator statistics.</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def analyze_indicators(df: pd.DataFrame, column: str = \"Close\", rsi_period: int = 14) -&gt; IndicatorStats:\n    \"\"\"Analyze RSI, MACD, Bollinger Bands, MA crossovers, volume, and volatility.\n\n    :param df: OHLCV DataFrame.\n    :param column: Price column to analyze.\n    :param rsi_period: RSI period.\n    :return: Structured indicator statistics.\n    \"\"\"\n    validate_ohlcv_frame(df)\n    if column not in df.columns:\n        raise ValidationError(f\"Column '{column}' does not exist in DataFrame.\")\n\n    values = pd.to_numeric(df[column], errors=\"coerce\").dropna()\n    if ta is None:\n        rsi_value = compute_rsi(values, period=rsi_period)\n        macd_value, signal_value, histogram = compute_macd(values)\n        macd_state, crossover_days = _classify_macd(values)\n    else:\n        rsi_value = _compute_rsi_with_pandas_ta(values, period=rsi_period)\n        macd_value, signal_value, histogram, macd_state, crossover_days = _compute_macd_with_pandas_ta(values)\n\n    rsi_state = _classify_rsi(values, rsi_value)\n\n    bb_position: str | None = None\n    bb_squeeze: bool | None = None\n    try:\n        bb_position, bb_squeeze = compute_bollinger(values)\n    except ValidationError:\n        pass\n\n    ma_cross: str | None = None\n    ma_cross_days: int | None = None\n    try:\n        ma_cross, ma_cross_days = compute_ma_crossover(values)\n    except ValidationError:\n        pass\n\n    volume_ratio: float | None = None\n    volume_state: str | None = None\n    try:\n        volume_ratio, volume_state = compute_volume_state(df)\n    except ValidationError:\n        pass\n\n    vol_pct: float | None = None\n    vol_state: str | None = None\n    try:\n        vol_pct, vol_state = compute_volatility_percentile(values)\n    except ValidationError:\n        pass\n\n    return IndicatorStats(\n        rsi_period=rsi_period,\n        rsi_value=rsi_value,\n        rsi_state=rsi_state,\n        macd_value=macd_value,\n        macd_signal=signal_value,\n        macd_histogram=histogram,\n        macd_state=macd_state,\n        crossover_days_ago=crossover_days,\n        bb_position=bb_position,\n        bb_squeeze=bb_squeeze,\n        ma_cross=ma_cross,\n        ma_cross_days_ago=ma_cross_days,\n        volume_ratio=volume_ratio,\n        volume_state=volume_state,\n        volatility_percentile=vol_pct,\n        volatility_state=vol_state,\n    )\n</code></pre>"},{"location":"reference/narrata/analysis/indicators/#narrata.analysis.indicators.describe_indicators","title":"<code>describe_indicators(stats)</code>","text":"<p>Render indicator statistics as concise narration lines.</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>IndicatorStats</code> <p>Indicator statistics.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Human-readable indicator narration.</p> Source code in <code>src/narrata/narrata/analysis/indicators.py</code> <pre><code>def describe_indicators(stats: IndicatorStats) -&gt; str:\n    \"\"\"Render indicator statistics as concise narration lines.\n\n    :param stats: Indicator statistics.\n    :return: Human-readable indicator narration.\n    \"\"\"\n    rsi_part = f\"RSI({stats.rsi_period}): {stats.rsi_value:.1f} ({stats.rsi_state})\"\n\n    if stats.crossover_days_ago is None:\n        macd_part = f\"MACD: {stats.macd_state}\"\n    else:\n        unit = \"day\" if stats.crossover_days_ago == 1 else \"days\"\n        macd_part = f\"MACD: {stats.macd_state} crossover {stats.crossover_days_ago} {unit} ago\"\n\n    parts = [f\"{rsi_part}  {macd_part}\"]\n\n    if stats.bb_position is not None:\n        bb_text = f\"BB: {stats.bb_position}\"\n        if stats.bb_squeeze:\n            bb_text += \" (squeeze)\"\n        parts.append(bb_text)\n\n    if stats.ma_cross is not None:\n        if stats.ma_cross_days_ago is not None:\n            unit = \"day\" if stats.ma_cross_days_ago == 1 else \"days\"\n            parts.append(f\"SMA 50/200: {stats.ma_cross} {stats.ma_cross_days_ago} {unit} ago\")\n        else:\n            parts.append(f\"SMA 50/200: {stats.ma_cross}\")\n\n    if stats.volume_ratio is not None and stats.volume_state is not None:\n        parts.append(f\"Volume: {stats.volume_ratio}x 20-day avg ({stats.volume_state})\")\n\n    if stats.volatility_percentile is not None and stats.volatility_state is not None:\n        percentile = _format_ordinal(stats.volatility_percentile)\n        parts.append(f\"Volatility: {percentile} percentile ({stats.volatility_state})\")\n\n    return \"\\n\".join(parts)\n</code></pre>"},{"location":"reference/narrata/analysis/patterns/","title":"patterns","text":""},{"location":"reference/narrata/analysis/patterns/#narrata.analysis.patterns","title":"<code>narrata.analysis.patterns</code>","text":"<p>Chart pattern and candlestick pattern detection.</p>"},{"location":"reference/narrata/analysis/patterns/#narrata.analysis.patterns.detect_patterns","title":"<code>detect_patterns(df, lookback=60)</code>","text":"<p>Detect chart and candlestick patterns.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>lookback</code> <code>int</code> <p>Number of recent rows to inspect for chart patterns.</p> <code>60</code> <p>Returns:</p> Type Description <code>PatternStats</code> <p>Pattern detection result.</p> Source code in <code>src/narrata/narrata/analysis/patterns.py</code> <pre><code>def detect_patterns(df: pd.DataFrame, lookback: int = 60) -&gt; PatternStats:\n    \"\"\"Detect chart and candlestick patterns.\n\n    :param df: OHLCV DataFrame.\n    :param lookback: Number of recent rows to inspect for chart patterns.\n    :return: Pattern detection result.\n    \"\"\"\n    validate_ohlcv_frame(df)\n    if lookback &lt; 10:\n        raise ValidationError(\"lookback must be &gt;= 10.\")\n\n    chart_pattern, chart_since = detect_chart_pattern(df, lookback=lookback)\n    candle_pattern, candle_date = detect_candlestick_pattern(df)\n    return PatternStats(\n        chart_pattern=chart_pattern,\n        chart_pattern_since=chart_since,\n        candlestick_pattern=candle_pattern,\n        candlestick_date=candle_date,\n    )\n</code></pre>"},{"location":"reference/narrata/analysis/patterns/#narrata.analysis.patterns.detect_chart_pattern","title":"<code>detect_chart_pattern(df, lookback=60)</code>","text":"<p>Detect simple chart patterns from highs and lows.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>lookback</code> <code>int</code> <p>Number of recent rows to inspect.</p> <code>60</code> <p>Returns:</p> Type Description <code>tuple[str | None, date | None]</code> <p>Pattern name and starting timestamp if detected.</p> Source code in <code>src/narrata/narrata/analysis/patterns.py</code> <pre><code>def detect_chart_pattern(df: pd.DataFrame, lookback: int = 60) -&gt; tuple[str | None, date | None]:\n    \"\"\"Detect simple chart patterns from highs and lows.\n\n    :param df: OHLCV DataFrame.\n    :param lookback: Number of recent rows to inspect.\n    :return: Pattern name and starting timestamp if detected.\n    \"\"\"\n    if \"High\" not in df.columns or \"Low\" not in df.columns or \"Close\" not in df.columns:\n        raise ValidationError(\"DataFrame must contain High, Low and Close columns.\")\n\n    window = df.tail(lookback).copy()\n    highs = pd.to_numeric(window[\"High\"], errors=\"coerce\").dropna()\n    lows = pd.to_numeric(window[\"Low\"], errors=\"coerce\").dropna()\n    if highs.size &lt; 5 or lows.size &lt; 5:\n        return None, None\n\n    resistance = highs.quantile(0.85)\n    high_band = highs[(highs &gt;= resistance * 0.99) &amp; (highs &lt;= resistance * 1.01)]\n    if high_band.size &lt; 2:\n        return None, None\n\n    low_x = np.arange(lows.size, dtype=float)\n    slope, _ = np.polyfit(low_x, lows.to_numpy(dtype=float), 1)\n    if slope &lt;= 0:\n        return None, None\n\n    start_idx = min(high_band.index.min(), lows.index.min())\n    return \"Ascending triangle\", pd.Timestamp(start_idx).date()\n</code></pre>"},{"location":"reference/narrata/analysis/patterns/#narrata.analysis.patterns.detect_candlestick_pattern","title":"<code>detect_candlestick_pattern(df)</code>","text":"<p>Detect candlestick patterns using optional backend and in-house fallback.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <p>Returns:</p> Type Description <code>tuple[str | None, date | None]</code> <p>Candlestick pattern name and timestamp if detected.</p> Source code in <code>src/narrata/narrata/analysis/patterns.py</code> <pre><code>def detect_candlestick_pattern(df: pd.DataFrame) -&gt; tuple[str | None, date | None]:\n    \"\"\"Detect candlestick patterns using optional backend and in-house fallback.\n\n    :param df: OHLCV DataFrame.\n    :return: Candlestick pattern name and timestamp if detected.\n    \"\"\"\n    for column in (\"Open\", \"Close\"):\n        if column not in df.columns:\n            raise ValidationError(\"DataFrame must contain Open and Close columns.\")\n    if df.shape[0] &lt; 2:\n        return None, None\n\n    if ta is not None and \"High\" in df.columns and \"Low\" in df.columns:\n        detected = _detect_candlestick_with_pandas_ta(df)\n        if detected[0] is not None:\n            return detected\n\n    return _detect_candlestick_inhouse(df)\n</code></pre>"},{"location":"reference/narrata/analysis/patterns/#narrata.analysis.patterns.describe_patterns","title":"<code>describe_patterns(stats)</code>","text":"<p>Render chart pattern line.</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>PatternStats</code> <p>Pattern detection results.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Human-readable chart pattern narration.</p> Source code in <code>src/narrata/narrata/analysis/patterns.py</code> <pre><code>def describe_patterns(stats: PatternStats) -&gt; str:\n    \"\"\"Render chart pattern line.\n\n    :param stats: Pattern detection results.\n    :return: Human-readable chart pattern narration.\n    \"\"\"\n    if stats.chart_pattern is None or stats.chart_pattern_since is None:\n        return \"Patterns: none detected\"\n    return f\"Patterns: {stats.chart_pattern} forming since {stats.chart_pattern_since.isoformat()}\"\n</code></pre>"},{"location":"reference/narrata/analysis/patterns/#narrata.analysis.patterns.describe_candlestick","title":"<code>describe_candlestick(stats)</code>","text":"<p>Render candlestick line.</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>PatternStats</code> <p>Pattern detection results.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Human-readable candlestick narration.</p> Source code in <code>src/narrata/narrata/analysis/patterns.py</code> <pre><code>def describe_candlestick(stats: PatternStats) -&gt; str:\n    \"\"\"Render candlestick line.\n\n    :param stats: Pattern detection results.\n    :return: Human-readable candlestick narration.\n    \"\"\"\n    if stats.candlestick_pattern is None or stats.candlestick_date is None:\n        return \"Candlestick: none detected\"\n    return f\"Candlestick: {stats.candlestick_pattern} on {stats.candlestick_date.isoformat()}\"\n</code></pre>"},{"location":"reference/narrata/analysis/regimes/","title":"regimes","text":""},{"location":"reference/narrata/analysis/regimes/#narrata.analysis.regimes","title":"<code>narrata.analysis.regimes</code>","text":"<p>Regime classification for time series.</p> <p>Uses change-point detection from ruptures when available, with a robust rolling-statistics fallback when ruptures is not installed.</p>"},{"location":"reference/narrata/analysis/regimes/#narrata.analysis.regimes.analyze_regime","title":"<code>analyze_regime(df, column='Close', window=20, penalty=3.0, trend_threshold=0.0005)</code>","text":"<p>Classify current trend and volatility regime.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>column</code> <code>str</code> <p>Price column to analyze.</p> <code>'Close'</code> <code>window</code> <code>int</code> <p>Rolling window for fallback regime metrics.</p> <code>20</code> <code>penalty</code> <code>float</code> <p>Ruptures PELT penalty parameter.</p> <code>3.0</code> <code>trend_threshold</code> <code>float</code> <p>Mean-return threshold for trend labels.</p> <code>0.0005</code> <p>Returns:</p> Type Description <code>RegimeStats</code> <p>Regime classification with inferred start date.</p> Source code in <code>src/narrata/narrata/analysis/regimes.py</code> <pre><code>def analyze_regime(\n    df: pd.DataFrame,\n    column: str = \"Close\",\n    window: int = 20,\n    penalty: float = 3.0,\n    trend_threshold: float = 0.0005,\n) -&gt; RegimeStats:\n    \"\"\"Classify current trend and volatility regime.\n\n    :param df: OHLCV DataFrame.\n    :param column: Price column to analyze.\n    :param window: Rolling window for fallback regime metrics.\n    :param penalty: Ruptures PELT penalty parameter.\n    :param trend_threshold: Mean-return threshold for trend labels.\n    :return: Regime classification with inferred start date.\n    \"\"\"\n    validate_ohlcv_frame(df)\n    if column not in df.columns:\n        raise ValidationError(f\"Column '{column}' does not exist in DataFrame.\")\n    if window &lt; 5:\n        raise ValidationError(\"window must be &gt;= 5.\")\n\n    prices = pd.to_numeric(df[column], errors=\"coerce\").dropna()\n    returns = prices.pct_change().dropna()\n    if returns.size &lt; window:\n        raise ValidationError(\"Not enough data to infer regime.\")\n\n    if rpt is not None and returns.size &gt;= max(window, 40):\n        trend_label, volatility_label, start_date = _analyze_with_ruptures(\n            returns=returns,\n            penalty=penalty,\n            trend_threshold=trend_threshold,\n            min_size=window,\n            rpt_module=rpt,\n        )\n    else:\n        trend_label, volatility_label, start_date = _analyze_with_rolling(\n            returns=returns,\n            window=window,\n            trend_threshold=trend_threshold,\n        )\n\n    return RegimeStats(\n        trend_label=trend_label,\n        volatility_label=volatility_label,\n        start_date=start_date,\n    )\n</code></pre>"},{"location":"reference/narrata/analysis/regimes/#narrata.analysis.regimes.describe_regime","title":"<code>describe_regime(stats)</code>","text":"<p>Render regime classification as one line.</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>RegimeStats</code> <p>Regime classification.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Human-readable regime text.</p> Source code in <code>src/narrata/narrata/analysis/regimes.py</code> <pre><code>def describe_regime(stats: RegimeStats) -&gt; str:\n    \"\"\"Render regime classification as one line.\n\n    :param stats: Regime classification.\n    :return: Human-readable regime text.\n    \"\"\"\n    return f\"Regime: {stats.trend_label} since {stats.start_date.isoformat()} ({stats.volatility_label} volatility)\"\n</code></pre>"},{"location":"reference/narrata/analysis/summary/","title":"summary","text":""},{"location":"reference/narrata/analysis/summary/#narrata.analysis.summary","title":"<code>narrata.analysis.summary</code>","text":"<p>Statistical summary analysis and textual description for one series.</p>"},{"location":"reference/narrata/analysis/summary/#narrata.analysis.summary.analyze_summary","title":"<code>analyze_summary(df, column='Close', ticker=None)</code>","text":"<p>Compute summary statistics for a selected numeric column.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>column</code> <code>str</code> <p>Numeric column to summarize.</p> <code>'Close'</code> <code>ticker</code> <code>str | None</code> <p>Optional ticker override.</p> <code>None</code> <p>Returns:</p> Type Description <code>SummaryStats</code> <p>Structured summary statistics.</p> Source code in <code>src/narrata/narrata/analysis/summary.py</code> <pre><code>def analyze_summary(df: pd.DataFrame, column: str = \"Close\", ticker: str | None = None) -&gt; SummaryStats:\n    \"\"\"Compute summary statistics for a selected numeric column.\n\n    :param df: OHLCV DataFrame.\n    :param column: Numeric column to summarize.\n    :param ticker: Optional ticker override.\n    :return: Structured summary statistics.\n    \"\"\"\n    validate_ohlcv_frame(df)\n\n    if column not in df.columns:\n        raise ValidationError(f\"Column '{column}' does not exist in DataFrame.\")\n\n    series = pd.to_numeric(df[column], errors=\"coerce\").dropna()\n    if series.empty:\n        raise ValidationError(f\"Column '{column}' contains no numeric values.\")\n\n    start = float(series.iloc[0])\n    end = float(series.iloc[-1])\n\n    if start == 0.0:\n        change_pct = math.nan\n    else:\n        change_pct = ((end - start) / abs(start)) * 100.0\n\n    return SummaryStats(\n        ticker=_resolve_ticker(df, ticker),\n        column=column,\n        points=int(series.size),\n        frequency=infer_frequency_label(df.index),\n        start_date=df.index[0].date(),\n        end_date=df.index[-1].date(),\n        start=start,\n        end=end,\n        minimum=float(series.min()),\n        maximum=float(series.max()),\n        mean=float(series.mean()),\n        std=float(series.std(ddof=0)),\n        change_pct=change_pct,\n    )\n</code></pre>"},{"location":"reference/narrata/analysis/summary/#narrata.analysis.summary.describe_summary","title":"<code>describe_summary(summary, currency_symbol='$', precision=2, include_header=True)</code>","text":"<p>Render summary statistics as text.</p> <p>Parameters:</p> Name Type Description Default <code>summary</code> <code>SummaryStats</code> <p>Summary statistics.</p> required <code>currency_symbol</code> <code>str</code> <p>Symbol for currency formatting.</p> <code>'$'</code> <code>precision</code> <code>int</code> <p>Decimal precision for numeric values.</p> <code>2</code> <code>include_header</code> <code>bool</code> <p>Include ticker/points/frequency prefix.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>Summary narration.</p> Source code in <code>src/narrata/narrata/analysis/summary.py</code> <pre><code>def describe_summary(\n    summary: SummaryStats, currency_symbol: str = \"$\", precision: int = 2, include_header: bool = True\n) -&gt; str:\n    \"\"\"Render summary statistics as text.\n\n    :param summary: Summary statistics.\n    :param currency_symbol: Symbol for currency formatting.\n    :param precision: Decimal precision for numeric values.\n    :param include_header: Include ticker/points/frequency prefix.\n    :return: Summary narration.\n    \"\"\"\n    entity_name = summary.ticker or summary.column\n    prefix = f\"{entity_name} ({summary.points} pts, {summary.frequency}): \" if include_header else \"\"\n\n    line_1 = (\n        f\"{prefix}Range: [{_format_currency(summary.minimum, currency_symbol, precision)}, \"\n        f\"{_format_currency(summary.maximum, currency_symbol, precision)}]  \"\n        f\"Mean: {_format_currency(summary.mean, currency_symbol, precision)}  \"\n        f\"Std: {_format_currency(summary.std, currency_symbol, precision)}\"\n    )\n    line_2 = (\n        f\"Start: {_format_currency(summary.start, currency_symbol, precision)}  \"\n        f\"End: {_format_currency(summary.end, currency_symbol, precision)}  \"\n        f\"Change: {_format_change(summary.change_pct, precision)}\"\n    )\n\n    return f\"{line_1}\\n{line_2}\"\n</code></pre>"},{"location":"reference/narrata/analysis/support_resistance/","title":"support_resistance","text":""},{"location":"reference/narrata/analysis/support_resistance/#narrata.analysis.support_resistance","title":"<code>narrata.analysis.support_resistance</code>","text":"<p>Support and resistance level extraction.</p>"},{"location":"reference/narrata/analysis/support_resistance/#narrata.analysis.support_resistance.find_support_resistance","title":"<code>find_support_resistance(df, column='Close', tolerance_ratio=0.01, max_levels=2, extrema_order=5)</code>","text":"<p>Detect support and resistance levels from local extrema and touch counts.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>column</code> <code>str</code> <p>Price column used for level detection.</p> <code>'Close'</code> <code>tolerance_ratio</code> <code>float</code> <p>Clustering tolerance as a price ratio.</p> <code>0.01</code> <code>max_levels</code> <code>int</code> <p>Max number of support and resistance levels to return.</p> <code>2</code> <code>extrema_order</code> <code>int</code> <p>Neighborhood size used by <code>argrelextrema</code>.</p> <code>5</code> <p>Returns:</p> Type Description <code>LevelStats</code> <p>Structured support and resistance levels.</p> Source code in <code>src/narrata/narrata/analysis/support_resistance.py</code> <pre><code>def find_support_resistance(\n    df: pd.DataFrame,\n    column: str = \"Close\",\n    tolerance_ratio: float = 0.01,\n    max_levels: int = 2,\n    extrema_order: int = 5,\n) -&gt; LevelStats:\n    \"\"\"Detect support and resistance levels from local extrema and touch counts.\n\n    :param df: OHLCV DataFrame.\n    :param column: Price column used for level detection.\n    :param tolerance_ratio: Clustering tolerance as a price ratio.\n    :param max_levels: Max number of support and resistance levels to return.\n    :param extrema_order: Neighborhood size used by ``argrelextrema``.\n    :return: Structured support and resistance levels.\n    \"\"\"\n    validate_ohlcv_frame(df)\n    if column not in df.columns:\n        raise ValidationError(f\"Column '{column}' does not exist in DataFrame.\")\n    if tolerance_ratio &lt;= 0.0:\n        raise ValidationError(\"tolerance_ratio must be &gt; 0.\")\n    if max_levels &lt; 1:\n        raise ValidationError(\"max_levels must be &gt;= 1.\")\n    if extrema_order &lt; 1:\n        raise ValidationError(\"extrema_order must be &gt;= 1.\")\n\n    prices = pd.to_numeric(df[column], errors=\"coerce\").dropna().to_numpy(dtype=float)\n    if prices.size &lt; extrema_order * 2 + 3:\n        raise ValidationError(\"Not enough data to find support/resistance.\")\n\n    minima_indices = argrelextrema(prices, np.less_equal, order=extrema_order)[0]\n    maxima_indices = argrelextrema(prices, np.greater_equal, order=extrema_order)[0]\n    current_price = float(prices[-1])\n    tolerance = max(current_price * tolerance_ratio, 1e-9)\n\n    support_values = [float(prices[idx]) for idx in minima_indices if prices[idx] &lt;= current_price]\n    resistance_values = [float(prices[idx]) for idx in maxima_indices if prices[idx] &gt;= current_price]\n\n    supports = _build_levels(\n        candidate_values=support_values,\n        extrema_values=np.asarray([prices[idx] for idx in minima_indices], dtype=float),\n        all_prices=prices,\n        tolerance=tolerance,\n        max_levels=max_levels,\n        reverse=True,\n    )\n    resistances = _build_levels(\n        candidate_values=resistance_values,\n        extrema_values=np.asarray([prices[idx] for idx in maxima_indices], dtype=float),\n        all_prices=prices,\n        tolerance=tolerance,\n        max_levels=max_levels,\n        reverse=False,\n    )\n\n    return LevelStats(supports=supports, resistances=resistances)\n</code></pre>"},{"location":"reference/narrata/analysis/support_resistance/#narrata.analysis.support_resistance.describe_support_resistance","title":"<code>describe_support_resistance(stats, currency_symbol='$', precision=2)</code>","text":"<p>Render support and resistance levels as one line.</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>LevelStats</code> <p>Support and resistance stats.</p> required <code>currency_symbol</code> <code>str</code> <p>Currency symbol for formatting.</p> <code>'$'</code> <code>precision</code> <code>int</code> <p>Decimal precision.</p> <code>2</code> <p>Returns:</p> Type Description <code>str</code> <p>Human-readable support/resistance narration.</p> Source code in <code>src/narrata/narrata/analysis/support_resistance.py</code> <pre><code>def describe_support_resistance(stats: LevelStats, currency_symbol: str = \"$\", precision: int = 2) -&gt; str:\n    \"\"\"Render support and resistance levels as one line.\n\n    :param stats: Support and resistance stats.\n    :param currency_symbol: Currency symbol for formatting.\n    :param precision: Decimal precision.\n    :return: Human-readable support/resistance narration.\n    \"\"\"\n    support_text = _format_levels(stats.supports, currency_symbol, precision)\n    resistance_text = _format_levels(stats.resistances, currency_symbol, precision)\n    return f\"Support: {support_text}  Resistance: {resistance_text}\"\n</code></pre>"},{"location":"reference/narrata/analysis/symbolic/","title":"symbolic","text":""},{"location":"reference/narrata/analysis/symbolic/#narrata.analysis.symbolic","title":"<code>narrata.analysis.symbolic</code>","text":"<p>Symbolic time-series encodings.</p> <p>Implements SAX and ASTRIDE-style symbolization.</p> <p>Uses tslearn's SAX implementation when available, and falls back to an in-house SAX implementation otherwise.  ASTRIDE uses ruptures for change-point-based adaptive segmentation.</p> <p>References:     [SAX] Lin et al., \"Experiencing SAX\", DMKD 2007.     [ASTRIDE] Combettes et al., \"An Adaptive Symbolization for Time Series\",     EUSIPCO 2024. arXiv:2302.04097.</p>"},{"location":"reference/narrata/analysis/symbolic/#narrata.analysis.symbolic.sax_encode","title":"<code>sax_encode(df, column='Close', word_size=16, alphabet_size=8)</code>","text":"<p>Encode a series with SAX-style symbolization.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>column</code> <code>str</code> <p>Price column to encode.</p> <code>'Close'</code> <code>word_size</code> <code>int</code> <p>Number of PAA segments.</p> <code>16</code> <code>alphabet_size</code> <code>int</code> <p>Number of symbols in alphabet.</p> <code>8</code> <p>Returns:</p> Type Description <code>SymbolicStats</code> <p>Structured symbolic encoding result.</p> Source code in <code>src/narrata/narrata/analysis/symbolic.py</code> <pre><code>def sax_encode(df: pd.DataFrame, column: str = \"Close\", word_size: int = 16, alphabet_size: int = 8) -&gt; SymbolicStats:\n    \"\"\"Encode a series with SAX-style symbolization.\n\n    :param df: OHLCV DataFrame.\n    :param column: Price column to encode.\n    :param word_size: Number of PAA segments.\n    :param alphabet_size: Number of symbols in alphabet.\n    :return: Structured symbolic encoding result.\n    \"\"\"\n    validate_ohlcv_frame(df)\n    if column not in df.columns:\n        raise ValidationError(f\"Column '{column}' does not exist in DataFrame.\")\n    if word_size &lt; 2:\n        raise ValidationError(\"word_size must be &gt;= 2.\")\n    if alphabet_size &lt; 2 or alphabet_size &gt; 26:\n        raise ValidationError(\"alphabet_size must be between 2 and 26.\")\n\n    values = pd.to_numeric(df[column], errors=\"coerce\").dropna().to_numpy(dtype=float)\n    if values.size &lt; word_size:\n        raise ValidationError(\"Not enough data points for requested word_size.\")\n\n    if SymbolicAggregateApproximation is not None:\n        symbols = _sax_encode_with_tslearn(\n            values=values,\n            word_size=word_size,\n            alphabet_size=alphabet_size,\n            sax_cls=SymbolicAggregateApproximation,\n        )\n    else:\n        symbols = _sax_encode_inhouse(values=values, word_size=word_size, alphabet_size=alphabet_size)\n\n    return SymbolicStats(\n        method=\"SAX\",\n        word_size=word_size,\n        alphabet_size=alphabet_size,\n        symbols=symbols,\n    )\n</code></pre>"},{"location":"reference/narrata/analysis/symbolic/#narrata.analysis.symbolic.describe_sax","title":"<code>describe_sax(stats)</code>","text":"<p>Render symbolic encoding as one line.</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>SymbolicStats</code> <p>Symbolic encoding result.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Human-readable symbolic description.</p> Source code in <code>src/narrata/narrata/analysis/symbolic.py</code> <pre><code>def describe_sax(stats: SymbolicStats) -&gt; str:\n    \"\"\"Render symbolic encoding as one line.\n\n    :param stats: Symbolic encoding result.\n    :return: Human-readable symbolic description.\n    \"\"\"\n    return f\"SAX({stats.word_size}): {stats.symbols}\"\n</code></pre>"},{"location":"reference/narrata/analysis/symbolic/#narrata.analysis.symbolic.astride_encode","title":"<code>astride_encode(df, column='Close', n_segments=16, alphabet_size=8, penalty=3.0)</code>","text":"<p>Encode a series with ASTRIDE-style adaptive symbolization.</p> <p>Uses change-point detection (ruptures) to find segment boundaries that align with regime changes, then quantizes segment means into symbols. Unlike SAX, segments have variable length.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>column</code> <code>str</code> <p>Price column to encode.</p> <code>'Close'</code> <code>n_segments</code> <code>int</code> <p>Approximate number of segments.</p> <code>16</code> <code>alphabet_size</code> <code>int</code> <p>Number of symbols in alphabet.</p> <code>8</code> <code>penalty</code> <code>float</code> <p>Ruptures PELT penalty parameter.</p> <code>3.0</code> <p>Returns:</p> Type Description <code>SymbolicStats</code> <p>Structured symbolic encoding result.</p> Source code in <code>src/narrata/narrata/analysis/symbolic.py</code> <pre><code>def astride_encode(\n    df: pd.DataFrame,\n    column: str = \"Close\",\n    n_segments: int = 16,\n    alphabet_size: int = 8,\n    penalty: float = 3.0,\n) -&gt; SymbolicStats:\n    \"\"\"Encode a series with ASTRIDE-style adaptive symbolization.\n\n    Uses change-point detection (ruptures) to find segment boundaries that\n    align with regime changes, then quantizes segment means into symbols.\n    Unlike SAX, segments have variable length.\n\n    :param df: OHLCV DataFrame.\n    :param column: Price column to encode.\n    :param n_segments: Approximate number of segments.\n    :param alphabet_size: Number of symbols in alphabet.\n    :param penalty: Ruptures PELT penalty parameter.\n    :return: Structured symbolic encoding result.\n    \"\"\"\n    validate_ohlcv_frame(df)\n    if column not in df.columns:\n        raise ValidationError(f\"Column '{column}' does not exist in DataFrame.\")\n    if n_segments &lt; 2:\n        raise ValidationError(\"n_segments must be &gt;= 2.\")\n    if alphabet_size &lt; 2 or alphabet_size &gt; 26:\n        raise ValidationError(\"alphabet_size must be between 2 and 26.\")\n    if rpt is None:\n        raise ValidationError(\n            \"ASTRIDE encoding requires the 'ruptures' package. Install with: pip install narrata[symbolic]\"\n        )\n\n    values = pd.to_numeric(df[column], errors=\"coerce\").dropna().to_numpy(dtype=float)\n    if values.size &lt; n_segments:\n        raise ValidationError(\"Not enough data points for requested n_segments.\")\n\n    normalized = _z_normalize(values)\n    symbols = _astride_encode_core(normalized, n_segments=n_segments, alphabet_size=alphabet_size, penalty=penalty)\n\n    return SymbolicStats(\n        method=\"ASTRIDE\",\n        word_size=len(symbols),\n        alphabet_size=alphabet_size,\n        symbols=symbols,\n    )\n</code></pre>"},{"location":"reference/narrata/analysis/symbolic/#narrata.analysis.symbolic.describe_astride","title":"<code>describe_astride(stats)</code>","text":"<p>Render ASTRIDE symbolic encoding as one line.</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>SymbolicStats</code> <p>Symbolic encoding result.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Human-readable symbolic description.</p> Source code in <code>src/narrata/narrata/analysis/symbolic.py</code> <pre><code>def describe_astride(stats: SymbolicStats) -&gt; str:\n    \"\"\"Render ASTRIDE symbolic encoding as one line.\n\n    :param stats: Symbolic encoding result.\n    :return: Human-readable symbolic description.\n    \"\"\"\n    return f\"ASTRIDE({stats.word_size}): {stats.symbols}\"\n</code></pre>"},{"location":"reference/narrata/composition/","title":"composition","text":""},{"location":"reference/narrata/composition/#narrata.composition","title":"<code>narrata.composition</code>","text":"<p>Narration composition entry points.</p>"},{"location":"reference/narrata/composition/narrate/","title":"narrate","text":""},{"location":"reference/narrata/composition/narrate/#narrata.composition.narrate","title":"<code>narrata.composition.narrate</code>","text":"<p>High-level narration composition for LLM-ready text.</p>"},{"location":"reference/narrata/composition/narrate/#narrata.composition.narrate.narrate","title":"<code>narrate(df, *, column='Close', ticker=None, include_summary=True, include_sparkline=True, include_regime=True, include_indicators=True, include_symbolic=True, include_patterns=True, include_support_resistance=True, sparkline_width=20, symbolic_word_size=16, symbolic_alphabet_size=8, digit_level=False, output_format='plain')</code>","text":"<p>Compose selected narration components into one final text output.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>OHLCV DataFrame.</p> required <code>column</code> <code>str</code> <p>Price column used across modules.</p> <code>'Close'</code> <code>ticker</code> <code>str | None</code> <p>Optional ticker override.</p> <code>None</code> <code>include_summary</code> <code>bool</code> <p>Include summary lines.</p> <code>True</code> <code>include_sparkline</code> <code>bool</code> <p>Include sparkline in overview line.</p> <code>True</code> <code>include_regime</code> <code>bool</code> <p>Include regime classification line.</p> <code>True</code> <code>include_indicators</code> <code>bool</code> <p>Include indicators line.</p> <code>True</code> <code>include_symbolic</code> <code>bool</code> <p>Include SAX line.</p> <code>True</code> <code>include_patterns</code> <code>bool</code> <p>Include chart and candlestick pattern lines.</p> <code>True</code> <code>include_support_resistance</code> <code>bool</code> <p>Include support/resistance line.</p> <code>True</code> <code>sparkline_width</code> <code>int</code> <p>Sparkline width.</p> <code>20</code> <code>symbolic_word_size</code> <code>int</code> <p>SAX word size.</p> <code>16</code> <code>symbolic_alphabet_size</code> <code>int</code> <p>SAX alphabet size.</p> <code>8</code> <code>digit_level</code> <code>bool</code> <p>Apply digit-level tokenization to final text.</p> <code>False</code> <code>output_format</code> <code>OutputFormat</code> <p>Output format.</p> <code>'plain'</code> <p>Returns:</p> Type Description <code>str</code> <p>Composed narration text.</p> Source code in <code>src/narrata/narrata/composition/narrate.py</code> <pre><code>def narrate(\n    df: pd.DataFrame,\n    *,\n    column: str = \"Close\",\n    ticker: str | None = None,\n    include_summary: bool = True,\n    include_sparkline: bool = True,\n    include_regime: bool = True,\n    include_indicators: bool = True,\n    include_symbolic: bool = True,\n    include_patterns: bool = True,\n    include_support_resistance: bool = True,\n    sparkline_width: int = 20,\n    symbolic_word_size: int = 16,\n    symbolic_alphabet_size: int = 8,\n    digit_level: bool = False,\n    output_format: OutputFormat = \"plain\",\n) -&gt; str:\n    \"\"\"Compose selected narration components into one final text output.\n\n    :param df: OHLCV DataFrame.\n    :param column: Price column used across modules.\n    :param ticker: Optional ticker override.\n    :param include_summary: Include summary lines.\n    :param include_sparkline: Include sparkline in overview line.\n    :param include_regime: Include regime classification line.\n    :param include_indicators: Include indicators line.\n    :param include_symbolic: Include SAX line.\n    :param include_patterns: Include chart and candlestick pattern lines.\n    :param include_support_resistance: Include support/resistance line.\n    :param sparkline_width: Sparkline width.\n    :param symbolic_word_size: SAX word size.\n    :param symbolic_alphabet_size: SAX alphabet size.\n    :param digit_level: Apply digit-level tokenization to final text.\n    :param output_format: Output format.\n    :return: Composed narration text.\n    \"\"\"\n    validate_ohlcv_frame(df)\n\n    if column not in df.columns:\n        raise ValidationError(f\"Column '{column}' does not exist in DataFrame.\")\n\n    if not any(\n        [\n            include_summary,\n            include_sparkline,\n            include_regime,\n            include_indicators,\n            include_symbolic,\n            include_patterns,\n            include_support_resistance,\n        ]\n    ):\n        raise ValidationError(\"At least one narration component must be enabled.\")\n\n    sections: dict[str, str] = {}\n    summary = analyze_summary(df, column=column, ticker=ticker)\n\n    if include_summary or include_sparkline:\n        entity_name = summary.ticker or summary.column\n        if include_sparkline:\n            values = pd.to_numeric(df[column], errors=\"coerce\").dropna().tolist()\n            if not values:\n                raise ValidationError(f\"Column '{column}' contains no numeric values for sparkline rendering.\")\n            sparkline = make_sparkline(values, width=sparkline_width)\n            sections[\"overview\"] = f\"{entity_name} ({summary.points} pts, {summary.frequency}): {sparkline}\"\n        else:\n            sections[\"overview\"] = f\"{entity_name} ({summary.points} pts, {summary.frequency})\"\n\n    if include_summary:\n        sections[\"date_range\"] = f\"Date range: {summary.start_date.isoformat()} to {summary.end_date.isoformat()}\"\n        summary_lines = describe_summary(summary, include_header=False).splitlines()\n        sections[\"range\"] = summary_lines[0]\n        sections[\"change\"] = summary_lines[1]\n\n    if include_regime:\n        sections[\"regime\"] = describe_regime(analyze_regime(df, column=column))\n\n    if include_indicators:\n        sections[\"indicators\"] = describe_indicators(analyze_indicators(df, column=column))\n\n    if include_symbolic:\n        symbolic = sax_encode(df, column=column, word_size=symbolic_word_size, alphabet_size=symbolic_alphabet_size)\n        sections[\"symbolic\"] = describe_sax(symbolic)\n\n    if include_patterns:\n        pattern_stats = detect_patterns(df)\n        sections[\"patterns\"] = describe_patterns(pattern_stats)\n        sections[\"candlestick\"] = describe_candlestick(pattern_stats)\n\n    if include_support_resistance:\n        levels = find_support_resistance(df, column=column)\n        sections[\"levels\"] = describe_support_resistance(levels)\n\n    rendered = format_sections(sections, output_format=output_format)\n    if digit_level:\n        return digit_tokenize(rendered)\n\n    return rendered\n</code></pre>"},{"location":"reference/narrata/compression/","title":"compression","text":""},{"location":"reference/narrata/compression/#narrata.compression","title":"<code>narrata.compression</code>","text":"<p>Token-oriented compression helpers for narrata.</p>"},{"location":"reference/narrata/compression/#narrata.compression.digit_tokenize","title":"<code>digit_tokenize(text, add_note=True)</code>","text":"<p>Split every digit into standalone tokens separated by spaces.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Input text.</p> required <code>add_note</code> <code>bool</code> <p>Prefix output with a short marker when digit splitting is applied.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>Digit-tokenized text.</p> Source code in <code>src/narrata/narrata/compression/digits.py</code> <pre><code>def digit_tokenize(text: str, add_note: bool = True) -&gt; str:\n    \"\"\"Split every digit into standalone tokens separated by spaces.\n\n    :param text: Input text.\n    :param add_note: Prefix output with a short marker when digit splitting is applied.\n    :return: Digit-tokenized text.\n    \"\"\"\n    spaced = _DIGIT_PATTERN.sub(r\" \\1 \", text)\n    tokenized = \" \".join(spaced.split())\n    if add_note:\n        return f\"&lt;digits-split&gt;\\n{tokenized}\"\n    return tokenized\n</code></pre>"},{"location":"reference/narrata/compression/digits/","title":"digits","text":""},{"location":"reference/narrata/compression/digits/#narrata.compression.digits","title":"<code>narrata.compression.digits</code>","text":"<p>Digit-level tokenization utilities.</p> <p>References:     [LLMTime] Gruver et al., \"Large Language Models Are Zero-Shot     Time Series Forecasters\", NeurIPS 2023. arXiv:2310.07820</p>"},{"location":"reference/narrata/compression/digits/#narrata.compression.digits.digit_tokenize","title":"<code>digit_tokenize(text, add_note=True)</code>","text":"<p>Split every digit into standalone tokens separated by spaces.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Input text.</p> required <code>add_note</code> <code>bool</code> <p>Prefix output with a short marker when digit splitting is applied.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>Digit-tokenized text.</p> Source code in <code>src/narrata/narrata/compression/digits.py</code> <pre><code>def digit_tokenize(text: str, add_note: bool = True) -&gt; str:\n    \"\"\"Split every digit into standalone tokens separated by spaces.\n\n    :param text: Input text.\n    :param add_note: Prefix output with a short marker when digit splitting is applied.\n    :return: Digit-tokenized text.\n    \"\"\"\n    spaced = _DIGIT_PATTERN.sub(r\" \\1 \", text)\n    tokenized = \" \".join(spaced.split())\n    if add_note:\n        return f\"&lt;digits-split&gt;\\n{tokenized}\"\n    return tokenized\n</code></pre>"},{"location":"reference/narrata/exceptions/","title":"exceptions","text":""},{"location":"reference/narrata/exceptions/#narrata.exceptions","title":"<code>narrata.exceptions</code>","text":"<p>Custom exception hierarchy for narrata.</p>"},{"location":"reference/narrata/exceptions/#narrata.exceptions.NarrataError","title":"<code>NarrataError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for narrata.</p>"},{"location":"reference/narrata/exceptions/#narrata.exceptions.ValidationError","title":"<code>ValidationError</code>","text":"<p>               Bases: <code>NarrataError</code></p> <p>Raised when input data does not meet narrata contracts.</p>"},{"location":"reference/narrata/exceptions/#narrata.exceptions.UnsupportedFormatError","title":"<code>UnsupportedFormatError</code>","text":"<p>               Bases: <code>NarrataError</code></p> <p>Raised when a requested output format is unsupported.</p>"},{"location":"reference/narrata/formatting/","title":"formatting","text":""},{"location":"reference/narrata/formatting/#narrata.formatting","title":"<code>narrata.formatting</code>","text":"<p>Output formatters for narrata text sections.</p>"},{"location":"reference/narrata/formatting/#narrata.formatting.format_sections","title":"<code>format_sections(sections, output_format='plain')</code>","text":"<p>Format narration sections for the selected output format.</p> <p>Parameters:</p> Name Type Description Default <code>sections</code> <code>Mapping[str, str]</code> <p>Ordered mapping of section keys to rendered text.</p> required <code>output_format</code> <code>OutputFormat</code> <p>Output format selector.</p> <code>'plain'</code> <p>Returns:</p> Type Description <code>str</code> <p>Serialized text output.</p> Source code in <code>src/narrata/narrata/formatting/serializers.py</code> <pre><code>def format_sections(sections: Mapping[str, str], output_format: OutputFormat = \"plain\") -&gt; str:\n    \"\"\"Format narration sections for the selected output format.\n\n    :param sections: Ordered mapping of section keys to rendered text.\n    :param output_format: Output format selector.\n    :return: Serialized text output.\n    \"\"\"\n    if output_format == \"plain\":\n        return to_plain(list(sections.values()))\n    if output_format == \"markdown_kv\":\n        return to_markdown_kv(sections)\n    if output_format == \"toon\":\n        return to_toon(sections)\n    raise UnsupportedFormatError(f\"Unsupported output format: {output_format}\")\n</code></pre>"},{"location":"reference/narrata/formatting/#narrata.formatting.to_markdown_kv","title":"<code>to_markdown_kv(data)</code>","text":"<p>Serialize key-value pairs as Markdown.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Mapping[str, object]</code> <p>Mapping of section names to values.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Markdown key-value representation.</p> Source code in <code>src/narrata/narrata/formatting/serializers.py</code> <pre><code>def to_markdown_kv(data: Mapping[str, object]) -&gt; str:\n    \"\"\"Serialize key-value pairs as Markdown.\n\n    :param data: Mapping of section names to values.\n    :return: Markdown key-value representation.\n    \"\"\"\n    return \"\\n\".join(f\"**{key}**: {value}\" for key, value in data.items())\n</code></pre>"},{"location":"reference/narrata/formatting/#narrata.formatting.to_plain","title":"<code>to_plain(lines)</code>","text":"<p>Join non-empty lines into plain-text output.</p> <p>Parameters:</p> Name Type Description Default <code>lines</code> <code>Sequence[str]</code> <p>Ordered lines to join.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Plain-text representation.</p> Source code in <code>src/narrata/narrata/formatting/serializers.py</code> <pre><code>def to_plain(lines: Sequence[str]) -&gt; str:\n    \"\"\"Join non-empty lines into plain-text output.\n\n    :param lines: Ordered lines to join.\n    :return: Plain-text representation.\n    \"\"\"\n    return \"\\n\".join(line for line in lines if line)\n</code></pre>"},{"location":"reference/narrata/formatting/#narrata.formatting.to_toon","title":"<code>to_toon(data)</code>","text":"<p>Serialize mappings to TOON.</p> <p>Requires the <code>toons</code> package.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Mapping[str, object]</code> <p>Mapping of section names to values.</p> required <p>Returns:</p> Type Description <code>str</code> <p>TOON string representation.</p> Source code in <code>src/narrata/narrata/formatting/serializers.py</code> <pre><code>def to_toon(data: Mapping[str, object]) -&gt; str:\n    \"\"\"Serialize mappings to TOON.\n\n    Requires the ``toons`` package.\n\n    :param data: Mapping of section names to values.\n    :return: TOON string representation.\n    \"\"\"\n    return str(dumps(dict(data)))\n</code></pre>"},{"location":"reference/narrata/formatting/serializers/","title":"serializers","text":""},{"location":"reference/narrata/formatting/serializers/#narrata.formatting.serializers","title":"<code>narrata.formatting.serializers</code>","text":"<p>Serializers for final narration output.</p>"},{"location":"reference/narrata/formatting/serializers/#narrata.formatting.serializers.to_plain","title":"<code>to_plain(lines)</code>","text":"<p>Join non-empty lines into plain-text output.</p> <p>Parameters:</p> Name Type Description Default <code>lines</code> <code>Sequence[str]</code> <p>Ordered lines to join.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Plain-text representation.</p> Source code in <code>src/narrata/narrata/formatting/serializers.py</code> <pre><code>def to_plain(lines: Sequence[str]) -&gt; str:\n    \"\"\"Join non-empty lines into plain-text output.\n\n    :param lines: Ordered lines to join.\n    :return: Plain-text representation.\n    \"\"\"\n    return \"\\n\".join(line for line in lines if line)\n</code></pre>"},{"location":"reference/narrata/formatting/serializers/#narrata.formatting.serializers.to_markdown_kv","title":"<code>to_markdown_kv(data)</code>","text":"<p>Serialize key-value pairs as Markdown.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Mapping[str, object]</code> <p>Mapping of section names to values.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Markdown key-value representation.</p> Source code in <code>src/narrata/narrata/formatting/serializers.py</code> <pre><code>def to_markdown_kv(data: Mapping[str, object]) -&gt; str:\n    \"\"\"Serialize key-value pairs as Markdown.\n\n    :param data: Mapping of section names to values.\n    :return: Markdown key-value representation.\n    \"\"\"\n    return \"\\n\".join(f\"**{key}**: {value}\" for key, value in data.items())\n</code></pre>"},{"location":"reference/narrata/formatting/serializers/#narrata.formatting.serializers.to_toon","title":"<code>to_toon(data)</code>","text":"<p>Serialize mappings to TOON.</p> <p>Requires the <code>toons</code> package.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Mapping[str, object]</code> <p>Mapping of section names to values.</p> required <p>Returns:</p> Type Description <code>str</code> <p>TOON string representation.</p> Source code in <code>src/narrata/narrata/formatting/serializers.py</code> <pre><code>def to_toon(data: Mapping[str, object]) -&gt; str:\n    \"\"\"Serialize mappings to TOON.\n\n    Requires the ``toons`` package.\n\n    :param data: Mapping of section names to values.\n    :return: TOON string representation.\n    \"\"\"\n    return str(dumps(dict(data)))\n</code></pre>"},{"location":"reference/narrata/formatting/serializers/#narrata.formatting.serializers.format_sections","title":"<code>format_sections(sections, output_format='plain')</code>","text":"<p>Format narration sections for the selected output format.</p> <p>Parameters:</p> Name Type Description Default <code>sections</code> <code>Mapping[str, str]</code> <p>Ordered mapping of section keys to rendered text.</p> required <code>output_format</code> <code>OutputFormat</code> <p>Output format selector.</p> <code>'plain'</code> <p>Returns:</p> Type Description <code>str</code> <p>Serialized text output.</p> Source code in <code>src/narrata/narrata/formatting/serializers.py</code> <pre><code>def format_sections(sections: Mapping[str, str], output_format: OutputFormat = \"plain\") -&gt; str:\n    \"\"\"Format narration sections for the selected output format.\n\n    :param sections: Ordered mapping of section keys to rendered text.\n    :param output_format: Output format selector.\n    :return: Serialized text output.\n    \"\"\"\n    if output_format == \"plain\":\n        return to_plain(list(sections.values()))\n    if output_format == \"markdown_kv\":\n        return to_markdown_kv(sections)\n    if output_format == \"toon\":\n        return to_toon(sections)\n    raise UnsupportedFormatError(f\"Unsupported output format: {output_format}\")\n</code></pre>"},{"location":"reference/narrata/mcp_api/","title":"mcp_api","text":""},{"location":"reference/narrata/mcp_api/#narrata.mcp_api","title":"<code>narrata.mcp_api</code>","text":"<p>High-level adapters for MCP tools built on top of narrata public APIs.</p> <p>This module converts row-wise OHLCV records into DataFrames and exposes high-level helper functions suitable for MCP tool handlers.</p>"},{"location":"reference/narrata/mcp_api/#narrata.mcp_api.ohlcv_records_to_frame","title":"<code>ohlcv_records_to_frame(records, *, ticker=None, timestamp_field='timestamp', deduplicate_timestamps=True, sort_index=True)</code>","text":"<p>Convert OHLCV records into a narrata-ready DataFrame.</p> <p>Missing numeric values are allowed and passed through as NaN so narrata analytics can handle patchy data gracefully.</p> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>list[dict[str, Any]]</code> <p>List of OHLCV row dictionaries.</p> required <code>ticker</code> <code>str | None</code> <p>Optional ticker symbol attached to <code>DataFrame.attrs[\"ticker\"]</code>.</p> <code>None</code> <code>timestamp_field</code> <code>str</code> <p>Preferred timestamp field name in each record.</p> <code>'timestamp'</code> <code>deduplicate_timestamps</code> <code>bool</code> <p>If <code>True</code>, keep only the latest row for duplicates.</p> <code>True</code> <code>sort_index</code> <code>bool</code> <p>If <code>True</code>, sort by timestamp ascending.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame indexed by timestamp with canonical OHLCV column names.</p> Source code in <code>src/narrata/narrata/mcp_api.py</code> <pre><code>def ohlcv_records_to_frame(\n    records: list[dict[str, Any]],\n    *,\n    ticker: str | None = None,\n    timestamp_field: str = \"timestamp\",\n    deduplicate_timestamps: bool = True,\n    sort_index: bool = True,\n) -&gt; pd.DataFrame:\n    \"\"\"Convert OHLCV records into a narrata-ready DataFrame.\n\n    Missing numeric values are allowed and passed through as NaN so narrata\n    analytics can handle patchy data gracefully.\n\n    :param records: List of OHLCV row dictionaries.\n    :param ticker: Optional ticker symbol attached to ``DataFrame.attrs[\"ticker\"]``.\n    :param timestamp_field: Preferred timestamp field name in each record.\n    :param deduplicate_timestamps: If ``True``, keep only the latest row for duplicates.\n    :param sort_index: If ``True``, sort by timestamp ascending.\n    :return: DataFrame indexed by timestamp with canonical OHLCV column names.\n    \"\"\"\n    if not records:\n        raise ValidationError(\"At least one OHLCV record is required.\")\n\n    raw = pd.DataFrame.from_records(records)\n    timestamp_column = _resolve_timestamp_column(raw, preferred=timestamp_field)\n\n    timestamp = pd.to_datetime(raw[timestamp_column], errors=\"coerce\")\n    if timestamp.isna().all():\n        raise ValidationError(f\"Timestamp column '{timestamp_column}' contains no parseable datetime values.\")\n\n    frame = raw.copy()\n    frame.index = pd.DatetimeIndex(timestamp)\n    frame = frame[~frame.index.isna()]\n\n    if deduplicate_timestamps:\n        frame = frame[~frame.index.duplicated(keep=\"last\")]\n    if sort_index:\n        frame = frame.sort_index()\n\n    canonical: dict[str, pd.Series] = {}\n    for target in REQUIRED_OHLCV_COLUMNS:\n        source = _resolve_ohlcv_column(frame, target)\n        canonical[target] = pd.to_numeric(frame[source], errors=\"coerce\")\n\n    result = pd.DataFrame(canonical, index=frame.index)\n    if ticker and ticker.strip():\n        result.attrs[\"ticker\"] = ticker.strip()\n    return result\n</code></pre>"},{"location":"reference/narrata/mcp_api/#narrata.mcp_api.narrate_from_records","title":"<code>narrate_from_records(records, *, ticker=None, timestamp_field='timestamp', deduplicate_timestamps=True, sort_index=True, column='Close', include_summary=True, include_sparkline=True, include_regime=True, include_indicators=True, include_symbolic=True, include_patterns=True, include_support_resistance=True, sparkline_width=20, symbolic_word_size=16, symbolic_alphabet_size=8, digit_level=False, output_format='plain')</code>","text":"<p>Generate the full narrata text from OHLCV records.</p> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>list[dict[str, Any]]</code> <p>List of OHLCV row dictionaries.</p> required <code>ticker</code> <code>str | None</code> <p>Optional ticker symbol.</p> <code>None</code> <code>timestamp_field</code> <code>str</code> <p>Preferred timestamp field name.</p> <code>'timestamp'</code> <code>deduplicate_timestamps</code> <code>bool</code> <p>Keep only latest row for duplicate timestamps.</p> <code>True</code> <code>sort_index</code> <code>bool</code> <p>Sort by timestamp ascending.</p> <code>True</code> <code>column</code> <code>str</code> <p>Price column used across analyzers.</p> <code>'Close'</code> <code>include_summary</code> <code>bool</code> <p>Include summary lines.</p> <code>True</code> <code>include_sparkline</code> <code>bool</code> <p>Include sparkline in overview.</p> <code>True</code> <code>include_regime</code> <code>bool</code> <p>Include regime line.</p> <code>True</code> <code>include_indicators</code> <code>bool</code> <p>Include indicator lines.</p> <code>True</code> <code>include_symbolic</code> <code>bool</code> <p>Include SAX line.</p> <code>True</code> <code>include_patterns</code> <code>bool</code> <p>Include pattern lines.</p> <code>True</code> <code>include_support_resistance</code> <code>bool</code> <p>Include support/resistance line.</p> <code>True</code> <code>sparkline_width</code> <code>int</code> <p>Sparkline width.</p> <code>20</code> <code>symbolic_word_size</code> <code>int</code> <p>SAX word size.</p> <code>16</code> <code>symbolic_alphabet_size</code> <code>int</code> <p>SAX alphabet size.</p> <code>8</code> <code>digit_level</code> <code>bool</code> <p>Enable digit tokenization in final output.</p> <code>False</code> <code>output_format</code> <code>str</code> <p>Output format (plain, markdown_kv, toon).</p> <code>'plain'</code> <p>Returns:</p> Type Description <code>str</code> <p>Full narrata output text.</p> Source code in <code>src/narrata/narrata/mcp_api.py</code> <pre><code>def narrate_from_records(\n    records: list[dict[str, Any]],\n    *,\n    ticker: str | None = None,\n    timestamp_field: str = \"timestamp\",\n    deduplicate_timestamps: bool = True,\n    sort_index: bool = True,\n    column: str = \"Close\",\n    include_summary: bool = True,\n    include_sparkline: bool = True,\n    include_regime: bool = True,\n    include_indicators: bool = True,\n    include_symbolic: bool = True,\n    include_patterns: bool = True,\n    include_support_resistance: bool = True,\n    sparkline_width: int = 20,\n    symbolic_word_size: int = 16,\n    symbolic_alphabet_size: int = 8,\n    digit_level: bool = False,\n    output_format: str = \"plain\",\n) -&gt; str:\n    \"\"\"Generate the full narrata text from OHLCV records.\n\n    :param records: List of OHLCV row dictionaries.\n    :param ticker: Optional ticker symbol.\n    :param timestamp_field: Preferred timestamp field name.\n    :param deduplicate_timestamps: Keep only latest row for duplicate timestamps.\n    :param sort_index: Sort by timestamp ascending.\n    :param column: Price column used across analyzers.\n    :param include_summary: Include summary lines.\n    :param include_sparkline: Include sparkline in overview.\n    :param include_regime: Include regime line.\n    :param include_indicators: Include indicator lines.\n    :param include_symbolic: Include SAX line.\n    :param include_patterns: Include pattern lines.\n    :param include_support_resistance: Include support/resistance line.\n    :param sparkline_width: Sparkline width.\n    :param symbolic_word_size: SAX word size.\n    :param symbolic_alphabet_size: SAX alphabet size.\n    :param digit_level: Enable digit tokenization in final output.\n    :param output_format: Output format (plain, markdown_kv, toon).\n    :return: Full narrata output text.\n    \"\"\"\n    frame = ohlcv_records_to_frame(\n        records,\n        ticker=ticker,\n        timestamp_field=timestamp_field,\n        deduplicate_timestamps=deduplicate_timestamps,\n        sort_index=sort_index,\n    )\n    return narrate(\n        frame,\n        column=column,\n        include_summary=include_summary,\n        include_sparkline=include_sparkline,\n        include_regime=include_regime,\n        include_indicators=include_indicators,\n        include_symbolic=include_symbolic,\n        include_patterns=include_patterns,\n        include_support_resistance=include_support_resistance,\n        sparkline_width=sparkline_width,\n        symbolic_word_size=symbolic_word_size,\n        symbolic_alphabet_size=symbolic_alphabet_size,\n        digit_level=digit_level,\n        output_format=output_format,  # type: ignore[arg-type]\n    )\n</code></pre>"},{"location":"reference/narrata/mcp_api/#narrata.mcp_api.summary_from_records","title":"<code>summary_from_records(records, *, ticker=None, timestamp_field='timestamp', deduplicate_timestamps=True, sort_index=True, column='Close')</code>","text":"<p>Compute summary stats and text from OHLCV records.</p> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>list[dict[str, Any]]</code> <p>List of OHLCV row dictionaries.</p> required <code>ticker</code> <code>str | None</code> <p>Optional ticker symbol.</p> <code>None</code> <code>timestamp_field</code> <code>str</code> <p>Preferred timestamp field name.</p> <code>'timestamp'</code> <code>deduplicate_timestamps</code> <code>bool</code> <p>Keep only latest row for duplicate timestamps.</p> <code>True</code> <code>sort_index</code> <code>bool</code> <p>Sort by timestamp ascending.</p> <code>True</code> <code>column</code> <code>str</code> <p>Price column to summarize.</p> <code>'Close'</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict with <code>summary</code> (structured) and <code>text</code> fields.</p> Source code in <code>src/narrata/narrata/mcp_api.py</code> <pre><code>def summary_from_records(\n    records: list[dict[str, Any]],\n    *,\n    ticker: str | None = None,\n    timestamp_field: str = \"timestamp\",\n    deduplicate_timestamps: bool = True,\n    sort_index: bool = True,\n    column: str = \"Close\",\n) -&gt; dict[str, Any]:\n    \"\"\"Compute summary stats and text from OHLCV records.\n\n    :param records: List of OHLCV row dictionaries.\n    :param ticker: Optional ticker symbol.\n    :param timestamp_field: Preferred timestamp field name.\n    :param deduplicate_timestamps: Keep only latest row for duplicate timestamps.\n    :param sort_index: Sort by timestamp ascending.\n    :param column: Price column to summarize.\n    :return: Dict with ``summary`` (structured) and ``text`` fields.\n    \"\"\"\n    frame = ohlcv_records_to_frame(\n        records,\n        ticker=ticker,\n        timestamp_field=timestamp_field,\n        deduplicate_timestamps=deduplicate_timestamps,\n        sort_index=sort_index,\n    )\n    stats = analyze_summary(frame, column=column)\n    return {\"summary\": _to_serializable(stats), \"text\": describe_summary(stats)}\n</code></pre>"},{"location":"reference/narrata/mcp_api/#narrata.mcp_api.regime_from_records","title":"<code>regime_from_records(records, *, ticker=None, timestamp_field='timestamp', deduplicate_timestamps=True, sort_index=True, column='Close', window=20, penalty=3.0, trend_threshold=0.0005)</code>","text":"<p>Compute current regime classification and narration.</p> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>list[dict[str, Any]]</code> <p>List of OHLCV row dictionaries.</p> required <code>ticker</code> <code>str | None</code> <p>Optional ticker symbol.</p> <code>None</code> <code>timestamp_field</code> <code>str</code> <p>Preferred timestamp field name.</p> <code>'timestamp'</code> <code>deduplicate_timestamps</code> <code>bool</code> <p>Keep only latest row for duplicate timestamps.</p> <code>True</code> <code>sort_index</code> <code>bool</code> <p>Sort by timestamp ascending.</p> <code>True</code> <code>column</code> <code>str</code> <p>Price column to analyze.</p> <code>'Close'</code> <code>window</code> <code>int</code> <p>Rolling window for fallback regime detection.</p> <code>20</code> <code>penalty</code> <code>float</code> <p>Ruptures penalty parameter when available.</p> <code>3.0</code> <code>trend_threshold</code> <code>float</code> <p>Mean-return threshold for trend labels.</p> <code>0.0005</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict with <code>regime</code> (structured) and <code>text</code> fields.</p> Source code in <code>src/narrata/narrata/mcp_api.py</code> <pre><code>def regime_from_records(\n    records: list[dict[str, Any]],\n    *,\n    ticker: str | None = None,\n    timestamp_field: str = \"timestamp\",\n    deduplicate_timestamps: bool = True,\n    sort_index: bool = True,\n    column: str = \"Close\",\n    window: int = 20,\n    penalty: float = 3.0,\n    trend_threshold: float = 0.0005,\n) -&gt; dict[str, Any]:\n    \"\"\"Compute current regime classification and narration.\n\n    :param records: List of OHLCV row dictionaries.\n    :param ticker: Optional ticker symbol.\n    :param timestamp_field: Preferred timestamp field name.\n    :param deduplicate_timestamps: Keep only latest row for duplicate timestamps.\n    :param sort_index: Sort by timestamp ascending.\n    :param column: Price column to analyze.\n    :param window: Rolling window for fallback regime detection.\n    :param penalty: Ruptures penalty parameter when available.\n    :param trend_threshold: Mean-return threshold for trend labels.\n    :return: Dict with ``regime`` (structured) and ``text`` fields.\n    \"\"\"\n    frame = ohlcv_records_to_frame(\n        records,\n        ticker=ticker,\n        timestamp_field=timestamp_field,\n        deduplicate_timestamps=deduplicate_timestamps,\n        sort_index=sort_index,\n    )\n    stats = analyze_regime(frame, column=column, window=window, penalty=penalty, trend_threshold=trend_threshold)\n    return {\"regime\": _to_serializable(stats), \"text\": describe_regime(stats)}\n</code></pre>"},{"location":"reference/narrata/mcp_api/#narrata.mcp_api.indicators_from_records","title":"<code>indicators_from_records(records, *, ticker=None, timestamp_field='timestamp', deduplicate_timestamps=True, sort_index=True, column='Close', rsi_period=14)</code>","text":"<p>Compute indicator stats and narration from OHLCV records.</p> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>list[dict[str, Any]]</code> <p>List of OHLCV row dictionaries.</p> required <code>ticker</code> <code>str | None</code> <p>Optional ticker symbol.</p> <code>None</code> <code>timestamp_field</code> <code>str</code> <p>Preferred timestamp field name.</p> <code>'timestamp'</code> <code>deduplicate_timestamps</code> <code>bool</code> <p>Keep only latest row for duplicate timestamps.</p> <code>True</code> <code>sort_index</code> <code>bool</code> <p>Sort by timestamp ascending.</p> <code>True</code> <code>column</code> <code>str</code> <p>Price column to analyze.</p> <code>'Close'</code> <code>rsi_period</code> <code>int</code> <p>RSI period.</p> <code>14</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict with <code>indicators</code> (structured) and <code>text</code> fields.</p> Source code in <code>src/narrata/narrata/mcp_api.py</code> <pre><code>def indicators_from_records(\n    records: list[dict[str, Any]],\n    *,\n    ticker: str | None = None,\n    timestamp_field: str = \"timestamp\",\n    deduplicate_timestamps: bool = True,\n    sort_index: bool = True,\n    column: str = \"Close\",\n    rsi_period: int = 14,\n) -&gt; dict[str, Any]:\n    \"\"\"Compute indicator stats and narration from OHLCV records.\n\n    :param records: List of OHLCV row dictionaries.\n    :param ticker: Optional ticker symbol.\n    :param timestamp_field: Preferred timestamp field name.\n    :param deduplicate_timestamps: Keep only latest row for duplicate timestamps.\n    :param sort_index: Sort by timestamp ascending.\n    :param column: Price column to analyze.\n    :param rsi_period: RSI period.\n    :return: Dict with ``indicators`` (structured) and ``text`` fields.\n    \"\"\"\n    frame = ohlcv_records_to_frame(\n        records,\n        ticker=ticker,\n        timestamp_field=timestamp_field,\n        deduplicate_timestamps=deduplicate_timestamps,\n        sort_index=sort_index,\n    )\n    stats = analyze_indicators(frame, column=column, rsi_period=rsi_period)\n    return {\"indicators\": _to_serializable(stats), \"text\": describe_indicators(stats)}\n</code></pre>"},{"location":"reference/narrata/mcp_api/#narrata.mcp_api.sax_from_records","title":"<code>sax_from_records(records, *, ticker=None, timestamp_field='timestamp', deduplicate_timestamps=True, sort_index=True, column='Close', word_size=16, alphabet_size=8)</code>","text":"<p>Compute SAX symbols and narration from OHLCV records.</p> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>list[dict[str, Any]]</code> <p>List of OHLCV row dictionaries.</p> required <code>ticker</code> <code>str | None</code> <p>Optional ticker symbol.</p> <code>None</code> <code>timestamp_field</code> <code>str</code> <p>Preferred timestamp field name.</p> <code>'timestamp'</code> <code>deduplicate_timestamps</code> <code>bool</code> <p>Keep only latest row for duplicate timestamps.</p> <code>True</code> <code>sort_index</code> <code>bool</code> <p>Sort by timestamp ascending.</p> <code>True</code> <code>column</code> <code>str</code> <p>Price column to encode.</p> <code>'Close'</code> <code>word_size</code> <code>int</code> <p>Number of SAX segments.</p> <code>16</code> <code>alphabet_size</code> <code>int</code> <p>SAX alphabet size.</p> <code>8</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict with <code>symbolic</code> (structured) and <code>text</code> fields.</p> Source code in <code>src/narrata/narrata/mcp_api.py</code> <pre><code>def sax_from_records(\n    records: list[dict[str, Any]],\n    *,\n    ticker: str | None = None,\n    timestamp_field: str = \"timestamp\",\n    deduplicate_timestamps: bool = True,\n    sort_index: bool = True,\n    column: str = \"Close\",\n    word_size: int = 16,\n    alphabet_size: int = 8,\n) -&gt; dict[str, Any]:\n    \"\"\"Compute SAX symbols and narration from OHLCV records.\n\n    :param records: List of OHLCV row dictionaries.\n    :param ticker: Optional ticker symbol.\n    :param timestamp_field: Preferred timestamp field name.\n    :param deduplicate_timestamps: Keep only latest row for duplicate timestamps.\n    :param sort_index: Sort by timestamp ascending.\n    :param column: Price column to encode.\n    :param word_size: Number of SAX segments.\n    :param alphabet_size: SAX alphabet size.\n    :return: Dict with ``symbolic`` (structured) and ``text`` fields.\n    \"\"\"\n    frame = ohlcv_records_to_frame(\n        records,\n        ticker=ticker,\n        timestamp_field=timestamp_field,\n        deduplicate_timestamps=deduplicate_timestamps,\n        sort_index=sort_index,\n    )\n    stats = sax_encode(frame, column=column, word_size=word_size, alphabet_size=alphabet_size)\n    return {\"symbolic\": _to_serializable(stats), \"text\": describe_sax(stats)}\n</code></pre>"},{"location":"reference/narrata/mcp_api/#narrata.mcp_api.astride_from_records","title":"<code>astride_from_records(records, *, ticker=None, timestamp_field='timestamp', deduplicate_timestamps=True, sort_index=True, column='Close', n_segments=16, alphabet_size=8, penalty=3.0)</code>","text":"<p>Compute ASTRIDE symbols and narration from OHLCV records.</p> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>list[dict[str, Any]]</code> <p>List of OHLCV row dictionaries.</p> required <code>ticker</code> <code>str | None</code> <p>Optional ticker symbol.</p> <code>None</code> <code>timestamp_field</code> <code>str</code> <p>Preferred timestamp field name.</p> <code>'timestamp'</code> <code>deduplicate_timestamps</code> <code>bool</code> <p>Keep only latest row for duplicate timestamps.</p> <code>True</code> <code>sort_index</code> <code>bool</code> <p>Sort by timestamp ascending.</p> <code>True</code> <code>column</code> <code>str</code> <p>Price column to encode.</p> <code>'Close'</code> <code>n_segments</code> <code>int</code> <p>Approximate adaptive segment count.</p> <code>16</code> <code>alphabet_size</code> <code>int</code> <p>Symbol alphabet size.</p> <code>8</code> <code>penalty</code> <code>float</code> <p>Ruptures penalty parameter.</p> <code>3.0</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict with <code>symbolic</code> (structured) and <code>text</code> fields.</p> Source code in <code>src/narrata/narrata/mcp_api.py</code> <pre><code>def astride_from_records(\n    records: list[dict[str, Any]],\n    *,\n    ticker: str | None = None,\n    timestamp_field: str = \"timestamp\",\n    deduplicate_timestamps: bool = True,\n    sort_index: bool = True,\n    column: str = \"Close\",\n    n_segments: int = 16,\n    alphabet_size: int = 8,\n    penalty: float = 3.0,\n) -&gt; dict[str, Any]:\n    \"\"\"Compute ASTRIDE symbols and narration from OHLCV records.\n\n    :param records: List of OHLCV row dictionaries.\n    :param ticker: Optional ticker symbol.\n    :param timestamp_field: Preferred timestamp field name.\n    :param deduplicate_timestamps: Keep only latest row for duplicate timestamps.\n    :param sort_index: Sort by timestamp ascending.\n    :param column: Price column to encode.\n    :param n_segments: Approximate adaptive segment count.\n    :param alphabet_size: Symbol alphabet size.\n    :param penalty: Ruptures penalty parameter.\n    :return: Dict with ``symbolic`` (structured) and ``text`` fields.\n    \"\"\"\n    frame = ohlcv_records_to_frame(\n        records,\n        ticker=ticker,\n        timestamp_field=timestamp_field,\n        deduplicate_timestamps=deduplicate_timestamps,\n        sort_index=sort_index,\n    )\n    stats = astride_encode(frame, column=column, n_segments=n_segments, alphabet_size=alphabet_size, penalty=penalty)\n    return {\"symbolic\": _to_serializable(stats), \"text\": describe_astride(stats)}\n</code></pre>"},{"location":"reference/narrata/mcp_api/#narrata.mcp_api.patterns_from_records","title":"<code>patterns_from_records(records, *, ticker=None, timestamp_field='timestamp', deduplicate_timestamps=True, sort_index=True, lookback=60)</code>","text":"<p>Detect chart/candlestick patterns and narration from OHLCV records.</p> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>list[dict[str, Any]]</code> <p>List of OHLCV row dictionaries.</p> required <code>ticker</code> <code>str | None</code> <p>Optional ticker symbol.</p> <code>None</code> <code>timestamp_field</code> <code>str</code> <p>Preferred timestamp field name.</p> <code>'timestamp'</code> <code>deduplicate_timestamps</code> <code>bool</code> <p>Keep only latest row for duplicate timestamps.</p> <code>True</code> <code>sort_index</code> <code>bool</code> <p>Sort by timestamp ascending.</p> <code>True</code> <code>lookback</code> <code>int</code> <p>Lookback rows for chart pattern detection.</p> <code>60</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict with <code>patterns</code> (structured) and text lines.</p> Source code in <code>src/narrata/narrata/mcp_api.py</code> <pre><code>def patterns_from_records(\n    records: list[dict[str, Any]],\n    *,\n    ticker: str | None = None,\n    timestamp_field: str = \"timestamp\",\n    deduplicate_timestamps: bool = True,\n    sort_index: bool = True,\n    lookback: int = 60,\n) -&gt; dict[str, Any]:\n    \"\"\"Detect chart/candlestick patterns and narration from OHLCV records.\n\n    :param records: List of OHLCV row dictionaries.\n    :param ticker: Optional ticker symbol.\n    :param timestamp_field: Preferred timestamp field name.\n    :param deduplicate_timestamps: Keep only latest row for duplicate timestamps.\n    :param sort_index: Sort by timestamp ascending.\n    :param lookback: Lookback rows for chart pattern detection.\n    :return: Dict with ``patterns`` (structured) and text lines.\n    \"\"\"\n    frame = ohlcv_records_to_frame(\n        records,\n        ticker=ticker,\n        timestamp_field=timestamp_field,\n        deduplicate_timestamps=deduplicate_timestamps,\n        sort_index=sort_index,\n    )\n    stats = detect_patterns(frame, lookback=lookback)\n    return {\n        \"patterns\": _to_serializable(stats),\n        \"chart_text\": describe_patterns(stats),\n        \"candlestick_text\": describe_candlestick(stats),\n    }\n</code></pre>"},{"location":"reference/narrata/mcp_api/#narrata.mcp_api.levels_from_records","title":"<code>levels_from_records(records, *, ticker=None, timestamp_field='timestamp', deduplicate_timestamps=True, sort_index=True, column='Close', tolerance_ratio=0.01, max_levels=2, extrema_order=5)</code>","text":"<p>Detect support/resistance levels and narration from OHLCV records.</p> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>list[dict[str, Any]]</code> <p>List of OHLCV row dictionaries.</p> required <code>ticker</code> <code>str | None</code> <p>Optional ticker symbol.</p> <code>None</code> <code>timestamp_field</code> <code>str</code> <p>Preferred timestamp field name.</p> <code>'timestamp'</code> <code>deduplicate_timestamps</code> <code>bool</code> <p>Keep only latest row for duplicate timestamps.</p> <code>True</code> <code>sort_index</code> <code>bool</code> <p>Sort by timestamp ascending.</p> <code>True</code> <code>column</code> <code>str</code> <p>Price column to analyze.</p> <code>'Close'</code> <code>tolerance_ratio</code> <code>float</code> <p>Price-band clustering tolerance ratio.</p> <code>0.01</code> <code>max_levels</code> <code>int</code> <p>Max support/resistance levels to return per side.</p> <code>2</code> <code>extrema_order</code> <code>int</code> <p>Neighborhood size for local extrema.</p> <code>5</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict with <code>levels</code> (structured) and <code>text</code> fields.</p> Source code in <code>src/narrata/narrata/mcp_api.py</code> <pre><code>def levels_from_records(\n    records: list[dict[str, Any]],\n    *,\n    ticker: str | None = None,\n    timestamp_field: str = \"timestamp\",\n    deduplicate_timestamps: bool = True,\n    sort_index: bool = True,\n    column: str = \"Close\",\n    tolerance_ratio: float = 0.01,\n    max_levels: int = 2,\n    extrema_order: int = 5,\n) -&gt; dict[str, Any]:\n    \"\"\"Detect support/resistance levels and narration from OHLCV records.\n\n    :param records: List of OHLCV row dictionaries.\n    :param ticker: Optional ticker symbol.\n    :param timestamp_field: Preferred timestamp field name.\n    :param deduplicate_timestamps: Keep only latest row for duplicate timestamps.\n    :param sort_index: Sort by timestamp ascending.\n    :param column: Price column to analyze.\n    :param tolerance_ratio: Price-band clustering tolerance ratio.\n    :param max_levels: Max support/resistance levels to return per side.\n    :param extrema_order: Neighborhood size for local extrema.\n    :return: Dict with ``levels`` (structured) and ``text`` fields.\n    \"\"\"\n    frame = ohlcv_records_to_frame(\n        records,\n        ticker=ticker,\n        timestamp_field=timestamp_field,\n        deduplicate_timestamps=deduplicate_timestamps,\n        sort_index=sort_index,\n    )\n    stats = find_support_resistance(\n        frame,\n        column=column,\n        tolerance_ratio=tolerance_ratio,\n        max_levels=max_levels,\n        extrema_order=extrema_order,\n    )\n    return {\"levels\": _to_serializable(stats), \"text\": describe_support_resistance(stats)}\n</code></pre>"},{"location":"reference/narrata/rendering/","title":"rendering","text":""},{"location":"reference/narrata/rendering/#narrata.rendering","title":"<code>narrata.rendering</code>","text":"<p>Text rendering helpers for narrata.</p>"},{"location":"reference/narrata/rendering/#narrata.rendering.downsample_evenly","title":"<code>downsample_evenly(values, width)</code>","text":"<p>Reduce a sequence to an evenly sampled representation.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Sequence[float]</code> <p>Input numeric sequence.</p> required <code>width</code> <code>int</code> <p>Output width.</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>Evenly sampled values.</p> Source code in <code>src/narrata/narrata/rendering/sparkline.py</code> <pre><code>def downsample_evenly(values: Sequence[float], width: int) -&gt; list[float]:\n    \"\"\"Reduce a sequence to an evenly sampled representation.\n\n    :param values: Input numeric sequence.\n    :param width: Output width.\n    :return: Evenly sampled values.\n    \"\"\"\n    if width &lt; 1:\n        raise ValueError(\"width must be &gt;= 1\")\n\n    array = np.asarray(values, dtype=float)\n    if array.size == 0:\n        return []\n\n    if array.size &lt;= width:\n        return [float(value) for value in array.tolist()]\n\n    indices = np.linspace(0, array.size - 1, num=width)\n    sampled = array[np.round(indices).astype(int)]\n    return [float(value) for value in sampled.tolist()]\n</code></pre>"},{"location":"reference/narrata/rendering/#narrata.rendering.make_sparkline","title":"<code>make_sparkline(values, width=20, bars=BARS)</code>","text":"<p>Create a single-line Unicode sparkline.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Sequence[float]</code> <p>Input numeric sequence.</p> required <code>width</code> <code>int</code> <p>Max number of output glyphs.</p> <code>20</code> <code>bars</code> <code>str</code> <p>Glyph palette from low to high.</p> <code>BARS</code> <p>Returns:</p> Type Description <code>str</code> <p>Sparkline string.</p> Source code in <code>src/narrata/narrata/rendering/sparkline.py</code> <pre><code>def make_sparkline(values: Sequence[float], width: int = 20, bars: str = BARS) -&gt; str:\n    \"\"\"Create a single-line Unicode sparkline.\n\n    :param values: Input numeric sequence.\n    :param width: Max number of output glyphs.\n    :param bars: Glyph palette from low to high.\n    :return: Sparkline string.\n    \"\"\"\n    if len(bars) &lt; 2:\n        raise ValueError(\"bars must have at least two characters\")\n\n    sampled = downsample_evenly(values, width=width)\n    if not sampled:\n        return \"\"\n\n    bins = normalize_to_bins(sampled, bins=len(bars))\n    return \"\".join(bars[index] for index in bins)\n</code></pre>"},{"location":"reference/narrata/rendering/#narrata.rendering.normalize_to_bins","title":"<code>normalize_to_bins(values, bins)</code>","text":"<p>Map numeric values to integer bins in [0, bins - 1].</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Sequence[float]</code> <p>Input numeric sequence.</p> required <code>bins</code> <code>int</code> <p>Number of target bins.</p> required <p>Returns:</p> Type Description <code>list[int]</code> <p>Bin indices.</p> Source code in <code>src/narrata/narrata/rendering/sparkline.py</code> <pre><code>def normalize_to_bins(values: Sequence[float], bins: int) -&gt; list[int]:\n    \"\"\"Map numeric values to integer bins in [0, bins - 1].\n\n    :param values: Input numeric sequence.\n    :param bins: Number of target bins.\n    :return: Bin indices.\n    \"\"\"\n    if bins &lt; 2:\n        raise ValueError(\"bins must be &gt;= 2\")\n\n    array = np.asarray(values, dtype=float)\n    if array.size == 0:\n        return []\n\n    if not np.isfinite(array).all():\n        raise ValueError(\"values must be finite numbers\")\n\n    low = float(array.min())\n    high = float(array.max())\n\n    if high == low:\n        return [bins // 2] * int(array.size)\n\n    scaled = (array - low) / (high - low)\n    mapped = np.clip(np.rint(scaled * (bins - 1)).astype(int), 0, bins - 1)\n    return [int(value) for value in mapped.tolist()]\n</code></pre>"},{"location":"reference/narrata/rendering/sparkline/","title":"sparkline","text":""},{"location":"reference/narrata/rendering/sparkline/#narrata.rendering.sparkline","title":"<code>narrata.rendering.sparkline</code>","text":"<p>Unicode sparkline rendering for compact trend visualization.</p>"},{"location":"reference/narrata/rendering/sparkline/#narrata.rendering.sparkline.downsample_evenly","title":"<code>downsample_evenly(values, width)</code>","text":"<p>Reduce a sequence to an evenly sampled representation.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Sequence[float]</code> <p>Input numeric sequence.</p> required <code>width</code> <code>int</code> <p>Output width.</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>Evenly sampled values.</p> Source code in <code>src/narrata/narrata/rendering/sparkline.py</code> <pre><code>def downsample_evenly(values: Sequence[float], width: int) -&gt; list[float]:\n    \"\"\"Reduce a sequence to an evenly sampled representation.\n\n    :param values: Input numeric sequence.\n    :param width: Output width.\n    :return: Evenly sampled values.\n    \"\"\"\n    if width &lt; 1:\n        raise ValueError(\"width must be &gt;= 1\")\n\n    array = np.asarray(values, dtype=float)\n    if array.size == 0:\n        return []\n\n    if array.size &lt;= width:\n        return [float(value) for value in array.tolist()]\n\n    indices = np.linspace(0, array.size - 1, num=width)\n    sampled = array[np.round(indices).astype(int)]\n    return [float(value) for value in sampled.tolist()]\n</code></pre>"},{"location":"reference/narrata/rendering/sparkline/#narrata.rendering.sparkline.normalize_to_bins","title":"<code>normalize_to_bins(values, bins)</code>","text":"<p>Map numeric values to integer bins in [0, bins - 1].</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Sequence[float]</code> <p>Input numeric sequence.</p> required <code>bins</code> <code>int</code> <p>Number of target bins.</p> required <p>Returns:</p> Type Description <code>list[int]</code> <p>Bin indices.</p> Source code in <code>src/narrata/narrata/rendering/sparkline.py</code> <pre><code>def normalize_to_bins(values: Sequence[float], bins: int) -&gt; list[int]:\n    \"\"\"Map numeric values to integer bins in [0, bins - 1].\n\n    :param values: Input numeric sequence.\n    :param bins: Number of target bins.\n    :return: Bin indices.\n    \"\"\"\n    if bins &lt; 2:\n        raise ValueError(\"bins must be &gt;= 2\")\n\n    array = np.asarray(values, dtype=float)\n    if array.size == 0:\n        return []\n\n    if not np.isfinite(array).all():\n        raise ValueError(\"values must be finite numbers\")\n\n    low = float(array.min())\n    high = float(array.max())\n\n    if high == low:\n        return [bins // 2] * int(array.size)\n\n    scaled = (array - low) / (high - low)\n    mapped = np.clip(np.rint(scaled * (bins - 1)).astype(int), 0, bins - 1)\n    return [int(value) for value in mapped.tolist()]\n</code></pre>"},{"location":"reference/narrata/rendering/sparkline/#narrata.rendering.sparkline.make_sparkline","title":"<code>make_sparkline(values, width=20, bars=BARS)</code>","text":"<p>Create a single-line Unicode sparkline.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Sequence[float]</code> <p>Input numeric sequence.</p> required <code>width</code> <code>int</code> <p>Max number of output glyphs.</p> <code>20</code> <code>bars</code> <code>str</code> <p>Glyph palette from low to high.</p> <code>BARS</code> <p>Returns:</p> Type Description <code>str</code> <p>Sparkline string.</p> Source code in <code>src/narrata/narrata/rendering/sparkline.py</code> <pre><code>def make_sparkline(values: Sequence[float], width: int = 20, bars: str = BARS) -&gt; str:\n    \"\"\"Create a single-line Unicode sparkline.\n\n    :param values: Input numeric sequence.\n    :param width: Max number of output glyphs.\n    :param bars: Glyph palette from low to high.\n    :return: Sparkline string.\n    \"\"\"\n    if len(bars) &lt; 2:\n        raise ValueError(\"bars must have at least two characters\")\n\n    sampled = downsample_evenly(values, width=width)\n    if not sampled:\n        return \"\"\n\n    bins = normalize_to_bins(sampled, bins=len(bars))\n    return \"\".join(bars[index] for index in bins)\n</code></pre>"},{"location":"reference/narrata/types/","title":"types","text":""},{"location":"reference/narrata/types/#narrata.types","title":"<code>narrata.types</code>","text":"<p>Shared public types for narrata.</p>"},{"location":"reference/narrata/types/#narrata.types.SummaryStats","title":"<code>SummaryStats(ticker, column, points, frequency, start_date, end_date, start, end, minimum, maximum, mean, std, change_pct)</code>  <code>dataclass</code>","text":"<p>Structured output of summary analysis for one series.</p>"},{"location":"reference/narrata/types/#narrata.types.IndicatorStats","title":"<code>IndicatorStats(rsi_period, rsi_value, rsi_state, macd_value, macd_signal, macd_histogram, macd_state, crossover_days_ago, bb_position=None, bb_squeeze=None, ma_cross=None, ma_cross_days_ago=None, volume_ratio=None, volume_state=None, volatility_percentile=None, volatility_state=None)</code>  <code>dataclass</code>","text":"<p>Structured output for key technical indicators.</p>"},{"location":"reference/narrata/types/#narrata.types.RegimeStats","title":"<code>RegimeStats(trend_label, volatility_label, start_date)</code>  <code>dataclass</code>","text":"<p>Structured output for current market regime.</p>"},{"location":"reference/narrata/types/#narrata.types.SymbolicStats","title":"<code>SymbolicStats(method, word_size, alphabet_size, symbols)</code>  <code>dataclass</code>","text":"<p>Structured output for symbolic time-series encoding.</p>"},{"location":"reference/narrata/types/#narrata.types.PatternStats","title":"<code>PatternStats(chart_pattern, chart_pattern_since, candlestick_pattern, candlestick_date)</code>  <code>dataclass</code>","text":"<p>Structured output for detected chart and candlestick patterns.</p>"},{"location":"reference/narrata/types/#narrata.types.PriceLevel","title":"<code>PriceLevel(price, touches)</code>  <code>dataclass</code>","text":"<p>Single support or resistance level.</p>"},{"location":"reference/narrata/types/#narrata.types.LevelStats","title":"<code>LevelStats(supports, resistances)</code>  <code>dataclass</code>","text":"<p>Structured support and resistance output.</p>"},{"location":"reference/narrata/validation/","title":"validation","text":""},{"location":"reference/narrata/validation/#narrata.validation","title":"<code>narrata.validation</code>","text":"<p>Validation contracts for input time-series frames.</p>"},{"location":"reference/narrata/validation/#narrata.validation.infer_frequency_label","title":"<code>infer_frequency_label(index)</code>","text":"<p>Infer a user-facing frequency label from a DatetimeIndex.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>DatetimeIndex</code> <p>Datetime index.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Inferred frequency label.</p> Source code in <code>src/narrata/narrata/validation/ohlcv.py</code> <pre><code>def infer_frequency_label(index: pd.DatetimeIndex) -&gt; str:\n    \"\"\"Infer a user-facing frequency label from a DatetimeIndex.\n\n    :param index: Datetime index.\n    :return: Inferred frequency label.\n    \"\"\"\n    if len(index) &lt; 2:\n        return \"irregular\"\n\n    inferred = pd.infer_freq(index)\n    if inferred:\n        key = str(inferred).split(\"-\")[0]\n        return _FREQUENCY_LABELS.get(key, key.lower())\n\n    deltas = index.to_series().diff().dropna()\n    if deltas.empty:\n        return \"irregular\"\n\n    median_seconds = float(deltas.dt.total_seconds().median())\n\n    if median_seconds &lt;= 3600:\n        return \"hourly\"\n    if median_seconds &lt;= 86_400:\n        return \"daily\"\n    if median_seconds &lt;= 86_400 * 7:\n        return \"weekly\"\n    if median_seconds &lt;= 86_400 * 31:\n        return \"monthly\"\n    return \"irregular\"\n</code></pre>"},{"location":"reference/narrata/validation/#narrata.validation.validate_ohlcv_frame","title":"<code>validate_ohlcv_frame(df, required_columns=REQUIRED_OHLCV_COLUMNS)</code>","text":"<p>Validate basic OHLCV and index contracts expected by narrata.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame to validate.</p> required <code>required_columns</code> <code>Sequence[str]</code> <p>Required OHLCV columns.</p> <code>REQUIRED_OHLCV_COLUMNS</code> <p>Returns:</p> Type Description <code>None</code> <p><code>None</code> if validation passes.</p> Source code in <code>src/narrata/narrata/validation/ohlcv.py</code> <pre><code>def validate_ohlcv_frame(df: pd.DataFrame, required_columns: Sequence[str] = REQUIRED_OHLCV_COLUMNS) -&gt; None:\n    \"\"\"Validate basic OHLCV and index contracts expected by narrata.\n\n    :param df: Input DataFrame to validate.\n    :param required_columns: Required OHLCV columns.\n    :return: ``None`` if validation passes.\n    \"\"\"\n    if isinstance(df, pd.DataFrame) and df.attrs.get(_VALIDATED_ATTR):\n        return\n\n    if not isinstance(df, pd.DataFrame):\n        raise ValidationError(\"Input must be a pandas DataFrame.\")\n\n    if df.empty:\n        raise ValidationError(\"Input DataFrame must not be empty.\")\n\n    if isinstance(df.index, pd.MultiIndex):\n        raise ValidationError(\n            \"MultiIndex input is not supported. For stacked multi-ticker data, \"\n            \"split by ticker and call narrate per symbol.\"\n        )\n\n    if not isinstance(df.index, pd.DatetimeIndex):\n        raise ValidationError(\"DataFrame index must be a pandas DatetimeIndex.\")\n\n    if df.index.has_duplicates:\n        raise ValidationError(\"DataFrame index must not contain duplicate timestamps.\")\n\n    if not df.index.is_monotonic_increasing:\n        raise ValidationError(\"DataFrame index must be sorted in ascending order.\")\n\n    missing_columns = [name for name in required_columns if name not in df.columns]\n    if missing_columns:\n        joined = \", \".join(missing_columns)\n        raise ValidationError(f\"DataFrame is missing required columns: {joined}.\")\n\n    df.attrs[_VALIDATED_ATTR] = True\n</code></pre>"},{"location":"reference/narrata/validation/ohlcv/","title":"ohlcv","text":""},{"location":"reference/narrata/validation/ohlcv/#narrata.validation.ohlcv","title":"<code>narrata.validation.ohlcv</code>","text":"<p>Validation routines for OHLCV time-series DataFrames.</p>"},{"location":"reference/narrata/validation/ohlcv/#narrata.validation.ohlcv.validate_ohlcv_frame","title":"<code>validate_ohlcv_frame(df, required_columns=REQUIRED_OHLCV_COLUMNS)</code>","text":"<p>Validate basic OHLCV and index contracts expected by narrata.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame to validate.</p> required <code>required_columns</code> <code>Sequence[str]</code> <p>Required OHLCV columns.</p> <code>REQUIRED_OHLCV_COLUMNS</code> <p>Returns:</p> Type Description <code>None</code> <p><code>None</code> if validation passes.</p> Source code in <code>src/narrata/narrata/validation/ohlcv.py</code> <pre><code>def validate_ohlcv_frame(df: pd.DataFrame, required_columns: Sequence[str] = REQUIRED_OHLCV_COLUMNS) -&gt; None:\n    \"\"\"Validate basic OHLCV and index contracts expected by narrata.\n\n    :param df: Input DataFrame to validate.\n    :param required_columns: Required OHLCV columns.\n    :return: ``None`` if validation passes.\n    \"\"\"\n    if isinstance(df, pd.DataFrame) and df.attrs.get(_VALIDATED_ATTR):\n        return\n\n    if not isinstance(df, pd.DataFrame):\n        raise ValidationError(\"Input must be a pandas DataFrame.\")\n\n    if df.empty:\n        raise ValidationError(\"Input DataFrame must not be empty.\")\n\n    if isinstance(df.index, pd.MultiIndex):\n        raise ValidationError(\n            \"MultiIndex input is not supported. For stacked multi-ticker data, \"\n            \"split by ticker and call narrate per symbol.\"\n        )\n\n    if not isinstance(df.index, pd.DatetimeIndex):\n        raise ValidationError(\"DataFrame index must be a pandas DatetimeIndex.\")\n\n    if df.index.has_duplicates:\n        raise ValidationError(\"DataFrame index must not contain duplicate timestamps.\")\n\n    if not df.index.is_monotonic_increasing:\n        raise ValidationError(\"DataFrame index must be sorted in ascending order.\")\n\n    missing_columns = [name for name in required_columns if name not in df.columns]\n    if missing_columns:\n        joined = \", \".join(missing_columns)\n        raise ValidationError(f\"DataFrame is missing required columns: {joined}.\")\n\n    df.attrs[_VALIDATED_ATTR] = True\n</code></pre>"},{"location":"reference/narrata/validation/ohlcv/#narrata.validation.ohlcv.infer_frequency_label","title":"<code>infer_frequency_label(index)</code>","text":"<p>Infer a user-facing frequency label from a DatetimeIndex.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>DatetimeIndex</code> <p>Datetime index.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Inferred frequency label.</p> Source code in <code>src/narrata/narrata/validation/ohlcv.py</code> <pre><code>def infer_frequency_label(index: pd.DatetimeIndex) -&gt; str:\n    \"\"\"Infer a user-facing frequency label from a DatetimeIndex.\n\n    :param index: Datetime index.\n    :return: Inferred frequency label.\n    \"\"\"\n    if len(index) &lt; 2:\n        return \"irregular\"\n\n    inferred = pd.infer_freq(index)\n    if inferred:\n        key = str(inferred).split(\"-\")[0]\n        return _FREQUENCY_LABELS.get(key, key.lower())\n\n    deltas = index.to_series().diff().dropna()\n    if deltas.empty:\n        return \"irregular\"\n\n    median_seconds = float(deltas.dt.total_seconds().median())\n\n    if median_seconds &lt;= 3600:\n        return \"hourly\"\n    if median_seconds &lt;= 86_400:\n        return \"daily\"\n    if median_seconds &lt;= 86_400 * 7:\n        return \"weekly\"\n    if median_seconds &lt;= 86_400 * 31:\n        return \"monthly\"\n    return \"irregular\"\n</code></pre>"}]}